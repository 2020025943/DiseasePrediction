{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import glorot_normal\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = pd.read_csv('E:/BaiduNetdiskDownload/论文/ALF_Data.csv')\n",
    "data.dropna(subset = ['Hepatitis'], inplace = True)\n",
    "for i in ['Weight', 'Height', 'Waist', 'Maximum Blood Pressure', 'Minimum Blood Pressure', 'Good Cholesterol', 'Bad Cholesterol']:\n",
    "    data.loc[:, i] = SimpleImputer(strategy = 'mean').fit_transform(data[i].values.reshape(-1, 1))\n",
    "for i in ['Obesity', 'Physical Activity', 'Education', 'Unmarried', 'Income', 'PoorVision', 'HyperTension', 'Family Hepatitis', 'Chronic Fatigue', 'ALF']:\n",
    "    data.loc[:, i] = SimpleImputer(strategy = 'most_frequent').fit_transform(data[i].values.reshape(-1, 1))\n",
    "data.loc[:, 'Body Mass Index'] = data['Weight'] / ((data['Height'] / 100) ** 2)\n",
    "data.loc[:, 'Total Cholesterol'] = data['Good Cholesterol'] + data['Bad Cholesterol']\n",
    "for i in ['Gender', 'Region', 'Source of Care']:\n",
    "    data.loc[:, i] = OrdinalEncoder().fit_transform(data[i].values.reshape(-1, 1))\n",
    "dense_features=['Age','Weight','Height',\n",
    "                'Body Mass Index','Waist','Maximum Blood Pressure',\n",
    "                'Minimum Blood Pressure','Good Cholesterol','Bad Cholesterol',\n",
    "                'Total Cholesterol']\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data.loc[:, dense_features] = mms.fit_transform(data[dense_features])\n",
    "data.loc[:, 'Hepatitis'] = data['Hepatitis'].astype('int')\n",
    "train = data.iloc[:6000]\n",
    "test = data.iloc[6000:]\n",
    "Xtrain = train.loc[:, train.columns != 'Hepatitis']\n",
    "Ytrain = train.loc[:, 'Hepatitis']\n",
    "Xtest = test.loc[:, test.columns != 'Hepatitis']\n",
    "Ytest = test.loc[:, 'Hepatitis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Region</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Waist</th>\n",
       "      <th>Maximum Blood Pressure</th>\n",
       "      <th>Minimum Blood Pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>PoorVision</th>\n",
       "      <th>Alcohol Consumption</th>\n",
       "      <th>HyperTension</th>\n",
       "      <th>Family  HyperTension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Family Diabetes</th>\n",
       "      <th>Hepatitis</th>\n",
       "      <th>Family Hepatitis</th>\n",
       "      <th>Chronic Fatigue</th>\n",
       "      <th>ALF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181276</td>\n",
       "      <td>0.454806</td>\n",
       "      <td>0.170407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218451</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.206321</td>\n",
       "      <td>0.456241</td>\n",
       "      <td>0.199274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157528</td>\n",
       "      <td>0.149068</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.347645</td>\n",
       "      <td>0.460545</td>\n",
       "      <td>0.362724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.476066</td>\n",
       "      <td>0.267081</td>\n",
       "      <td>0.385246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.523077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261181</td>\n",
       "      <td>0.431851</td>\n",
       "      <td>0.273890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168842</td>\n",
       "      <td>0.236025</td>\n",
       "      <td>0.385246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.283244</td>\n",
       "      <td>0.413199</td>\n",
       "      <td>0.308851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268059</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8780</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.264758</td>\n",
       "      <td>0.589670</td>\n",
       "      <td>0.216142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252393</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8781</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.455575</td>\n",
       "      <td>0.721664</td>\n",
       "      <td>0.352893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.476066</td>\n",
       "      <td>0.279503</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8782</td>\n",
       "      <td>0.261538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.350626</td>\n",
       "      <td>0.797704</td>\n",
       "      <td>0.227105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305483</td>\n",
       "      <td>0.447205</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8783</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396541</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.274399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.345518</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.532787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8784</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196184</td>\n",
       "      <td>0.440459</td>\n",
       "      <td>0.192996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.355962</td>\n",
       "      <td>0.329193</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8763 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  Gender  Region    Weight    Height  Body Mass Index  Obesity  \\\n",
       "0     0.692308     1.0     0.0  0.181276  0.454806         0.170407      0.0   \n",
       "1     0.246154     1.0     2.0  0.206321  0.456241         0.199274      0.0   \n",
       "2     0.707692     1.0     0.0  0.347645  0.460545         0.362724      1.0   \n",
       "3     0.523077     1.0     0.0  0.261181  0.431851         0.273890      0.0   \n",
       "4     0.661538     1.0     1.0  0.283244  0.413199         0.308851      0.0   \n",
       "...        ...     ...     ...       ...       ...              ...      ...   \n",
       "8780  0.230769     0.0     0.0  0.264758  0.589670         0.216142      0.0   \n",
       "8781  0.707692     0.0     1.0  0.455575  0.721664         0.352893      1.0   \n",
       "8782  0.261538     0.0     2.0  0.350626  0.797704         0.227105      0.0   \n",
       "8783  0.292308     0.0     0.0  0.396541  0.780488         0.274399      0.0   \n",
       "8784  0.769231     1.0     0.0  0.196184  0.440459         0.192996      0.0   \n",
       "\n",
       "         Waist  Maximum Blood Pressure  Minimum Blood Pressure  ...  \\\n",
       "0     0.218451                0.391304                0.500000  ...   \n",
       "1     0.157528                0.149068                0.344262  ...   \n",
       "2     0.476066                0.267081                0.385246  ...   \n",
       "3     0.168842                0.236025                0.385246  ...   \n",
       "4     0.268059                0.372671                0.516393  ...   \n",
       "...        ...                     ...                     ...  ...   \n",
       "8780  0.252393                0.260870                0.540984  ...   \n",
       "8781  0.476066                0.279503                0.508197  ...   \n",
       "8782  0.305483                0.447205                0.590164  ...   \n",
       "8783  0.345518                0.304348                0.532787  ...   \n",
       "8784  0.355962                0.329193                0.590164  ...   \n",
       "\n",
       "      PoorVision  Alcohol Consumption  HyperTension  Family  HyperTension  \\\n",
       "0            0.0                    1           0.0                     0   \n",
       "1            0.0                    0           0.0                     0   \n",
       "2            0.0                    1           0.0                     0   \n",
       "3            0.0                    1           0.0                     0   \n",
       "4            0.0                    0           1.0                     0   \n",
       "...          ...                  ...           ...                   ...   \n",
       "8780         0.0                    1           0.0                     1   \n",
       "8781         0.0                    0           1.0                     0   \n",
       "8782         0.0                    0           1.0                     0   \n",
       "8783         0.0                    0           0.0                     0   \n",
       "8784         0.0                    0           1.0                     1   \n",
       "\n",
       "      Diabetes  Family Diabetes  Hepatitis  Family Hepatitis  Chronic Fatigue  \\\n",
       "0          0.0                1          1               0.0              0.0   \n",
       "1          0.0                0          0               0.0              0.0   \n",
       "2          1.0                0          0               0.0              0.0   \n",
       "3          0.0                0          0               0.0              0.0   \n",
       "4          0.0                0          0               0.0              0.0   \n",
       "...        ...              ...        ...               ...              ...   \n",
       "8780       0.0                1          0               0.0              0.0   \n",
       "8781       0.0                1          0               0.0              0.0   \n",
       "8782       0.0                0          0               0.0              0.0   \n",
       "8783       0.0                0          0               0.0              0.0   \n",
       "8784       0.0                0          0               0.0              0.0   \n",
       "\n",
       "      ALF  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "...   ...  \n",
       "8780  0.0  \n",
       "8781  0.0  \n",
       "8782  0.0  \n",
       "8783  0.0  \n",
       "8784  0.0  \n",
       "\n",
       "[8763 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 35ms/step - loss: 1.9457 - auc: 0.4971 - val_loss: 1.4624 - val_auc: 0.5383\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1514 - auc: 0.4981 - val_loss: 0.8634 - val_auc: 0.5070\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6978 - auc: 0.4969 - val_loss: 0.5402 - val_auc: 0.5453\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4695 - auc: 0.4988 - val_loss: 0.3881 - val_auc: 0.5000\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3657 - auc: 0.4950 - val_loss: 0.3197 - val_auc: 0.5000\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3189 - auc: 0.5043 - val_loss: 0.2879 - val_auc: 0.5013\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2967 - auc: 0.4798 - val_loss: 0.2723 - val_auc: 0.5000\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2853 - auc: 0.5000 - val_loss: 0.2639 - val_auc: 0.5000\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2790 - auc: 0.5000 - val_loss: 0.2590 - val_auc: 0.5000\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2750 - auc: 0.4799 - val_loss: 0.2556 - val_auc: 0.5000\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.6902 - auc: 0.5082 - val_loss: 1.2940 - val_auc: 0.6639\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0653 - auc: 0.5675 - val_loss: 0.8269 - val_auc: 0.7434\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7051 - auc: 0.5835 - val_loss: 0.5618 - val_auc: 0.7619\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5020 - auc: 0.5883 - val_loss: 0.4141 - val_auc: 0.7798\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3895 - auc: 0.5761 - val_loss: 0.3327 - val_auc: 0.7540\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3278 - auc: 0.5578 - val_loss: 0.2885 - val_auc: 0.7671\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2942 - auc: 0.5596 - val_loss: 0.2646 - val_auc: 0.7677\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2761 - auc: 0.5475 - val_loss: 0.2517 - val_auc: 0.7558\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2663 - auc: 0.5413 - val_loss: 0.2446 - val_auc: 0.7301\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2609 - auc: 0.5354 - val_loss: 0.2407 - val_auc: 0.7193\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 1.7161 - auc: 0.5707 - val_loss: 1.3087 - val_auc: 0.7901\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0806 - auc: 0.7333 - val_loss: 0.8353 - val_auc: 0.8276\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7153 - auc: 0.7712 - val_loss: 0.5682 - val_auc: 0.8392\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.5092 - auc: 0.7906 - val_loss: 0.4191 - val_auc: 0.8466\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3938 - auc: 0.8015 - val_loss: 0.3360 - val_auc: 0.8472\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3294 - auc: 0.8086 - val_loss: 0.2897 - val_auc: 0.8494\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2951 - auc: 0.808 - 0s 5ms/step - loss: 0.2932 - auc: 0.8141 - val_loss: 0.2638 - val_auc: 0.8519\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2727 - auc: 0.8190 - val_loss: 0.2492 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2608 - auc: 0.8225 - val_loss: 0.2406 - val_auc: 0.8525\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2536 - auc: 0.8252 - val_loss: 0.2356 - val_auc: 0.8523\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 1.6772 - auc: 0.5464 - val_loss: 1.2395 - val_auc: 0.7207\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0186 - auc: 0.6764 - val_loss: 0.7768 - val_auc: 0.7835\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6672 - auc: 0.7333 - val_loss: 0.5270 - val_auc: 0.8171\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4765 - auc: 0.7661 - val_loss: 0.3916 - val_auc: 0.8319\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3732 - auc: 0.7827 - val_loss: 0.3187 - val_auc: 0.8396\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3172 - auc: 0.7959 - val_loss: 0.2794 - val_auc: 0.8428\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2864 - auc: 0.8040 - val_loss: 0.2577 - val_auc: 0.8452\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2690 - auc: 0.8101 - val_loss: 0.2454 - val_auc: 0.8479\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2589 - auc: 0.8145 - val_loss: 0.2383 - val_auc: 0.8501\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2528 - auc: 0.8188 - val_loss: 0.2340 - val_auc: 0.8506\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8179149613919074 tanh\n",
      "[0.6644976915787988, 0.792849942541481, 0.8179149613919074, 0.8092175560976593]\n",
      "0.2126307161986677 tanh\n",
      "[0.25417817041272495, 0.2522331599686787, 0.2126307161986677, 0.21452537121421783]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = ['softmax', 'sigmoid', 'tanh', 'relu']\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = i,kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'relu',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 1.9859 - auc: 0.5017 - val_loss: 1.5551 - val_auc: 0.5589\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2951 - auc: 0.5107 - val_loss: 1.0454 - val_auc: 0.6400\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8824 - auc: 0.5167 - val_loss: 0.7478 - val_auc: 0.5986\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6772 - auc: 0.5225 - val_loss: 0.6062 - val_auc: 0.5855\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5704 - auc: 0.5148 - val_loss: 0.5280 - val_auc: 0.6052\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5096 - auc: 0.5224 - val_loss: 0.4812 - val_auc: 0.6039\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4719 - auc: 0.5197 - val_loss: 0.4506 - val_auc: 0.6079\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4462 - auc: 0.5165 - val_loss: 0.4284 - val_auc: 0.5948\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4269 - auc: 0.5218 - val_loss: 0.4109 - val_auc: 0.5888\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4112 - auc: 0.5199 - val_loss: 0.3962 - val_auc: 0.5812\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_15 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.6669 - auc: 0.5343 - val_loss: 1.2169 - val_auc: 0.7200\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9822 - auc: 0.6529 - val_loss: 0.7385 - val_auc: 0.7801\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6251 - auc: 0.7079 - val_loss: 0.4903 - val_auc: 0.8003\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4417 - auc: 0.7171 - val_loss: 0.3640 - val_auc: 0.8168\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3492 - auc: 0.7126 - val_loss: 0.3009 - val_auc: 0.7952\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3031 - auc: 0.6942 - val_loss: 0.2696 - val_auc: 0.7758\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2803 - auc: 0.6708 - val_loss: 0.2540 - val_auc: 0.7355\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2689 - auc: 0.6429 - val_loss: 0.2461 - val_auc: 0.7102\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2630 - auc: 0.6104 - val_loss: 0.2419 - val_auc: 0.7023\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2597 - auc: 0.5739 - val_loss: 0.2394 - val_auc: 0.6973\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_18 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 1.7574 - auc: 0.5870 - val_loss: 1.3732 - val_auc: 0.8131\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1517 - auc: 0.7554 - val_loss: 0.9026 - val_auc: 0.8398\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7755 - auc: 0.7873 - val_loss: 0.6198 - val_auc: 0.8467\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5519 - auc: 0.8020 - val_loss: 0.4542 - val_auc: 0.8487\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4220 - auc: 0.8105 - val_loss: 0.3589 - val_auc: 0.8507\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3472 - auc: 0.8156 - val_loss: 0.3044 - val_auc: 0.8518\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3043 - auc: 0.8210 - val_loss: 0.2733 - val_auc: 0.8539\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2797 - auc: 0.8249 - val_loss: 0.2555 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2653 - auc: 0.8269 - val_loss: 0.2451 - val_auc: 0.8540\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2567 - auc: 0.8301 - val_loss: 0.2390 - val_auc: 0.8553\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_21 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 1.7161 - auc: 0.5707 - val_loss: 1.3087 - val_auc: 0.7901\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0806 - auc: 0.7333 - val_loss: 0.8353 - val_auc: 0.8276\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7153 - auc: 0.7712 - val_loss: 0.5682 - val_auc: 0.8392\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5092 - auc: 0.7906 - val_loss: 0.4191 - val_auc: 0.8466\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3938 - auc: 0.8015 - val_loss: 0.3360 - val_auc: 0.8472\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3294 - auc: 0.8086 - val_loss: 0.2897 - val_auc: 0.8494\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2932 - auc: 0.8141 - val_loss: 0.2638 - val_auc: 0.8519\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2727 - auc: 0.8190 - val_loss: 0.2492 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2608 - auc: 0.8225 - val_loss: 0.2406 - val_auc: 0.8525\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2536 - auc: 0.8252 - val_loss: 0.2356 - val_auc: 0.8523\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8221870526803896 tanh\n",
      "[0.5401493921493518, 0.7564363621701176, 0.8221870526803896, 0.8179149613919074]\n",
      "0.21078722318954607 tanh\n",
      "[0.37753373923786643, 0.2526413182412159, 0.21078722318954607, 0.2126307161986677]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = ['softmax', 'sigmoid', 'tanh', 'relu']\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = i,kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_24 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 2.3097 - auc: 0.4721 - val_loss: 2.2607 - val_auc: 0.5529\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2423 - auc: 0.4770 - val_loss: 2.1995 - val_auc: 0.5591\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1892 - auc: 0.4816 - val_loss: 2.1512 - val_auc: 0.5695\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.1475 - auc: 0.4862 - val_loss: 2.1129 - val_auc: 0.5745\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.1142 - auc: 0.4916 - val_loss: 2.0820 - val_auc: 0.5814\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.0873 - auc: 0.4967 - val_loss: 2.0566 - val_auc: 0.5899\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0651 - auc: 0.5020 - val_loss: 2.0354 - val_auc: 0.5967\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.0464 - auc: 0.5079 - val_loss: 2.0172 - val_auc: 0.6061\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0302 - auc: 0.5135 - val_loss: 2.0014 - val_auc: 0.6116\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.0160 - auc: 0.5194 - val_loss: 1.9872 - val_auc: 0.6157\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_27 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 2.1796 - auc: 0.4880 - val_loss: 2.0448 - val_auc: 0.5897\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.0193 - auc: 0.5102 - val_loss: 1.9579 - val_auc: 0.6269\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9564 - auc: 0.5453 - val_loss: 1.9036 - val_auc: 0.6585\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9064 - auc: 0.5766 - val_loss: 1.8548 - val_auc: 0.6836\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8589 - auc: 0.6048 - val_loss: 1.8078 - val_auc: 0.7077\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8124 - auc: 0.6285 - val_loss: 1.7618 - val_auc: 0.7258\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7667 - auc: 0.6498 - val_loss: 1.7168 - val_auc: 0.7423\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7220 - auc: 0.6686 - val_loss: 1.6727 - val_auc: 0.7535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6781 - auc: 0.6841 - val_loss: 1.6295 - val_auc: 0.7683\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6352 - auc: 0.6966 - val_loss: 1.5872 - val_auc: 0.7759\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_30 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 2.1095 - auc: 0.4981 - val_loss: 1.9642 - val_auc: 0.6204\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.9448 - auc: 0.5487 - val_loss: 1.8715 - val_auc: 0.6784\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8580 - auc: 0.6047 - val_loss: 1.7870 - val_auc: 0.7149\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7742 - auc: 0.6455 - val_loss: 1.7050 - val_auc: 0.7480\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6932 - auc: 0.6779 - val_loss: 1.6259 - val_auc: 0.7694\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6152 - auc: 0.7013 - val_loss: 1.5498 - val_auc: 0.7860\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5404 - auc: 0.7184 - val_loss: 1.4770 - val_auc: 0.7994\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4687 - auc: 0.7341 - val_loss: 1.4074 - val_auc: 0.8054\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4003 - auc: 0.7475 - val_loss: 1.3410 - val_auc: 0.8144\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.3352 - auc: 0.7555 - val_loss: 1.2778 - val_auc: 0.8224\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_33 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 2.0670 - auc: 0.5050 - val_loss: 1.9190 - val_auc: 0.6438\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.8880 - auc: 0.5853 - val_loss: 1.7965 - val_auc: 0.7123\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7665 - auc: 0.6505 - val_loss: 1.6788 - val_auc: 0.7539\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6507 - auc: 0.6884 - val_loss: 1.5666 - val_auc: 0.7830\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5413 - auc: 0.7181 - val_loss: 1.4612 - val_auc: 0.7990\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4386 - auc: 0.7392 - val_loss: 1.3625 - val_auc: 0.8099\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3427 - auc: 0.7527 - val_loss: 1.2706 - val_auc: 0.8235\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2535 - auc: 0.7644 - val_loss: 1.1851 - val_auc: 0.8279\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1706 - auc: 0.7737 - val_loss: 1.1059 - val_auc: 0.8323\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0939 - auc: 0.7810 - val_loss: 1.0326 - val_auc: 0.8354\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_36 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 2.0368 - auc: 0.5120 - val_loss: 1.8813 - val_auc: 0.6662\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.8336 - auc: 0.6145 - val_loss: 1.7250 - val_auc: 0.7399\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6791 - auc: 0.6800 - val_loss: 1.5762 - val_auc: 0.7774\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5352 - auc: 0.7184 - val_loss: 1.4389 - val_auc: 0.8009\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4028 - auc: 0.7436 - val_loss: 1.3132 - val_auc: 0.8176\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2820 - auc: 0.7589 - val_loss: 1.1989 - val_auc: 0.8266\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1723 - auc: 0.7717 - val_loss: 1.0953 - val_auc: 0.8320\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0731 - auc: 0.7812 - val_loss: 1.0017 - val_auc: 0.8350\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9835 - auc: 0.7877 - val_loss: 0.9174 - val_auc: 0.8404\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9029 - auc: 0.7949 - val_loss: 0.8416 - val_auc: 0.8416\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_39 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 2.0124 - auc: 0.5210 - val_loss: 1.8447 - val_auc: 0.6840\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.7803 - auc: 0.6354 - val_loss: 1.6556 - val_auc: 0.7610\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5956 - auc: 0.7016 - val_loss: 1.4796 - val_auc: 0.7952\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4278 - auc: 0.7379 - val_loss: 1.3218 - val_auc: 0.8175\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2775 - auc: 0.7591 - val_loss: 1.1813 - val_auc: 0.8275\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1442 - auc: 0.7727 - val_loss: 1.0570 - val_auc: 0.8334\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0266 - auc: 0.7837 - val_loss: 0.9477 - val_auc: 0.8398\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9231 - auc: 0.7931 - val_loss: 0.8517 - val_auc: 0.8428\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8325 - auc: 0.7990 - val_loss: 0.7677 - val_auc: 0.8432\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7532 - auc: 0.8052 - val_loss: 0.6945 - val_auc: 0.8449\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_42 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 1.9909 - auc: 0.5301 - val_loss: 1.8083 - val_auc: 0.6998\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.7284 - auc: 0.6592 - val_loss: 1.5881 - val_auc: 0.7783\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5161 - auc: 0.7201 - val_loss: 1.3891 - val_auc: 0.8095\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3282 - auc: 0.7510 - val_loss: 1.2149 - val_auc: 0.8236\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1646 - auc: 0.7715 - val_loss: 1.0643 - val_auc: 0.8345\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0235 - auc: 0.7824 - val_loss: 0.9348 - val_auc: 0.8376\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9025 - auc: 0.7930 - val_loss: 0.8242 - val_auc: 0.8423\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7992 - auc: 0.8005 - val_loss: 0.7299 - val_auc: 0.8438\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7113 - auc: 0.8060 - val_loss: 0.6498 - val_auc: 0.8446\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6367 - auc: 0.8094 - val_loss: 0.5819 - val_auc: 0.8483\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_45 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.9709 - auc: 0.5387 - val_loss: 1.7726 - val_auc: 0.7154\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6779 - auc: 0.6758 - val_loss: 1.5230 - val_auc: 0.7874\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.4406 - auc: 0.7321 - val_loss: 1.3043 - val_auc: 0.8161\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2362 - auc: 0.7625 - val_loss: 1.1177 - val_auc: 0.8309\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0632 - auc: 0.7788 - val_loss: 0.9609 - val_auc: 0.8379\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9182 - auc: 0.7897 - val_loss: 0.8301 - val_auc: 0.8402\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7975 - auc: 0.7992 - val_loss: 0.7214 - val_auc: 0.8457\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6973 - auc: 0.8050 - val_loss: 0.6315 - val_auc: 0.8474\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6146 - auc: 0.8098 - val_loss: 0.5573 - val_auc: 0.8486\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5464 - auc: 0.8134 - val_loss: 0.4964 - val_auc: 0.8493\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_48 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 1.9518 - auc: 0.5465 - val_loss: 1.7378 - val_auc: 0.7320\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.6290 - auc: 0.6884 - val_loss: 1.4607 - val_auc: 0.7984\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3690 - auc: 0.7421 - val_loss: 1.2250 - val_auc: 0.8247\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1514 - auc: 0.7708 - val_loss: 1.0296 - val_auc: 0.8341\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9724 - auc: 0.7838 - val_loss: 0.8699 - val_auc: 0.8405\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8267 - auc: 0.7955 - val_loss: 0.7405 - val_auc: 0.8432\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7088 - auc: 0.8031 - val_loss: 0.6361 - val_auc: 0.8468\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6138 - auc: 0.8092 - val_loss: 0.5522 - val_auc: 0.8480\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5377 - auc: 0.8133 - val_loss: 0.4851 - val_auc: 0.8485\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4768 - auc: 0.8168 - val_loss: 0.4316 - val_auc: 0.8515\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_51 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.9333 - auc: 0.5521 - val_loss: 1.7043 - val_auc: 0.7508\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.5815 - auc: 0.6993 - val_loss: 1.4013 - val_auc: 0.8099\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3014 - auc: 0.7507 - val_loss: 1.1512 - val_auc: 0.8284\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0735 - auc: 0.7759 - val_loss: 0.9498 - val_auc: 0.8379\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8913 - auc: 0.7898 - val_loss: 0.7899 - val_auc: 0.8425\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7472 - auc: 0.7999 - val_loss: 0.6640 - val_auc: 0.8448\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6340 - auc: 0.8068 - val_loss: 0.5654 - val_auc: 0.8472\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5455 - auc: 0.8126 - val_loss: 0.4885 - val_auc: 0.8494\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4766 - auc: 0.8162 - val_loss: 0.4288 - val_auc: 0.8494\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4232 - auc: 0.8188 - val_loss: 0.3826 - val_auc: 0.8501\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_54 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 1.9154 - auc: 0.5578 - val_loss: 1.6721 - val_auc: 0.7628\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5353 - auc: 0.7080 - val_loss: 1.3445 - val_auc: 0.8110\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.2374 - auc: 0.7575 - val_loss: 1.0825 - val_auc: 0.8322\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0018 - auc: 0.7808 - val_loss: 0.8776 - val_auc: 0.8404\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8189 - auc: 0.7946 - val_loss: 0.7196 - val_auc: 0.8434\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6784 - auc: 0.8028 - val_loss: 0.5987 - val_auc: 0.8472\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5711 - auc: 0.8093 - val_loss: 0.5068 - val_auc: 0.8497\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.8148 - val_loss: 0.4374 - val_auc: 0.8504\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4283 - auc: 0.8180 - val_loss: 0.3850 - val_auc: 0.8506\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3821 - auc: 0.8215 - val_loss: 0.3457 - val_auc: 0.8523\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_57 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 1.8979 - auc: 0.5617 - val_loss: 1.6409 - val_auc: 0.7730\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4905 - auc: 0.7141 - val_loss: 1.2905 - val_auc: 0.8193\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1770 - auc: 0.7636 - val_loss: 1.0187 - val_auc: 0.8360\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9361 - auc: 0.7852 - val_loss: 0.8124 - val_auc: 0.8415\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7544 - auc: 0.7973 - val_loss: 0.6578 - val_auc: 0.8454\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6188 - auc: 0.8055 - val_loss: 0.5431 - val_auc: 0.8490\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5184 - auc: 0.8120 - val_loss: 0.4584 - val_auc: 0.8504\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4444 - auc: 0.8163 - val_loss: 0.3963 - val_auc: 0.8511\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3902 - auc: 0.8200 - val_loss: 0.3509 - val_auc: 0.8517\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3505 - auc: 0.8233 - val_loss: 0.3178 - val_auc: 0.8534\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_60 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 1.8808 - auc: 0.5655 - val_loss: 1.6102 - val_auc: 0.7824\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.4470 - auc: 0.7222 - val_loss: 1.2388 - val_auc: 0.8239\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1200 - auc: 0.7673 - val_loss: 0.9593 - val_auc: 0.8371\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8758 - auc: 0.7880 - val_loss: 0.7534 - val_auc: 0.8436\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6969 - auc: 0.8002 - val_loss: 0.6036 - val_auc: 0.8476\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5673 - auc: 0.8077 - val_loss: 0.4957 - val_auc: 0.8488\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4741 - auc: 0.8145 - val_loss: 0.4184 - val_auc: 0.8510\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4075 - auc: 0.8185 - val_loss: 0.3634 - val_auc: 0.8511\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3601 - auc: 0.8219 - val_loss: 0.3244 - val_auc: 0.8532\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3264 - auc: 0.8255 - val_loss: 0.2968 - val_auc: 0.8532\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_63 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.8641 - auc: 0.5688 - val_loss: 1.5798 - val_auc: 0.7888\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.4048 - auc: 0.7299 - val_loss: 1.1892 - val_auc: 0.8272\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0663 - auc: 0.7713 - val_loss: 0.9040 - val_auc: 0.8388\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8206 - auc: 0.7909 - val_loss: 0.7000 - val_auc: 0.8458\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6458 - auc: 0.8030 - val_loss: 0.5560 - val_auc: 0.8490\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5228 - auc: 0.8100 - val_loss: 0.4553 - val_auc: 0.8491\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4370 - auc: 0.8160 - val_loss: 0.3854 - val_auc: 0.8506\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3775 - auc: 0.8198 - val_loss: 0.3371 - val_auc: 0.8528\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3363 - auc: 0.8235 - val_loss: 0.3038 - val_auc: 0.8531\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3079 - auc: 0.8267 - val_loss: 0.2809 - val_auc: 0.8529\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_66 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.8477 - auc: 0.5723 - val_loss: 1.5493 - val_auc: 0.7978\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3639 - auc: 0.7353 - val_loss: 1.1415 - val_auc: 0.8309\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0156 - auc: 0.7754 - val_loss: 0.8525 - val_auc: 0.8407\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7700 - auc: 0.7945 - val_loss: 0.6518 - val_auc: 0.8464\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6003 - auc: 0.8051 - val_loss: 0.5144 - val_auc: 0.8479\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4845 - auc: 0.8115 - val_loss: 0.4211 - val_auc: 0.8505\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4060 - auc: 0.8165 - val_loss: 0.3583 - val_auc: 0.8511\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3531 - auc: 0.8208 - val_loss: 0.3161 - val_auc: 0.8528\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3176 - auc: 0.8247 - val_loss: 0.2878 - val_auc: 0.8522\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2937 - auc: 0.8273 - val_loss: 0.2689 - val_auc: 0.8534\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_69 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.8316 - auc: 0.5742 - val_loss: 1.5185 - val_auc: 0.8005\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3242 - auc: 0.7391 - val_loss: 1.0957 - val_auc: 0.8326\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9679 - auc: 0.7777 - val_loss: 0.8046 - val_auc: 0.8425\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7237 - auc: 0.7961 - val_loss: 0.6084 - val_auc: 0.8467\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5600 - auc: 0.8065 - val_loss: 0.4780 - val_auc: 0.8483\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.4515 - auc: 0.8127 - val_loss: 0.3921 - val_auc: 0.8509\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3801 - auc: 0.8174 - val_loss: 0.3359 - val_auc: 0.8517\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3334 - auc: 0.8217 - val_loss: 0.2993 - val_auc: 0.8527\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3028 - auc: 0.8251 - val_loss: 0.2754 - val_auc: 0.8525\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2828 - auc: 0.8278 - val_loss: 0.2599 - val_auc: 0.8539\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_72 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.8157 - auc: 0.5771 - val_loss: 1.4877 - val_auc: 0.8035\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2859 - auc: 0.7434 - val_loss: 1.0517 - val_auc: 0.8332\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9230 - auc: 0.7800 - val_loss: 0.7602 - val_auc: 0.8420\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6815 - auc: 0.7980 - val_loss: 0.5694 - val_auc: 0.8471\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5242 - auc: 0.8073 - val_loss: 0.4463 - val_auc: 0.8482\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4231 - auc: 0.8137 - val_loss: 0.3676 - val_auc: 0.8501\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3585 - auc: 0.8192 - val_loss: 0.3176 - val_auc: 0.8525\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3173 - auc: 0.8230 - val_loss: 0.2859 - val_auc: 0.8528\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2912 - auc: 0.8258 - val_loss: 0.2658 - val_auc: 0.8527\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2745 - auc: 0.8287 - val_loss: 0.2531 - val_auc: 0.8548\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_75 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.8001 - auc: 0.5782 - val_loss: 1.4570 - val_auc: 0.8080\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.2488 - auc: 0.7475 - val_loss: 1.0097 - val_auc: 0.8341\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8807 - auc: 0.7825 - val_loss: 0.7191 - val_auc: 0.8429\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6428 - auc: 0.7988 - val_loss: 0.5343 - val_auc: 0.8475\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4925 - auc: 0.8077 - val_loss: 0.4186 - val_auc: 0.8495\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3987 - auc: 0.8146 - val_loss: 0.3468 - val_auc: 0.8506\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3404 - auc: 0.8199 - val_loss: 0.3025 - val_auc: 0.8525\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3044 - auc: 0.8232 - val_loss: 0.2752 - val_auc: 0.8523\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2820 - auc: 0.8264 - val_loss: 0.2584 - val_auc: 0.8537\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2680 - auc: 0.8299 - val_loss: 0.2479 - val_auc: 0.8546\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_78 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.7846 - auc: 0.5797 - val_loss: 1.4265 - val_auc: 0.8090\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.2130 - auc: 0.7507 - val_loss: 0.9697 - val_auc: 0.8361\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8410 - auc: 0.7846 - val_loss: 0.6811 - val_auc: 0.8456\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6076 - auc: 0.8004 - val_loss: 0.5029 - val_auc: 0.8483\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4645 - auc: 0.8092 - val_loss: 0.3946 - val_auc: 0.8496\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3777 - auc: 0.8149 - val_loss: 0.3293 - val_auc: 0.8516\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3254 - auc: 0.8202 - val_loss: 0.2902 - val_auc: 0.8521\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2938 - auc: 0.8235 - val_loss: 0.2667 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2747 - auc: 0.8272 - val_loss: 0.2526 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2630 - auc: 0.8299 - val_loss: 0.2439 - val_auc: 0.8547\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_81 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.7694 - auc: 0.5846 - val_loss: 1.3966 - val_auc: 0.8120\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1784 - auc: 0.7520 - val_loss: 0.9316 - val_auc: 0.8379\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8037 - auc: 0.7858 - val_loss: 0.6460 - val_auc: 0.8463\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5755 - auc: 0.8009 - val_loss: 0.4746 - val_auc: 0.8481\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4397 - auc: 0.8104 - val_loss: 0.3736 - val_auc: 0.8505\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3597 - auc: 0.8150 - val_loss: 0.3146 - val_auc: 0.8517\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3128 - auc: 0.8202 - val_loss: 0.2801 - val_auc: 0.8524\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2853 - auc: 0.8249 - val_loss: 0.2599 - val_auc: 0.8537\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2690 - auc: 0.8274 - val_loss: 0.2480 - val_auc: 0.8538\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2592 - auc: 0.8299 - val_loss: 0.2409 - val_auc: 0.8550\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_81 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_84 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.7544 - auc: 0.5870 - val_loss: 1.3674 - val_auc: 0.8122\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1451 - auc: 0.7558 - val_loss: 0.8956 - val_auc: 0.8396\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7687 - auc: 0.7875 - val_loss: 0.6136 - val_auc: 0.8460\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5463 - auc: 0.8022 - val_loss: 0.4494 - val_auc: 0.8486\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4178 - auc: 0.8106 - val_loss: 0.3555 - val_auc: 0.8506\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3443 - auc: 0.8161 - val_loss: 0.3021 - val_auc: 0.8517\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3024 - auc: 0.8211 - val_loss: 0.2718 - val_auc: 0.8539\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2784 - auc: 0.8248 - val_loss: 0.2545 - val_auc: 0.8533\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2645 - auc: 0.8270 - val_loss: 0.2445 - val_auc: 0.8548\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2562 - auc: 0.8303 - val_loss: 0.2385 - val_auc: 0.8553\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8223866454305357 0.00101\n",
      "[0.46315094453740857, 0.6573294893248119, 0.7297393197717787, 0.7592629180863291, 0.7749702626963166, 0.784640430636479, 0.7913711417108525, 0.7967520816112578, 0.8008467571218322, 0.8041128203060423, 0.8070200197576662, 0.8093234007378884, 0.8113626741396341, 0.8133223120501604, 0.8149230862281002, 0.8164875708151046, 0.8179351222757605, 0.8192092901352794, 0.8203483800729824, 0.8214259793149332, 0.8223866454305357]\n",
      "0.21075855046739903 0.00101\n",
      "[0.2830793096525834, 0.24273975242105916, 0.2323688878170496, 0.22619577195903895, 0.22221986260474094, 0.2195291494026408, 0.21764525890227648, 0.2163027371938866, 0.21532373346585187, 0.214571029797582, 0.21395196311359188, 0.2134174087640657, 0.2129456584870686, 0.21252743635492463, 0.21215785605448, 0.21183319763394043, 0.21154988492888588, 0.21130430579678955, 0.21109285668870742, 0.21091205359126805, 0.21075855046739903]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0.00001, 0.00106, 0.00005)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=i, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_87 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 1.7574 - auc: 0.5870 - val_loss: 1.3732 - val_auc: 0.8131\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.1517 - auc: 0.7554 - val_loss: 0.9026 - val_auc: 0.8398\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7755 - auc: 0.7873 - val_loss: 0.6198 - val_auc: 0.8467\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5519 - auc: 0.8020 - val_loss: 0.4542 - val_auc: 0.8487\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4220 - auc: 0.8105 - val_loss: 0.3589 - val_auc: 0.8507\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3472 - auc: 0.8156 - val_loss: 0.3044 - val_auc: 0.8518\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3043 - auc: 0.8210 - val_loss: 0.2733 - val_auc: 0.8539\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2797 - auc: 0.8249 - val_loss: 0.2555 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2653 - auc: 0.8269 - val_loss: 0.2451 - val_auc: 0.8540\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2567 - auc: 0.8301 - val_loss: 0.2390 - val_auc: 0.8553\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_90 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.7544 - auc: 0.5870 - val_loss: 1.3674 - val_auc: 0.8122\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1451 - auc: 0.7558 - val_loss: 0.8956 - val_auc: 0.8396\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7687 - auc: 0.7875 - val_loss: 0.6136 - val_auc: 0.8460\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5463 - auc: 0.8022 - val_loss: 0.4494 - val_auc: 0.8486\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4178 - auc: 0.8106 - val_loss: 0.3555 - val_auc: 0.8506\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3443 - auc: 0.8161 - val_loss: 0.3021 - val_auc: 0.8517\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3024 - auc: 0.8211 - val_loss: 0.2718 - val_auc: 0.8539\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2784 - auc: 0.8248 - val_loss: 0.2545 - val_auc: 0.8533\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2645 - auc: 0.8270 - val_loss: 0.2445 - val_auc: 0.8548\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2562 - auc: 0.8303 - val_loss: 0.2385 - val_auc: 0.8553\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_93 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.7514 - auc: 0.5879 - val_loss: 1.3617 - val_auc: 0.8141\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1386 - auc: 0.7557 - val_loss: 0.8886 - val_auc: 0.8404\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7620 - auc: 0.7883 - val_loss: 0.6074 - val_auc: 0.8457\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5408 - auc: 0.8023 - val_loss: 0.4446 - val_auc: 0.8486\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4138 - auc: 0.8106 - val_loss: 0.3521 - val_auc: 0.8506\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3415 - auc: 0.8162 - val_loss: 0.2999 - val_auc: 0.8517\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3005 - auc: 0.8216 - val_loss: 0.2703 - val_auc: 0.8538\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2772 - auc: 0.8244 - val_loss: 0.2535 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2637 - auc: 0.8269 - val_loss: 0.2439 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2557 - auc: 0.8301 - val_loss: 0.2381 - val_auc: 0.8545\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_96 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 1.7485 - auc: 0.5882 - val_loss: 1.3559 - val_auc: 0.8137\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 1.1321 - auc: 0.7554 - val_loss: 0.8816 - val_auc: 0.8404\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7553 - auc: 0.7882 - val_loss: 0.6013 - val_auc: 0.8458\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5354 - auc: 0.8027 - val_loss: 0.4400 - val_auc: 0.8487\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4098 - auc: 0.8108 - val_loss: 0.3489 - val_auc: 0.8506\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3388 - auc: 0.8166 - val_loss: 0.2977 - val_auc: 0.8517\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2987 - auc: 0.8209 - val_loss: 0.2689 - val_auc: 0.8537\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2760 - auc: 0.8243 - val_loss: 0.2526 - val_auc: 0.8537\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2629 - auc: 0.8269 - val_loss: 0.2433 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2552 - auc: 0.8300 - val_loss: 0.2378 - val_auc: 0.8542\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_99 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.7455 - auc: 0.5890 - val_loss: 1.3503 - val_auc: 0.8125\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1256 - auc: 0.7548 - val_loss: 0.8748 - val_auc: 0.8399\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7488 - auc: 0.7882 - val_loss: 0.5953 - val_auc: 0.8460\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5301 - auc: 0.8029 - val_loss: 0.4355 - val_auc: 0.8489\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4059 - auc: 0.8104 - val_loss: 0.3457 - val_auc: 0.8510\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3362 - auc: 0.8161 - val_loss: 0.2956 - val_auc: 0.8515\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2970 - auc: 0.8212 - val_loss: 0.2676 - val_auc: 0.8539\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2749 - auc: 0.8243 - val_loss: 0.2518 - val_auc: 0.8538\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2622 - auc: 0.8273 - val_loss: 0.2427 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2547 - auc: 0.8300 - val_loss: 0.2374 - val_auc: 0.8547\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_99 (Dense)             (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_102 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 1.7426 - auc: 0.5888 - val_loss: 1.3446 - val_auc: 0.8127\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1193 - auc: 0.7554 - val_loss: 0.8680 - val_auc: 0.8397\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7423 - auc: 0.7887 - val_loss: 0.5894 - val_auc: 0.8454\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5249 - auc: 0.8030 - val_loss: 0.4311 - val_auc: 0.8491\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4022 - auc: 0.8103 - val_loss: 0.3427 - val_auc: 0.8511\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3336 - auc: 0.8161 - val_loss: 0.2936 - val_auc: 0.8512\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2953 - auc: 0.8212 - val_loss: 0.2663 - val_auc: 0.8541\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2738 - auc: 0.8245 - val_loss: 0.2509 - val_auc: 0.8537\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2615 - auc: 0.8272 - val_loss: 0.2422 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2542 - auc: 0.8305 - val_loss: 0.2371 - val_auc: 0.8547\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_105 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 1.7396 - auc: 0.5892 - val_loss: 1.3390 - val_auc: 0.8126\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1129 - auc: 0.7558 - val_loss: 0.8613 - val_auc: 0.8398\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7359 - auc: 0.7892 - val_loss: 0.5836 - val_auc: 0.8458\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5197 - auc: 0.8034 - val_loss: 0.4268 - val_auc: 0.8495\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3985 - auc: 0.8101 - val_loss: 0.3397 - val_auc: 0.8511\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3311 - auc: 0.8161 - val_loss: 0.2916 - val_auc: 0.8513\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2937 - auc: 0.8213 - val_loss: 0.2650 - val_auc: 0.8541\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2728 - auc: 0.8244 - val_loss: 0.2501 - val_auc: 0.8537\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2608 - auc: 0.8271 - val_loss: 0.2417 - val_auc: 0.8547\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2538 - auc: 0.8305 - val_loss: 0.2367 - val_auc: 0.8546\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_108 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 1.7367 - auc: 0.5892 - val_loss: 1.3334 - val_auc: 0.8145\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.1066 - auc: 0.7565 - val_loss: 0.8547 - val_auc: 0.8401\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7296 - auc: 0.7894 - val_loss: 0.5779 - val_auc: 0.8461\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5147 - auc: 0.8036 - val_loss: 0.4226 - val_auc: 0.8494\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3949 - auc: 0.8102 - val_loss: 0.3368 - val_auc: 0.8519\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3287 - auc: 0.8161 - val_loss: 0.2897 - val_auc: 0.8519\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2922 - auc: 0.8215 - val_loss: 0.2638 - val_auc: 0.8546\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2718 - auc: 0.8246 - val_loss: 0.2494 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2602 - auc: 0.8274 - val_loss: 0.2412 - val_auc: 0.8547\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2534 - auc: 0.8305 - val_loss: 0.2364 - val_auc: 0.8546\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_108 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_111 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.7338 - auc: 0.5905 - val_loss: 1.3278 - val_auc: 0.8161\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1004 - auc: 0.7565 - val_loss: 0.8482 - val_auc: 0.8406\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7233 - auc: 0.7896 - val_loss: 0.5722 - val_auc: 0.8461\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5098 - auc: 0.8039 - val_loss: 0.4184 - val_auc: 0.8495\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3914 - auc: 0.8103 - val_loss: 0.3340 - val_auc: 0.8514\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3264 - auc: 0.8164 - val_loss: 0.2879 - val_auc: 0.8518\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2907 - auc: 0.8214 - val_loss: 0.2626 - val_auc: 0.8547\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2708 - auc: 0.8244 - val_loss: 0.2486 - val_auc: 0.8533\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2596 - auc: 0.8278 - val_loss: 0.2407 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2530 - auc: 0.8304 - val_loss: 0.2361 - val_auc: 0.8548\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_114 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 1.7309 - auc: 0.5905 - val_loss: 1.3223 - val_auc: 0.8177\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0942 - auc: 0.7571 - val_loss: 0.8417 - val_auc: 0.8402\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7172 - auc: 0.7897 - val_loss: 0.5667 - val_auc: 0.8463\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5050 - auc: 0.8033 - val_loss: 0.4144 - val_auc: 0.8494\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3880 - auc: 0.8103 - val_loss: 0.3313 - val_auc: 0.8513\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3242 - auc: 0.8160 - val_loss: 0.2861 - val_auc: 0.8520\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2892 - auc: 0.8214 - val_loss: 0.2615 - val_auc: 0.8546\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2699 - auc: 0.8244 - val_loss: 0.2479 - val_auc: 0.8532\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2590 - auc: 0.8279 - val_loss: 0.2403 - val_auc: 0.8543\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2527 - auc: 0.8306 - val_loss: 0.2358 - val_auc: 0.8547\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_117 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.7280 - auc: 0.5910 - val_loss: 1.3168 - val_auc: 0.8176\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0880 - auc: 0.7572 - val_loss: 0.8353 - val_auc: 0.8398\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7111 - auc: 0.7899 - val_loss: 0.5613 - val_auc: 0.8464\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5003 - auc: 0.8033 - val_loss: 0.4104 - val_auc: 0.8499\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3847 - auc: 0.8105 - val_loss: 0.3286 - val_auc: 0.8508\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3220 - auc: 0.8160 - val_loss: 0.2844 - val_auc: 0.8521\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2878 - auc: 0.8213 - val_loss: 0.2604 - val_auc: 0.8545\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2690 - auc: 0.8244 - val_loss: 0.2473 - val_auc: 0.8531\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2585 - auc: 0.8278 - val_loss: 0.2399 - val_auc: 0.8541\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2523 - auc: 0.8304 - val_loss: 0.2356 - val_auc: 0.8546\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_117 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_120 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 1.7251 - auc: 0.5918 - val_loss: 1.3113 - val_auc: 0.8161\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0819 - auc: 0.7571 - val_loss: 0.8289 - val_auc: 0.8396\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7051 - auc: 0.7905 - val_loss: 0.5559 - val_auc: 0.8465\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4956 - auc: 0.8031 - val_loss: 0.4066 - val_auc: 0.8499\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3815 - auc: 0.8107 - val_loss: 0.3260 - val_auc: 0.8508\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3199 - auc: 0.8158 - val_loss: 0.2828 - val_auc: 0.8521\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2865 - auc: 0.8213 - val_loss: 0.2594 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2682 - auc: 0.8243 - val_loss: 0.2466 - val_auc: 0.8530\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2579 - auc: 0.8278 - val_loss: 0.2395 - val_auc: 0.8542\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2520 - auc: 0.8304 - val_loss: 0.2353 - val_auc: 0.8547\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_123 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 38ms/step - loss: 1.7222 - auc: 0.5928 - val_loss: 1.3059 - val_auc: 0.8131\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0758 - auc: 0.7575 - val_loss: 0.8226 - val_auc: 0.8405\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6992 - auc: 0.7909 - val_loss: 0.5506 - val_auc: 0.8459\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.8028 - val_loss: 0.4028 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3783 - auc: 0.8108 - val_loss: 0.3235 - val_auc: 0.8511\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3178 - auc: 0.8158 - val_loss: 0.2812 - val_auc: 0.8521\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2852 - auc: 0.8213 - val_loss: 0.2584 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2674 - auc: 0.8248 - val_loss: 0.2460 - val_auc: 0.8531\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2574 - auc: 0.8277 - val_loss: 0.2391 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2516 - auc: 0.8306 - val_loss: 0.2351 - val_auc: 0.8546\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_123 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_126 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 25ms/step - loss: 1.7193 - auc: 0.5927 - val_loss: 1.3005 - val_auc: 0.8140\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0698 - auc: 0.7585 - val_loss: 0.8164 - val_auc: 0.8405\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6934 - auc: 0.7911 - val_loss: 0.5455 - val_auc: 0.8463\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4866 - auc: 0.8028 - val_loss: 0.3991 - val_auc: 0.8501\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3753 - auc: 0.8105 - val_loss: 0.3211 - val_auc: 0.8509\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3158 - auc: 0.8159 - val_loss: 0.2796 - val_auc: 0.8532\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2839 - auc: 0.8214 - val_loss: 0.2575 - val_auc: 0.8538\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2666 - auc: 0.8250 - val_loss: 0.2454 - val_auc: 0.8529\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2569 - auc: 0.8277 - val_loss: 0.2387 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2513 - auc: 0.8307 - val_loss: 0.2348 - val_auc: 0.8546\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_126 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_129 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.7164 - auc: 0.5934 - val_loss: 1.2952 - val_auc: 0.8144\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0638 - auc: 0.7583 - val_loss: 0.8103 - val_auc: 0.8407\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6876 - auc: 0.7911 - val_loss: 0.5404 - val_auc: 0.8466\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4822 - auc: 0.8029 - val_loss: 0.3955 - val_auc: 0.8501\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3723 - auc: 0.8107 - val_loss: 0.3187 - val_auc: 0.8508\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3139 - auc: 0.8158 - val_loss: 0.2781 - val_auc: 0.8533\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2827 - auc: 0.8213 - val_loss: 0.2565 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2659 - auc: 0.8251 - val_loss: 0.2449 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2565 - auc: 0.8277 - val_loss: 0.2384 - val_auc: 0.8544\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2510 - auc: 0.8305 - val_loss: 0.2346 - val_auc: 0.8547\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_129 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_132 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 34ms/step - loss: 1.7136 - auc: 0.5925 - val_loss: 1.2898 - val_auc: 0.8163\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0579 - auc: 0.7590 - val_loss: 0.8042 - val_auc: 0.8415\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6820 - auc: 0.7914 - val_loss: 0.5353 - val_auc: 0.8467\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4779 - auc: 0.8028 - val_loss: 0.3920 - val_auc: 0.8500\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3694 - auc: 0.8107 - val_loss: 0.3164 - val_auc: 0.8508\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3120 - auc: 0.8158 - val_loss: 0.2767 - val_auc: 0.8535\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2816 - auc: 0.8213 - val_loss: 0.2556 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2652 - auc: 0.8250 - val_loss: 0.2443 - val_auc: 0.8542\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2560 - auc: 0.8277 - val_loss: 0.2380 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2508 - auc: 0.8302 - val_loss: 0.2344 - val_auc: 0.8546\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_132 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_135 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 1.7107 - auc: 0.5930 - val_loss: 1.2845 - val_auc: 0.8170\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0520 - auc: 0.7586 - val_loss: 0.7982 - val_auc: 0.8420\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6764 - auc: 0.7914 - val_loss: 0.5304 - val_auc: 0.8468\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4737 - auc: 0.8025 - val_loss: 0.3885 - val_auc: 0.8500\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3665 - auc: 0.8107 - val_loss: 0.3142 - val_auc: 0.8508\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3102 - auc: 0.8155 - val_loss: 0.2753 - val_auc: 0.8533\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2804 - auc: 0.8210 - val_loss: 0.2548 - val_auc: 0.8537\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2645 - auc: 0.8251 - val_loss: 0.2438 - val_auc: 0.8540\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2556 - auc: 0.8276 - val_loss: 0.2377 - val_auc: 0.8547\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2505 - auc: 0.8303 - val_loss: 0.2342 - val_auc: 0.8548\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_138 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 1.7079 - auc: 0.5937 - val_loss: 1.2793 - val_auc: 0.8169\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0462 - auc: 0.7598 - val_loss: 0.7922 - val_auc: 0.8416\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6708 - auc: 0.7916 - val_loss: 0.5256 - val_auc: 0.8468\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4696 - auc: 0.8026 - val_loss: 0.3852 - val_auc: 0.8499\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3637 - auc: 0.8108 - val_loss: 0.3120 - val_auc: 0.8507\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3084 - auc: 0.8157 - val_loss: 0.2739 - val_auc: 0.8536\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2794 - auc: 0.8210 - val_loss: 0.2540 - val_auc: 0.8536\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2638 - auc: 0.8249 - val_loss: 0.2433 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2552 - auc: 0.8278 - val_loss: 0.2374 - val_auc: 0.8543\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2502 - auc: 0.8302 - val_loss: 0.2340 - val_auc: 0.8544\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_138 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_141 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 1.7051 - auc: 0.5943 - val_loss: 1.2740 - val_auc: 0.8181\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 1.0404 - auc: 0.7602 - val_loss: 0.7863 - val_auc: 0.8418\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6654 - auc: 0.7920 - val_loss: 0.5208 - val_auc: 0.8469\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4655 - auc: 0.8029 - val_loss: 0.3819 - val_auc: 0.8498\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3610 - auc: 0.8105 - val_loss: 0.3099 - val_auc: 0.8507\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3067 - auc: 0.8161 - val_loss: 0.2726 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2783 - auc: 0.8209 - val_loss: 0.2532 - val_auc: 0.8535\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2632 - auc: 0.8249 - val_loss: 0.2428 - val_auc: 0.8542\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2548 - auc: 0.8278 - val_loss: 0.2371 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2500 - auc: 0.8303 - val_loss: 0.2338 - val_auc: 0.8547\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_141 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_144 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.7023 - auc: 0.5953 - val_loss: 1.2688 - val_auc: 0.8188\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0346 - auc: 0.7604 - val_loss: 0.7805 - val_auc: 0.8413\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6600 - auc: 0.7920 - val_loss: 0.5161 - val_auc: 0.8467\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4616 - auc: 0.8031 - val_loss: 0.3787 - val_auc: 0.8499\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3584 - auc: 0.8105 - val_loss: 0.3078 - val_auc: 0.8506\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3051 - auc: 0.8161 - val_loss: 0.2714 - val_auc: 0.8543\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2773 - auc: 0.8210 - val_loss: 0.2524 - val_auc: 0.8534\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2626 - auc: 0.8250 - val_loss: 0.2424 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2544 - auc: 0.8282 - val_loss: 0.2368 - val_auc: 0.8546\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2498 - auc: 0.8300 - val_loss: 0.2336 - val_auc: 0.8547\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_144 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8255640007257918 0.0011900000000000005\n",
      "[0.8221870526803896, 0.8223866454305357, 0.8225721255619847, 0.8228039757262959, 0.8229934880345154, 0.8232132416685147, 0.823380577004496, 0.8235731134452934, 0.8237233120299995, 0.8239067760730631, 0.8240741114090442, 0.8242353984798694, 0.8244087820810063, 0.8245962783008407, 0.8248059514929135, 0.8249531259450413, 0.8250781234249309, 0.825254531158646, 0.8254168262736639, 0.8255640007257918]\n",
      "0.21038442612714983 0.0011900000000000005\n",
      "[0.21078722318954607, 0.21075855046739903, 0.2107308350262103, 0.21070406391173116, 0.21067819993847248, 0.21065323373017655, 0.2106291264864551, 0.21060586359029634, 0.2105834229198398, 0.21056177682832147, 0.21054090699973074, 0.21052078918529957, 0.21050140236403592, 0.2104827256868531, 0.21046473414050984, 0.2104474143086354, 0.210430746071224, 0.21041470010122107, 0.21039926445524879, 0.21038442612714983]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0.001, 0.0012, 0.00001)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=i, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_147 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 1.6994 - auc: 0.5955 - val_loss: 1.2636 - val_auc: 0.8201\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0289 - auc: 0.7602 - val_loss: 0.7747 - val_auc: 0.8411\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6547 - auc: 0.7924 - val_loss: 0.5115 - val_auc: 0.8470\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4577 - auc: 0.8030 - val_loss: 0.3755 - val_auc: 0.8499\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3558 - auc: 0.8105 - val_loss: 0.3058 - val_auc: 0.8513\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3035 - auc: 0.8161 - val_loss: 0.2702 - val_auc: 0.8543\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2763 - auc: 0.8213 - val_loss: 0.2517 - val_auc: 0.8535\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2620 - auc: 0.8250 - val_loss: 0.2419 - val_auc: 0.8540\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2541 - auc: 0.8281 - val_loss: 0.2365 - val_auc: 0.8547\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2495 - auc: 0.8300 - val_loss: 0.2335 - val_auc: 0.8546\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_147 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_150 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.6966 - auc: 0.5959 - val_loss: 1.2585 - val_auc: 0.8180\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0232 - auc: 0.7605 - val_loss: 0.7690 - val_auc: 0.8409\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.6494 - auc: 0.7927 - val_loss: 0.5069 - val_auc: 0.8473\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4538 - auc: 0.8025 - val_loss: 0.3724 - val_auc: 0.8498\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3533 - auc: 0.8107 - val_loss: 0.3039 - val_auc: 0.8515\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3019 - auc: 0.8162 - val_loss: 0.2690 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2754 - auc: 0.8212 - val_loss: 0.2510 - val_auc: 0.8534\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2614 - auc: 0.8248 - val_loss: 0.2415 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2537 - auc: 0.8282 - val_loss: 0.2363 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2493 - auc: 0.8302 - val_loss: 0.2333 - val_auc: 0.8546\n",
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_150 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_153 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.6939 - auc: 0.5963 - val_loss: 1.2534 - val_auc: 0.8170\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0176 - auc: 0.7609 - val_loss: 0.7634 - val_auc: 0.8415\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6443 - auc: 0.7925 - val_loss: 0.5025 - val_auc: 0.8473\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4501 - auc: 0.8025 - val_loss: 0.3694 - val_auc: 0.8501\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3509 - auc: 0.8108 - val_loss: 0.3020 - val_auc: 0.8516\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3004 - auc: 0.8164 - val_loss: 0.2678 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2745 - auc: 0.8213 - val_loss: 0.2503 - val_auc: 0.8534\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2609 - auc: 0.8250 - val_loss: 0.2411 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2534 - auc: 0.8281 - val_loss: 0.2360 - val_auc: 0.8544\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.8301 - val_loss: 0.2331 - val_auc: 0.8546\n",
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_153 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_156 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 1.6911 - auc: 0.5972 - val_loss: 1.2483 - val_auc: 0.8175\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.0120 - auc: 0.7609 - val_loss: 0.7578 - val_auc: 0.8417\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6392 - auc: 0.7926 - val_loss: 0.4981 - val_auc: 0.8473\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4464 - auc: 0.8026 - val_loss: 0.3665 - val_auc: 0.8503\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3485 - auc: 0.8109 - val_loss: 0.3002 - val_auc: 0.8515\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2990 - auc: 0.8163 - val_loss: 0.2667 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2736 - auc: 0.8214 - val_loss: 0.2497 - val_auc: 0.8533\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2603 - auc: 0.8250 - val_loss: 0.2407 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2531 - auc: 0.8282 - val_loss: 0.2358 - val_auc: 0.8546\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2489 - auc: 0.8301 - val_loss: 0.2330 - val_auc: 0.8543\n",
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_156 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_159 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.6883 - auc: 0.5971 - val_loss: 1.2432 - val_auc: 0.8178\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0064 - auc: 0.7618 - val_loss: 0.7522 - val_auc: 0.8414\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6341 - auc: 0.7924 - val_loss: 0.4938 - val_auc: 0.8474\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4428 - auc: 0.8025 - val_loss: 0.3636 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3462 - auc: 0.8110 - val_loss: 0.2984 - val_auc: 0.8513\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2975 - auc: 0.8163 - val_loss: 0.2657 - val_auc: 0.8537\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2728 - auc: 0.8214 - val_loss: 0.2490 - val_auc: 0.8531\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2598 - auc: 0.8247 - val_loss: 0.2403 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2528 - auc: 0.8280 - val_loss: 0.2356 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8297 - val_loss: 0.2329 - val_auc: 0.8542\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_159 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_162 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.6855 - auc: 0.5979 - val_loss: 1.2382 - val_auc: 0.8186\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0009 - auc: 0.7617 - val_loss: 0.7468 - val_auc: 0.8425\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6292 - auc: 0.7925 - val_loss: 0.4895 - val_auc: 0.8477\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4393 - auc: 0.8029 - val_loss: 0.3608 - val_auc: 0.8501\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3439 - auc: 0.8109 - val_loss: 0.2966 - val_auc: 0.8512\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2962 - auc: 0.8163 - val_loss: 0.2646 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2720 - auc: 0.8211 - val_loss: 0.2484 - val_auc: 0.8531\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2578 - auc: 0.819 - 0s 3ms/step - loss: 0.2594 - auc: 0.8247 - val_loss: 0.2400 - val_auc: 0.8540\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2525 - auc: 0.8282 - val_loss: 0.2354 - val_auc: 0.8544\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.8296 - val_loss: 0.2327 - val_auc: 0.8536\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_162 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_165 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.6828 - auc: 0.5981 - val_loss: 1.2332 - val_auc: 0.8175\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9955 - auc: 0.7618 - val_loss: 0.7413 - val_auc: 0.8424\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6243 - auc: 0.7926 - val_loss: 0.4854 - val_auc: 0.8481\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4358 - auc: 0.8029 - val_loss: 0.3580 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3417 - auc: 0.8105 - val_loss: 0.2950 - val_auc: 0.8512\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2948 - auc: 0.8165 - val_loss: 0.2637 - val_auc: 0.8537\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2712 - auc: 0.8210 - val_loss: 0.2478 - val_auc: 0.8532\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2589 - auc: 0.8246 - val_loss: 0.2396 - val_auc: 0.8544\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2522 - auc: 0.8281 - val_loss: 0.2351 - val_auc: 0.8542\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.8296 - val_loss: 0.2326 - val_auc: 0.8535\n",
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_165 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_168 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.6800 - auc: 0.5982 - val_loss: 1.2282 - val_auc: 0.8183\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9900 - auc: 0.7620 - val_loss: 0.7360 - val_auc: 0.8426\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6195 - auc: 0.7926 - val_loss: 0.4813 - val_auc: 0.8482\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4324 - auc: 0.8029 - val_loss: 0.3554 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3396 - auc: 0.8105 - val_loss: 0.2933 - val_auc: 0.8514\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2936 - auc: 0.8165 - val_loss: 0.2627 - val_auc: 0.8536\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2704 - auc: 0.8210 - val_loss: 0.2473 - val_auc: 0.8532\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2606 - auc: 0.826 - 0s 5ms/step - loss: 0.2585 - auc: 0.8246 - val_loss: 0.2393 - val_auc: 0.8543\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2520 - auc: 0.8278 - val_loss: 0.2349 - val_auc: 0.8541\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8297 - val_loss: 0.2325 - val_auc: 0.8536\n",
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_168 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_171 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.6773 - auc: 0.5978 - val_loss: 1.2233 - val_auc: 0.8194\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9846 - auc: 0.7620 - val_loss: 0.7306 - val_auc: 0.8435\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6147 - auc: 0.7925 - val_loss: 0.4772 - val_auc: 0.8483\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4291 - auc: 0.8027 - val_loss: 0.3527 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3375 - auc: 0.8104 - val_loss: 0.2917 - val_auc: 0.8514\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2923 - auc: 0.8164 - val_loss: 0.2618 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2697 - auc: 0.8209 - val_loss: 0.2467 - val_auc: 0.8531\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2580 - auc: 0.8246 - val_loss: 0.2390 - val_auc: 0.8543\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.8276 - val_loss: 0.2348 - val_auc: 0.8535\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.8300 - val_loss: 0.2323 - val_auc: 0.8533\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_171 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_174 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.6746 - auc: 0.5986 - val_loss: 1.2184 - val_auc: 0.8206\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9793 - auc: 0.7616 - val_loss: 0.7254 - val_auc: 0.8434\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6100 - auc: 0.7922 - val_loss: 0.4733 - val_auc: 0.8486\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4258 - auc: 0.8030 - val_loss: 0.3502 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3354 - auc: 0.8102 - val_loss: 0.2902 - val_auc: 0.8513\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2911 - auc: 0.8167 - val_loss: 0.2609 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2690 - auc: 0.8212 - val_loss: 0.2462 - val_auc: 0.8530\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2576 - auc: 0.8243 - val_loss: 0.2387 - val_auc: 0.8543\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2515 - auc: 0.8276 - val_loss: 0.2346 - val_auc: 0.8534\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2479 - auc: 0.8300 - val_loss: 0.2322 - val_auc: 0.8533\n",
      "Model: \"sequential_58\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_174 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_177 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.6719 - auc: 0.5985 - val_loss: 1.2135 - val_auc: 0.8211\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9740 - auc: 0.7629 - val_loss: 0.7202 - val_auc: 0.8438\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6054 - auc: 0.7918 - val_loss: 0.4694 - val_auc: 0.8488\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4226 - auc: 0.8032 - val_loss: 0.3477 - val_auc: 0.8506\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3334 - auc: 0.8100 - val_loss: 0.2887 - val_auc: 0.8524\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2899 - auc: 0.8169 - val_loss: 0.2600 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2683 - auc: 0.8212 - val_loss: 0.2457 - val_auc: 0.8534\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2572 - auc: 0.8243 - val_loss: 0.2384 - val_auc: 0.8543\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.8274 - val_loss: 0.2344 - val_auc: 0.8535\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2478 - auc: 0.8296 - val_loss: 0.2321 - val_auc: 0.8534\n",
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_177 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_180 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.6692 - auc: 0.5984 - val_loss: 1.2086 - val_auc: 0.8208\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9687 - auc: 0.7634 - val_loss: 0.7150 - val_auc: 0.8441\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.6008 - auc: 0.7915 - val_loss: 0.4655 - val_auc: 0.8489\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4195 - auc: 0.8030 - val_loss: 0.3452 - val_auc: 0.8500\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3315 - auc: 0.8107 - val_loss: 0.2872 - val_auc: 0.8525\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2888 - auc: 0.8169 - val_loss: 0.2591 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2677 - auc: 0.8214 - val_loss: 0.2452 - val_auc: 0.8534\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2568 - auc: 0.8242 - val_loss: 0.2381 - val_auc: 0.8543\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2510 - auc: 0.8274 - val_loss: 0.2342 - val_auc: 0.8534\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.8294 - val_loss: 0.2320 - val_auc: 0.8540\n",
      "Model: \"sequential_60\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_183 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 1.6665 - auc: 0.5992 - val_loss: 1.2038 - val_auc: 0.8193\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9635 - auc: 0.7640 - val_loss: 0.7099 - val_auc: 0.8442\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5963 - auc: 0.7916 - val_loss: 0.4618 - val_auc: 0.8487\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4164 - auc: 0.8029 - val_loss: 0.3428 - val_auc: 0.8500\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3296 - auc: 0.8108 - val_loss: 0.2858 - val_auc: 0.8525\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2877 - auc: 0.8169 - val_loss: 0.2583 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2670 - auc: 0.8212 - val_loss: 0.2448 - val_auc: 0.8534\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2565 - auc: 0.8244 - val_loss: 0.2378 - val_auc: 0.8546\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2508 - auc: 0.8272 - val_loss: 0.2341 - val_auc: 0.8533\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2475 - auc: 0.8296 - val_loss: 0.2319 - val_auc: 0.8541\n",
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_183 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_186 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.6638 - auc: 0.5996 - val_loss: 1.1990 - val_auc: 0.8189\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9583 - auc: 0.7647 - val_loss: 0.7048 - val_auc: 0.8443\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5919 - auc: 0.7919 - val_loss: 0.4581 - val_auc: 0.8488\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4134 - auc: 0.8032 - val_loss: 0.3405 - val_auc: 0.8500\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3278 - auc: 0.8109 - val_loss: 0.2844 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2866 - auc: 0.8166 - val_loss: 0.2575 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2664 - auc: 0.8211 - val_loss: 0.2443 - val_auc: 0.8532\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2561 - auc: 0.8243 - val_loss: 0.2375 - val_auc: 0.8546\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.8271 - val_loss: 0.2339 - val_auc: 0.8533\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2474 - auc: 0.8297 - val_loss: 0.2318 - val_auc: 0.8541\n",
      "Model: \"sequential_62\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_186 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_189 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 1.6611 - auc: 0.6003 - val_loss: 1.1942 - val_auc: 0.8198\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9532 - auc: 0.7647 - val_loss: 0.6998 - val_auc: 0.8441\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5875 - auc: 0.7921 - val_loss: 0.4544 - val_auc: 0.8488\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4104 - auc: 0.8030 - val_loss: 0.3382 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3260 - auc: 0.8107 - val_loss: 0.2831 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2856 - auc: 0.8164 - val_loss: 0.2568 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2658 - auc: 0.8205 - val_loss: 0.2439 - val_auc: 0.8542\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2558 - auc: 0.8240 - val_loss: 0.2373 - val_auc: 0.8545\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.8269 - val_loss: 0.2337 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2472 - auc: 0.8296 - val_loss: 0.2317 - val_auc: 0.8539\n",
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_189 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_192 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.6584 - auc: 0.6000 - val_loss: 1.1895 - val_auc: 0.8204\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9480 - auc: 0.7643 - val_loss: 0.6949 - val_auc: 0.8441\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5831 - auc: 0.7919 - val_loss: 0.4509 - val_auc: 0.8489\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4075 - auc: 0.8026 - val_loss: 0.3359 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3242 - auc: 0.8108 - val_loss: 0.2818 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2846 - auc: 0.8163 - val_loss: 0.2560 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2653 - auc: 0.8206 - val_loss: 0.2434 - val_auc: 0.8544\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2555 - auc: 0.8240 - val_loss: 0.2370 - val_auc: 0.8546\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.8264 - val_loss: 0.2336 - val_auc: 0.8541\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8296 - val_loss: 0.2316 - val_auc: 0.8539\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_192 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_195 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.6558 - auc: 0.6009 - val_loss: 1.1847 - val_auc: 0.8200\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9430 - auc: 0.7637 - val_loss: 0.6899 - val_auc: 0.8444\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5789 - auc: 0.7915 - val_loss: 0.4473 - val_auc: 0.8488\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4047 - auc: 0.8027 - val_loss: 0.3337 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3225 - auc: 0.8115 - val_loss: 0.2805 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2836 - auc: 0.8162 - val_loss: 0.2553 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2647 - auc: 0.8205 - val_loss: 0.2430 - val_auc: 0.8545\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2551 - auc: 0.8241 - val_loss: 0.2368 - val_auc: 0.8546\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.8264 - val_loss: 0.2335 - val_auc: 0.8540\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.8294 - val_loss: 0.2315 - val_auc: 0.8547\n",
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_195 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_198 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.6531 - auc: 0.6010 - val_loss: 1.1800 - val_auc: 0.8200\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9379 - auc: 0.7642 - val_loss: 0.6851 - val_auc: 0.8447\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5747 - auc: 0.7918 - val_loss: 0.4439 - val_auc: 0.8488\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4019 - auc: 0.8029 - val_loss: 0.3316 - val_auc: 0.8506\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3208 - auc: 0.8112 - val_loss: 0.2793 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2826 - auc: 0.8164 - val_loss: 0.2546 - val_auc: 0.8544\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2642 - auc: 0.8203 - val_loss: 0.2426 - val_auc: 0.8544\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2548 - auc: 0.8239 - val_loss: 0.2366 - val_auc: 0.8546\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8265 - val_loss: 0.2333 - val_auc: 0.8540\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.8294 - val_loss: 0.2314 - val_auc: 0.8546\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_198 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_201 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.6505 - auc: 0.6012 - val_loss: 1.1753 - val_auc: 0.8200\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9329 - auc: 0.7644 - val_loss: 0.6803 - val_auc: 0.8449\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5705 - auc: 0.7921 - val_loss: 0.4405 - val_auc: 0.8488\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3991 - auc: 0.8029 - val_loss: 0.3295 - val_auc: 0.8506\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3192 - auc: 0.8111 - val_loss: 0.2781 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2817 - auc: 0.8166 - val_loss: 0.2539 - val_auc: 0.8542\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2637 - auc: 0.8204 - val_loss: 0.2423 - val_auc: 0.8537\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2545 - auc: 0.8239 - val_loss: 0.2364 - val_auc: 0.8545\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.8264 - val_loss: 0.2332 - val_auc: 0.8540\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8293 - val_loss: 0.2314 - val_auc: 0.8546\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_201 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_204 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.6479 - auc: 0.6010 - val_loss: 1.1707 - val_auc: 0.8209\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9280 - auc: 0.7643 - val_loss: 0.6755 - val_auc: 0.8450\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5664 - auc: 0.7919 - val_loss: 0.4371 - val_auc: 0.8483\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3964 - auc: 0.8031 - val_loss: 0.3274 - val_auc: 0.8508\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3176 - auc: 0.8109 - val_loss: 0.2769 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2808 - auc: 0.8164 - val_loss: 0.2533 - val_auc: 0.8542\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2632 - auc: 0.8199 - val_loss: 0.2419 - val_auc: 0.8537\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2543 - auc: 0.8238 - val_loss: 0.2361 - val_auc: 0.8542\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2495 - auc: 0.8265 - val_loss: 0.2331 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2467 - auc: 0.8293 - val_loss: 0.2313 - val_auc: 0.8545\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_204 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_207 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.6452 - auc: 0.6007 - val_loss: 1.1660 - val_auc: 0.8202\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9231 - auc: 0.7646 - val_loss: 0.6708 - val_auc: 0.8441\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5624 - auc: 0.7918 - val_loss: 0.4339 - val_auc: 0.8486\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3938 - auc: 0.8032 - val_loss: 0.3254 - val_auc: 0.8508\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3161 - auc: 0.8107 - val_loss: 0.2758 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2800 - auc: 0.8162 - val_loss: 0.2526 - val_auc: 0.8542\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2627 - auc: 0.8199 - val_loss: 0.2415 - val_auc: 0.8538\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2540 - auc: 0.8238 - val_loss: 0.2359 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2493 - auc: 0.8263 - val_loss: 0.2329 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.8292 - val_loss: 0.2312 - val_auc: 0.8545\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_207 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_210 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.6426 - auc: 0.6016 - val_loss: 1.1614 - val_auc: 0.8205\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9182 - auc: 0.7655 - val_loss: 0.6661 - val_auc: 0.8442\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5584 - auc: 0.7918 - val_loss: 0.4306 - val_auc: 0.8486\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3912 - auc: 0.8031 - val_loss: 0.3235 - val_auc: 0.8508\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3146 - auc: 0.8106 - val_loss: 0.2747 - val_auc: 0.8535\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2791 - auc: 0.8160 - val_loss: 0.2520 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2622 - auc: 0.8199 - val_loss: 0.2412 - val_auc: 0.8537\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2537 - auc: 0.8238 - val_loss: 0.2357 - val_auc: 0.8540\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.8260 - val_loss: 0.2328 - val_auc: 0.8541\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2465 - auc: 0.8290 - val_loss: 0.2311 - val_auc: 0.8543\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_210 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_213 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.6400 - auc: 0.6013 - val_loss: 1.1569 - val_auc: 0.8210\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9133 - auc: 0.7659 - val_loss: 0.6614 - val_auc: 0.8442\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5545 - auc: 0.7918 - val_loss: 0.4275 - val_auc: 0.8486\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3887 - auc: 0.8030 - val_loss: 0.3216 - val_auc: 0.8509\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3131 - auc: 0.8107 - val_loss: 0.2736 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2783 - auc: 0.8160 - val_loss: 0.2514 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2618 - auc: 0.8200 - val_loss: 0.2409 - val_auc: 0.8544\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2535 - auc: 0.8235 - val_loss: 0.2355 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8256 - val_loss: 0.2327 - val_auc: 0.8540\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.8293 - val_loss: 0.2311 - val_auc: 0.8541\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_213 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_216 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 1.6374 - auc: 0.6024 - val_loss: 1.1523 - val_auc: 0.8215\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.9085 - auc: 0.7668 - val_loss: 0.6569 - val_auc: 0.8446\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5506 - auc: 0.7917 - val_loss: 0.4243 - val_auc: 0.8493\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3862 - auc: 0.8030 - val_loss: 0.3197 - val_auc: 0.8510\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3117 - auc: 0.8101 - val_loss: 0.2725 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2775 - auc: 0.8160 - val_loss: 0.2509 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.8199 - val_loss: 0.2405 - val_auc: 0.8544\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2532 - auc: 0.8234 - val_loss: 0.2354 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2489 - auc: 0.8256 - val_loss: 0.2326 - val_auc: 0.8540\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2463 - auc: 0.8294 - val_loss: 0.2310 - val_auc: 0.8540\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_216 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_219 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.6348 - auc: 0.6026 - val_loss: 1.1478 - val_auc: 0.8206\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.9038 - auc: 0.7671 - val_loss: 0.6523 - val_auc: 0.8444\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5468 - auc: 0.7917 - val_loss: 0.4213 - val_auc: 0.8492\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3838 - auc: 0.8030 - val_loss: 0.3179 - val_auc: 0.8510\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3103 - auc: 0.8103 - val_loss: 0.2715 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2767 - auc: 0.8159 - val_loss: 0.2503 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2609 - auc: 0.8203 - val_loss: 0.2402 - val_auc: 0.8545\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2530 - auc: 0.8229 - val_loss: 0.2352 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8260 - val_loss: 0.2325 - val_auc: 0.8540\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2463 - auc: 0.8293 - val_loss: 0.2309 - val_auc: 0.8540\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_219 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_222 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.6323 - auc: 0.6029 - val_loss: 1.1433 - val_auc: 0.8214\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8990 - auc: 0.7675 - val_loss: 0.6478 - val_auc: 0.8445\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5431 - auc: 0.7920 - val_loss: 0.4182 - val_auc: 0.8492\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3814 - auc: 0.8030 - val_loss: 0.3161 - val_auc: 0.8511\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3089 - auc: 0.8102 - val_loss: 0.2705 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2760 - auc: 0.8160 - val_loss: 0.2498 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2605 - auc: 0.8200 - val_loss: 0.2399 - val_auc: 0.8545\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2528 - auc: 0.8228 - val_loss: 0.2350 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8259 - val_loss: 0.2324 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2462 - auc: 0.8290 - val_loss: 0.2309 - val_auc: 0.8539\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_222 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_225 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.6297 - auc: 0.6034 - val_loss: 1.1388 - val_auc: 0.8219\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8944 - auc: 0.7675 - val_loss: 0.6434 - val_auc: 0.8440\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5394 - auc: 0.7917 - val_loss: 0.4153 - val_auc: 0.8493\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3791 - auc: 0.8028 - val_loss: 0.3143 - val_auc: 0.8510\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3076 - auc: 0.8103 - val_loss: 0.2696 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2753 - auc: 0.8157 - val_loss: 0.2492 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2601 - auc: 0.8197 - val_loss: 0.2396 - val_auc: 0.8544\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2526 - auc: 0.8230 - val_loss: 0.2348 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.8261 - val_loss: 0.2323 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2461 - auc: 0.8289 - val_loss: 0.2308 - val_auc: 0.8538\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_225 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_228 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 1.6271 - auc: 0.6030 - val_loss: 1.1343 - val_auc: 0.8218\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8897 - auc: 0.7679 - val_loss: 0.6390 - val_auc: 0.8440\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5357 - auc: 0.7916 - val_loss: 0.4123 - val_auc: 0.8494\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3768 - auc: 0.8027 - val_loss: 0.3126 - val_auc: 0.8508\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3063 - auc: 0.8102 - val_loss: 0.2686 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2746 - auc: 0.8158 - val_loss: 0.2487 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2597 - auc: 0.8196 - val_loss: 0.2394 - val_auc: 0.8544\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2523 - auc: 0.8228 - val_loss: 0.2347 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2484 - auc: 0.8260 - val_loss: 0.2322 - val_auc: 0.8537\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8287 - val_loss: 0.2307 - val_auc: 0.8538\n",
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_228 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_231 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.6246 - auc: 0.6030 - val_loss: 1.1299 - val_auc: 0.8220\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8851 - auc: 0.7679 - val_loss: 0.6346 - val_auc: 0.8443\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5321 - auc: 0.7915 - val_loss: 0.4095 - val_auc: 0.8492\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3746 - auc: 0.8033 - val_loss: 0.3110 - val_auc: 0.8508\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3051 - auc: 0.8098 - val_loss: 0.2677 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2739 - auc: 0.8157 - val_loss: 0.2482 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2594 - auc: 0.8195 - val_loss: 0.2391 - val_auc: 0.8545\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2521 - auc: 0.8227 - val_loss: 0.2345 - val_auc: 0.8533\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2483 - auc: 0.8260 - val_loss: 0.2321 - val_auc: 0.8540\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2460 - auc: 0.8285 - val_loss: 0.2307 - val_auc: 0.8538\n",
      "Model: \"sequential_77\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_231 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_234 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 1.6221 - auc: 0.6032 - val_loss: 1.1255 - val_auc: 0.8224\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.8805 - auc: 0.7684 - val_loss: 0.6303 - val_auc: 0.8443\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5285 - auc: 0.7912 - val_loss: 0.4067 - val_auc: 0.8494\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3724 - auc: 0.8027 - val_loss: 0.3093 - val_auc: 0.8508\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3038 - auc: 0.8098 - val_loss: 0.2668 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2732 - auc: 0.8157 - val_loss: 0.2478 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2590 - auc: 0.8193 - val_loss: 0.2388 - val_auc: 0.8544\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2519 - auc: 0.8229 - val_loss: 0.2344 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2481 - auc: 0.8258 - val_loss: 0.2320 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2459 - auc: 0.8283 - val_loss: 0.2306 - val_auc: 0.8537\n",
      "Model: \"sequential_78\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_234 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_237 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 1.6195 - auc: 0.6041 - val_loss: 1.1211 - val_auc: 0.8225\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8759 - auc: 0.7685 - val_loss: 0.6261 - val_auc: 0.8448\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5250 - auc: 0.7913 - val_loss: 0.4039 - val_auc: 0.8494\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3702 - auc: 0.8028 - val_loss: 0.3077 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3027 - auc: 0.8096 - val_loss: 0.2660 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2726 - auc: 0.8158 - val_loss: 0.2473 - val_auc: 0.8537\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2587 - auc: 0.8192 - val_loss: 0.2386 - val_auc: 0.8543\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2518 - auc: 0.8227 - val_loss: 0.2342 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2480 - auc: 0.8257 - val_loss: 0.2319 - val_auc: 0.8544\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2458 - auc: 0.8282 - val_loss: 0.2305 - val_auc: 0.8537\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_237 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8292473942057621 0.0015000000000000007\n",
      "[0.8257051269127638, 0.8258684300719744, 0.8260438297614968, 0.8261789076833129, 0.8263422108425234, 0.8264752726759541, 0.8266264793048528, 0.8267454285195862, 0.8268512731598152, 0.8269803028164754, 0.8271022761637871, 0.8272212253785205, 0.8273482389467953, 0.8274772686034555, 0.8276133545694644, 0.8277111348561521, 0.8278139553638032, 0.8279752424346284, 0.8280901594725912, 0.8282171730408661, 0.8283038648414346, 0.828396604907159, 0.8285155541218927, 0.8286183746295437, 0.8286728090159472, 0.8287695812584424, 0.8288663535009374, 0.8289409487711942, 0.8290528416765791, 0.829100219753634, 0.8292473942057621]\n",
      "0.21012807771808917 0.0015000000000000007\n",
      "[0.21037015580807125, 0.21035643983153687, 0.21034325865157005, 0.2103305999708702, 0.21031844190588483, 0.21030676428132888, 0.210295558879789, 0.2102848015815947, 0.21027448538480475, 0.21026458801284373, 0.21025509029287082, 0.21024598030409183, 0.21023723739056085, 0.21022886306066316, 0.21022082543370682, 0.2102131200418378, 0.2102057310909982, 0.21019863931733845, 0.2101917509380573, 0.21018519951923845, 0.21017892748033853, 0.21017290512049303, 0.21016712579303168, 0.2101615668964443, 0.21015623040292364, 0.21015109427791012, 0.21014615369423378, 0.21014138993847922, 0.21013679728282725, 0.21013236033635493, 0.21012807771808917]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0.0012, 0.0015, 0.00001)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=i, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_240 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.6195 - auc: 0.6041 - val_loss: 1.1211 - val_auc: 0.8225\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8759 - auc: 0.7685 - val_loss: 0.6261 - val_auc: 0.8448\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.5250 - auc: 0.7913 - val_loss: 0.4039 - val_auc: 0.8494\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3702 - auc: 0.8028 - val_loss: 0.3077 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3027 - auc: 0.8096 - val_loss: 0.2660 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2726 - auc: 0.8158 - val_loss: 0.2473 - val_auc: 0.8537\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2587 - auc: 0.8192 - val_loss: 0.2386 - val_auc: 0.8543\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2518 - auc: 0.8227 - val_loss: 0.2342 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.8257 - val_loss: 0.2319 - val_auc: 0.8544\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2458 - auc: 0.8282 - val_loss: 0.2305 - val_auc: 0.8537\n",
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_240 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_243 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.6170 - auc: 0.6039 - val_loss: 1.1167 - val_auc: 0.8224\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8714 - auc: 0.7688 - val_loss: 0.6218 - val_auc: 0.8440\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5216 - auc: 0.7911 - val_loss: 0.4011 - val_auc: 0.8490\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3681 - auc: 0.8027 - val_loss: 0.3062 - val_auc: 0.8506\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3015 - auc: 0.8094 - val_loss: 0.2651 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2720 - auc: 0.8155 - val_loss: 0.2468 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2583 - auc: 0.8193 - val_loss: 0.2383 - val_auc: 0.8543\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2516 - auc: 0.8227 - val_loss: 0.2341 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.8258 - val_loss: 0.2318 - val_auc: 0.8550\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2458 - auc: 0.8283 - val_loss: 0.2305 - val_auc: 0.8536\n",
      "Model: \"sequential_81\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_243 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_246 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.6145 - auc: 0.6038 - val_loss: 1.1124 - val_auc: 0.8233\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8669 - auc: 0.7692 - val_loss: 0.6177 - val_auc: 0.8440\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5182 - auc: 0.7911 - val_loss: 0.3985 - val_auc: 0.8493\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3661 - auc: 0.8023 - val_loss: 0.3047 - val_auc: 0.8509\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3003 - auc: 0.8097 - val_loss: 0.2643 - val_auc: 0.8533\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2714 - auc: 0.8155 - val_loss: 0.2464 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2580 - auc: 0.8192 - val_loss: 0.2381 - val_auc: 0.8543\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.8225 - val_loss: 0.2339 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2478 - auc: 0.8258 - val_loss: 0.2317 - val_auc: 0.8549\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2457 - auc: 0.8283 - val_loss: 0.2304 - val_auc: 0.8533\n",
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_246 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_249 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.6120 - auc: 0.6042 - val_loss: 1.1081 - val_auc: 0.8227\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8625 - auc: 0.7694 - val_loss: 0.6135 - val_auc: 0.8444\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5148 - auc: 0.7911 - val_loss: 0.3958 - val_auc: 0.8496\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3640 - auc: 0.8024 - val_loss: 0.3032 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2992 - auc: 0.8095 - val_loss: 0.2635 - val_auc: 0.8536\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2708 - auc: 0.8154 - val_loss: 0.2460 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2577 - auc: 0.8193 - val_loss: 0.2378 - val_auc: 0.8543\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.8224 - val_loss: 0.2338 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2477 - auc: 0.8259 - val_loss: 0.2316 - val_auc: 0.8549\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2457 - auc: 0.8282 - val_loss: 0.2304 - val_auc: 0.8532\n",
      "Model: \"sequential_83\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_249 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_252 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.6095 - auc: 0.6039 - val_loss: 1.1038 - val_auc: 0.8225\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8581 - auc: 0.7696 - val_loss: 0.6094 - val_auc: 0.8447\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5115 - auc: 0.7906 - val_loss: 0.3932 - val_auc: 0.8497\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3620 - auc: 0.8025 - val_loss: 0.3017 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2982 - auc: 0.8095 - val_loss: 0.2627 - val_auc: 0.8536\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2702 - auc: 0.8153 - val_loss: 0.2456 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2574 - auc: 0.8194 - val_loss: 0.2376 - val_auc: 0.8543\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2511 - auc: 0.8224 - val_loss: 0.2337 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2476 - auc: 0.8261 - val_loss: 0.2316 - val_auc: 0.8546\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2456 - auc: 0.8283 - val_loss: 0.2303 - val_auc: 0.8532\n",
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_252 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_255 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.6070 - auc: 0.6043 - val_loss: 1.0995 - val_auc: 0.8223\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8537 - auc: 0.7703 - val_loss: 0.6054 - val_auc: 0.8452\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5082 - auc: 0.7910 - val_loss: 0.3906 - val_auc: 0.8498\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3601 - auc: 0.8023 - val_loss: 0.3003 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2971 - auc: 0.8094 - val_loss: 0.2620 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2697 - auc: 0.8152 - val_loss: 0.2452 - val_auc: 0.8542\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2571 - auc: 0.8193 - val_loss: 0.2374 - val_auc: 0.8543\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.8223 - val_loss: 0.2336 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.8258 - val_loss: 0.2315 - val_auc: 0.8546\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2455 - auc: 0.8286 - val_loss: 0.2303 - val_auc: 0.8533\n",
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_255 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_258 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 1.6045 - auc: 0.6050 - val_loss: 1.0953 - val_auc: 0.8229\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8494 - auc: 0.7700 - val_loss: 0.6014 - val_auc: 0.8459\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.5050 - auc: 0.7912 - val_loss: 0.3881 - val_auc: 0.8499\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3582 - auc: 0.8022 - val_loss: 0.2989 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2961 - auc: 0.8096 - val_loss: 0.2612 - val_auc: 0.8533\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2691 - auc: 0.8152 - val_loss: 0.2448 - val_auc: 0.8542\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2568 - auc: 0.8193 - val_loss: 0.2372 - val_auc: 0.8542\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2508 - auc: 0.8223 - val_loss: 0.2334 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2475 - auc: 0.8256 - val_loss: 0.2314 - val_auc: 0.8546\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2455 - auc: 0.8287 - val_loss: 0.2302 - val_auc: 0.8532\n",
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_258 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_261 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 1.6020 - auc: 0.6052 - val_loss: 1.0911 - val_auc: 0.8239\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8451 - auc: 0.7704 - val_loss: 0.5974 - val_auc: 0.8451\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.5018 - auc: 0.7913 - val_loss: 0.3857 - val_auc: 0.8497\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3563 - auc: 0.8020 - val_loss: 0.2975 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2951 - auc: 0.8098 - val_loss: 0.2605 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2686 - auc: 0.8150 - val_loss: 0.2444 - val_auc: 0.8542\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2566 - auc: 0.8196 - val_loss: 0.2370 - val_auc: 0.8542\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.8222 - val_loss: 0.2333 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2474 - auc: 0.8257 - val_loss: 0.2313 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2454 - auc: 0.8287 - val_loss: 0.2302 - val_auc: 0.8533\n",
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_261 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_264 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.5996 - auc: 0.6050 - val_loss: 1.0869 - val_auc: 0.8259\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.8408 - auc: 0.7713 - val_loss: 0.5935 - val_auc: 0.8443\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4987 - auc: 0.7916 - val_loss: 0.3832 - val_auc: 0.8498\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3545 - auc: 0.8020 - val_loss: 0.2962 - val_auc: 0.8503\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2941 - auc: 0.8095 - val_loss: 0.2598 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2681 - auc: 0.8148 - val_loss: 0.2440 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2563 - auc: 0.8192 - val_loss: 0.2368 - val_auc: 0.8541\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2505 - auc: 0.8223 - val_loss: 0.2332 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2473 - auc: 0.8254 - val_loss: 0.2313 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2454 - auc: 0.8287 - val_loss: 0.2301 - val_auc: 0.8533\n",
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_264 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_267 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 1.5971 - auc: 0.6056 - val_loss: 1.0827 - val_auc: 0.8257\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8366 - auc: 0.7719 - val_loss: 0.5897 - val_auc: 0.8444\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4956 - auc: 0.7914 - val_loss: 0.3808 - val_auc: 0.8499\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3527 - auc: 0.8020 - val_loss: 0.2949 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2931 - auc: 0.8095 - val_loss: 0.2591 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2676 - auc: 0.8149 - val_loss: 0.2437 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2560 - auc: 0.8192 - val_loss: 0.2366 - val_auc: 0.8542\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2503 - auc: 0.8223 - val_loss: 0.2331 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2472 - auc: 0.8254 - val_loss: 0.2312 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2454 - auc: 0.8283 - val_loss: 0.2301 - val_auc: 0.8532\n",
      "Model: \"sequential_89\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_267 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_270 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5947 - auc: 0.6064 - val_loss: 1.0785 - val_auc: 0.8256\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8324 - auc: 0.7719 - val_loss: 0.5858 - val_auc: 0.8436\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4925 - auc: 0.7905 - val_loss: 0.3785 - val_auc: 0.8501\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3509 - auc: 0.8019 - val_loss: 0.2936 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2922 - auc: 0.8093 - val_loss: 0.2585 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2671 - auc: 0.8146 - val_loss: 0.2433 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2558 - auc: 0.8193 - val_loss: 0.2364 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.8223 - val_loss: 0.2330 - val_auc: 0.8537\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8250 - val_loss: 0.2311 - val_auc: 0.8544\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2453 - auc: 0.8283 - val_loss: 0.2300 - val_auc: 0.8533\n",
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_270 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_273 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.5922 - auc: 0.6067 - val_loss: 1.0744 - val_auc: 0.8248\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8282 - auc: 0.7719 - val_loss: 0.5820 - val_auc: 0.8438\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.7904 - val_loss: 0.3761 - val_auc: 0.8496\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3492 - auc: 0.8021 - val_loss: 0.2924 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2913 - auc: 0.8094 - val_loss: 0.2578 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2667 - auc: 0.8146 - val_loss: 0.2430 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2555 - auc: 0.8193 - val_loss: 0.2362 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2501 - auc: 0.8226 - val_loss: 0.2329 - val_auc: 0.8537\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8248 - val_loss: 0.2311 - val_auc: 0.8544\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2453 - auc: 0.8281 - val_loss: 0.2300 - val_auc: 0.8534\n",
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_273 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_276 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5898 - auc: 0.6071 - val_loss: 1.0703 - val_auc: 0.8249\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8241 - auc: 0.7720 - val_loss: 0.5783 - val_auc: 0.8439\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4866 - auc: 0.7902 - val_loss: 0.3739 - val_auc: 0.8498\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3475 - auc: 0.8021 - val_loss: 0.2912 - val_auc: 0.8499\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2904 - auc: 0.8092 - val_loss: 0.2572 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2662 - auc: 0.8146 - val_loss: 0.2426 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2553 - auc: 0.8192 - val_loss: 0.2360 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.8225 - val_loss: 0.2327 - val_auc: 0.8538\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.8247 - val_loss: 0.2310 - val_auc: 0.8543\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2452 - auc: 0.8279 - val_loss: 0.2300 - val_auc: 0.8526\n",
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_276 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_279 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.5874 - auc: 0.6070 - val_loss: 1.0662 - val_auc: 0.8261\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.8200 - auc: 0.7726 - val_loss: 0.5746 - val_auc: 0.8444\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4836 - auc: 0.7895 - val_loss: 0.3716 - val_auc: 0.8498\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3458 - auc: 0.8014 - val_loss: 0.2900 - val_auc: 0.8500\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2896 - auc: 0.8094 - val_loss: 0.2566 - val_auc: 0.8528\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2658 - auc: 0.8145 - val_loss: 0.2423 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2551 - auc: 0.8192 - val_loss: 0.2358 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8229 - val_loss: 0.2326 - val_auc: 0.8537\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.8247 - val_loss: 0.2309 - val_auc: 0.8543\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2452 - auc: 0.8277 - val_loss: 0.2299 - val_auc: 0.8527\n",
      "Model: \"sequential_93\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_279 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_282 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.5850 - auc: 0.6073 - val_loss: 1.0621 - val_auc: 0.8264\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8159 - auc: 0.7722 - val_loss: 0.5709 - val_auc: 0.8451\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4807 - auc: 0.7900 - val_loss: 0.3694 - val_auc: 0.8495\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3442 - auc: 0.8013 - val_loss: 0.2888 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2887 - auc: 0.8095 - val_loss: 0.2560 - val_auc: 0.8528\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2654 - auc: 0.8142 - val_loss: 0.2420 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2549 - auc: 0.8195 - val_loss: 0.2357 - val_auc: 0.8542\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.8230 - val_loss: 0.2325 - val_auc: 0.8537\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.8245 - val_loss: 0.2309 - val_auc: 0.8541\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2452 - auc: 0.8271 - val_loss: 0.2299 - val_auc: 0.8528\n",
      "Model: \"sequential_94\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_282 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_285 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5826 - auc: 0.6077 - val_loss: 1.0581 - val_auc: 0.8285\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8118 - auc: 0.7723 - val_loss: 0.5673 - val_auc: 0.8457\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4779 - auc: 0.7893 - val_loss: 0.3672 - val_auc: 0.8495\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3426 - auc: 0.8012 - val_loss: 0.2877 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2879 - auc: 0.8092 - val_loss: 0.2554 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2650 - auc: 0.8142 - val_loss: 0.2417 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2547 - auc: 0.8195 - val_loss: 0.2355 - val_auc: 0.8543\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.8227 - val_loss: 0.2324 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8247 - val_loss: 0.2308 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2451 - auc: 0.8268 - val_loss: 0.2298 - val_auc: 0.8528\n",
      "Model: \"sequential_95\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_285 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_288 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5802 - auc: 0.6070 - val_loss: 1.0541 - val_auc: 0.8286\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8078 - auc: 0.7726 - val_loss: 0.5638 - val_auc: 0.8456\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4751 - auc: 0.7892 - val_loss: 0.3651 - val_auc: 0.8498\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3411 - auc: 0.8010 - val_loss: 0.2865 - val_auc: 0.8503\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2871 - auc: 0.8092 - val_loss: 0.2548 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2646 - auc: 0.8140 - val_loss: 0.2414 - val_auc: 0.8537\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2545 - auc: 0.8197 - val_loss: 0.2353 - val_auc: 0.8543\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.8226 - val_loss: 0.2323 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8245 - val_loss: 0.2307 - val_auc: 0.8537\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2451 - auc: 0.8268 - val_loss: 0.2298 - val_auc: 0.8526\n",
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_288 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_291 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5778 - auc: 0.6077 - val_loss: 1.0501 - val_auc: 0.8294\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.8039 - auc: 0.7731 - val_loss: 0.5602 - val_auc: 0.8453\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4723 - auc: 0.7894 - val_loss: 0.3630 - val_auc: 0.8498\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3395 - auc: 0.8012 - val_loss: 0.2855 - val_auc: 0.8503\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2863 - auc: 0.8092 - val_loss: 0.2543 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2642 - auc: 0.8140 - val_loss: 0.2411 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2543 - auc: 0.8198 - val_loss: 0.2352 - val_auc: 0.8539\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.8221 - val_loss: 0.2323 - val_auc: 0.8533\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.8242 - val_loss: 0.2307 - val_auc: 0.8537\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2450 - auc: 0.8268 - val_loss: 0.2297 - val_auc: 0.8527\n",
      "Model: \"sequential_97\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_291 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_294 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5754 - auc: 0.6080 - val_loss: 1.0461 - val_auc: 0.8293\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7999 - auc: 0.7731 - val_loss: 0.5567 - val_auc: 0.8454\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4696 - auc: 0.7896 - val_loss: 0.3609 - val_auc: 0.8500\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3380 - auc: 0.8010 - val_loss: 0.2844 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2856 - auc: 0.8093 - val_loss: 0.2537 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2638 - auc: 0.8138 - val_loss: 0.2408 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2541 - auc: 0.8195 - val_loss: 0.2350 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2493 - auc: 0.8223 - val_loss: 0.2322 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2466 - auc: 0.8243 - val_loss: 0.2306 - val_auc: 0.8538\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2450 - auc: 0.8265 - val_loss: 0.2297 - val_auc: 0.8524\n",
      "Model: \"sequential_98\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_294 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_297 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5730 - auc: 0.6082 - val_loss: 1.0422 - val_auc: 0.8301\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7960 - auc: 0.7740 - val_loss: 0.5533 - val_auc: 0.8452\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4669 - auc: 0.7895 - val_loss: 0.3589 - val_auc: 0.8504\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3366 - auc: 0.8005 - val_loss: 0.2833 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2848 - auc: 0.8089 - val_loss: 0.2532 - val_auc: 0.8527\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2634 - auc: 0.8138 - val_loss: 0.2406 - val_auc: 0.8532\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2539 - auc: 0.8197 - val_loss: 0.2349 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.8222 - val_loss: 0.2321 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.8238 - val_loss: 0.2306 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2450 - auc: 0.8265 - val_loss: 0.2297 - val_auc: 0.8525\n",
      "Model: \"sequential_99\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_297 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_300 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.5707 - auc: 0.6084 - val_loss: 1.0383 - val_auc: 0.8307\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7921 - auc: 0.7740 - val_loss: 0.5498 - val_auc: 0.8445\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4643 - auc: 0.7894 - val_loss: 0.3569 - val_auc: 0.8499\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3351 - auc: 0.8002 - val_loss: 0.2823 - val_auc: 0.8503\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2841 - auc: 0.8086 - val_loss: 0.2527 - val_auc: 0.8528\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2631 - auc: 0.8133 - val_loss: 0.2403 - val_auc: 0.8533\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2537 - auc: 0.8195 - val_loss: 0.2347 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.8221 - val_loss: 0.2320 - val_auc: 0.8533\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2465 - auc: 0.8241 - val_loss: 0.2305 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2450 - auc: 0.8266 - val_loss: 0.2296 - val_auc: 0.8525\n",
      "Model: \"sequential_100\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_300 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_303 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5683 - auc: 0.6081 - val_loss: 1.0343 - val_auc: 0.8294\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7883 - auc: 0.7738 - val_loss: 0.5465 - val_auc: 0.8451\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4616 - auc: 0.7893 - val_loss: 0.3549 - val_auc: 0.8501\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3337 - auc: 0.7999 - val_loss: 0.2813 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2834 - auc: 0.8083 - val_loss: 0.2522 - val_auc: 0.8528\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2627 - auc: 0.8132 - val_loss: 0.2400 - val_auc: 0.8533\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2535 - auc: 0.8192 - val_loss: 0.2346 - val_auc: 0.8535\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8218 - val_loss: 0.2319 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2465 - auc: 0.8238 - val_loss: 0.2304 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2449 - auc: 0.8260 - val_loss: 0.2296 - val_auc: 0.8525\n",
      "Model: \"sequential_101\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_303 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_306 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5660 - auc: 0.6079 - val_loss: 1.0305 - val_auc: 0.8282\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7845 - auc: 0.7738 - val_loss: 0.5431 - val_auc: 0.8446\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4591 - auc: 0.7895 - val_loss: 0.3530 - val_auc: 0.8501\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3323 - auc: 0.8001 - val_loss: 0.2803 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2827 - auc: 0.8085 - val_loss: 0.2517 - val_auc: 0.8523\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2624 - auc: 0.8133 - val_loss: 0.2398 - val_auc: 0.8529\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2534 - auc: 0.8185 - val_loss: 0.2344 - val_auc: 0.8533\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2489 - auc: 0.8217 - val_loss: 0.2318 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.8240 - val_loss: 0.2304 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2449 - auc: 0.8257 - val_loss: 0.2296 - val_auc: 0.8525\n",
      "Model: \"sequential_102\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_306 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_309 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5636 - auc: 0.6085 - val_loss: 1.0266 - val_auc: 0.8279\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7807 - auc: 0.7742 - val_loss: 0.5398 - val_auc: 0.8444\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4565 - auc: 0.7893 - val_loss: 0.3511 - val_auc: 0.8504\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3310 - auc: 0.8005 - val_loss: 0.2794 - val_auc: 0.8506\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2820 - auc: 0.8085 - val_loss: 0.2512 - val_auc: 0.8524\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2620 - auc: 0.8133 - val_loss: 0.2395 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2532 - auc: 0.8182 - val_loss: 0.2343 - val_auc: 0.8534\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8216 - val_loss: 0.2317 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.8237 - val_loss: 0.2303 - val_auc: 0.8541\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2449 - auc: 0.8252 - val_loss: 0.2295 - val_auc: 0.8525\n",
      "Model: \"sequential_103\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_309 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_312 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5613 - auc: 0.6081 - val_loss: 1.0228 - val_auc: 0.8296\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7769 - auc: 0.7746 - val_loss: 0.5366 - val_auc: 0.8446\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4540 - auc: 0.7892 - val_loss: 0.3492 - val_auc: 0.8501\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3296 - auc: 0.8007 - val_loss: 0.2784 - val_auc: 0.8502\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2814 - auc: 0.8081 - val_loss: 0.2507 - val_auc: 0.8526\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2617 - auc: 0.8132 - val_loss: 0.2393 - val_auc: 0.8532\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2530 - auc: 0.8181 - val_loss: 0.2342 - val_auc: 0.8535\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8214 - val_loss: 0.2316 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2463 - auc: 0.8237 - val_loss: 0.2303 - val_auc: 0.8537\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2448 - auc: 0.8252 - val_loss: 0.2295 - val_auc: 0.8524\n",
      "Model: \"sequential_104\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_312 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_315 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5590 - auc: 0.6084 - val_loss: 1.0189 - val_auc: 0.8299\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7732 - auc: 0.7755 - val_loss: 0.5333 - val_auc: 0.8444\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4515 - auc: 0.7891 - val_loss: 0.3473 - val_auc: 0.8507\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3283 - auc: 0.8004 - val_loss: 0.2775 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2807 - auc: 0.8084 - val_loss: 0.2503 - val_auc: 0.8527\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2614 - auc: 0.8133 - val_loss: 0.2391 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2529 - auc: 0.8181 - val_loss: 0.2340 - val_auc: 0.8532\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8205 - val_loss: 0.2316 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2463 - auc: 0.8240 - val_loss: 0.2302 - val_auc: 0.8535\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2448 - auc: 0.8253 - val_loss: 0.2294 - val_auc: 0.8521\n",
      "Model: \"sequential_105\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_315 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_318 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 1.5566 - auc: 0.6090 - val_loss: 1.0152 - val_auc: 0.8300\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7695 - auc: 0.7755 - val_loss: 0.5302 - val_auc: 0.8437\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4491 - auc: 0.7891 - val_loss: 0.3455 - val_auc: 0.8495\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3270 - auc: 0.8003 - val_loss: 0.2766 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2801 - auc: 0.8087 - val_loss: 0.2498 - val_auc: 0.8528\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2611 - auc: 0.8134 - val_loss: 0.2388 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2527 - auc: 0.8179 - val_loss: 0.2339 - val_auc: 0.8530\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8206 - val_loss: 0.2315 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2463 - auc: 0.8241 - val_loss: 0.2302 - val_auc: 0.8535\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2448 - auc: 0.8255 - val_loss: 0.2294 - val_auc: 0.8522\n",
      "Model: \"sequential_106\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_318 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_321 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.5543 - auc: 0.6093 - val_loss: 1.0114 - val_auc: 0.8309\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7658 - auc: 0.7756 - val_loss: 0.5270 - val_auc: 0.8440\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4467 - auc: 0.7892 - val_loss: 0.3437 - val_auc: 0.8495\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3258 - auc: 0.8004 - val_loss: 0.2757 - val_auc: 0.8507\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2795 - auc: 0.8084 - val_loss: 0.2494 - val_auc: 0.8528\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2608 - auc: 0.8133 - val_loss: 0.2386 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2526 - auc: 0.8178 - val_loss: 0.2338 - val_auc: 0.8531\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8203 - val_loss: 0.2314 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2462 - auc: 0.8239 - val_loss: 0.2301 - val_auc: 0.8535\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2448 - auc: 0.8254 - val_loss: 0.2294 - val_auc: 0.8518\n",
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_321 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_324 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.5520 - auc: 0.6090 - val_loss: 1.0076 - val_auc: 0.8300\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7622 - auc: 0.7754 - val_loss: 0.5239 - val_auc: 0.8447\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.4443 - auc: 0.7895 - val_loss: 0.3420 - val_auc: 0.8489\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3245 - auc: 0.8004 - val_loss: 0.2748 - val_auc: 0.8507\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2789 - auc: 0.8084 - val_loss: 0.2490 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2605 - auc: 0.8134 - val_loss: 0.2384 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2524 - auc: 0.8177 - val_loss: 0.2336 - val_auc: 0.8532\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.8204 - val_loss: 0.2313 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2462 - auc: 0.8238 - val_loss: 0.2301 - val_auc: 0.8535\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2448 - auc: 0.8252 - val_loss: 0.2293 - val_auc: 0.8518\n",
      "Model: \"sequential_108\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_324 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_327 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5497 - auc: 0.6087 - val_loss: 1.0039 - val_auc: 0.8288\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7586 - auc: 0.7755 - val_loss: 0.5208 - val_auc: 0.8452\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4419 - auc: 0.7895 - val_loss: 0.3402 - val_auc: 0.8496\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3233 - auc: 0.7998 - val_loss: 0.2740 - val_auc: 0.8508\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2783 - auc: 0.8081 - val_loss: 0.2486 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2602 - auc: 0.8133 - val_loss: 0.2382 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2523 - auc: 0.8176 - val_loss: 0.2335 - val_auc: 0.8533\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2484 - auc: 0.8203 - val_loss: 0.2313 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2461 - auc: 0.8238 - val_loss: 0.2300 - val_auc: 0.8537\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2447 - auc: 0.8254 - val_loss: 0.2293 - val_auc: 0.8518\n",
      "Model: \"sequential_109\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_327 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8313017882703977 0.0017900000000000008\n",
      "[0.8292473942057621, 0.8293078768573213, 0.829388520392734, 0.829497389165541, 0.8295659361706417, 0.8296385153525131, 0.8297050462692285, 0.8297796415394851, 0.8298381081026591, 0.8299207677264572, 0.8300175399689522, 0.8301122961230619, 0.8301848753049333, 0.8302755992822726, 0.8303401141106026, 0.8304580552811435, 0.8304973690046572, 0.83054777121429, 0.8306425273683999, 0.830685873268684, 0.8307433317876655, 0.8308098627043808, 0.8308501844720872, 0.8309449406261971, 0.8310074393661417, 0.8310941311667102, 0.8311525977298845, 0.8312150964698293, 0.8312513860607649, 0.8313017882703977]\n",
      "0.21003305161532945 0.0017900000000000008\n",
      "[0.21012807771808917, 0.21012392749223174, 0.21011991155075285, 0.21011602046009298, 0.21011223531167358, 0.21010855180583826, 0.2101049618225867, 0.21010146334523302, 0.2100980371392527, 0.21009468924256874, 0.2100913948846298, 0.21008815428284558, 0.21008496662757556, 0.2100818239879153, 0.21007871664750416, 0.21007563286689132, 0.2100725755961076, 0.21006954049504822, 0.21006652114692423, 0.21006350643687433, 0.21006050026108292, 0.21005749061887047, 0.2100544850683427, 0.21005146214930617, 0.21004843488645714, 0.2100453934643365, 0.21004233358632146, 0.2100392605484454, 0.21003617183987888, 0.21003305161532945]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0.0015, 0.0018, 0.00001)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=i, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_330 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5497 - auc: 0.6087 - val_loss: 1.0039 - val_auc: 0.8288\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7586 - auc: 0.7755 - val_loss: 0.5208 - val_auc: 0.8452\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4419 - auc: 0.7895 - val_loss: 0.3402 - val_auc: 0.8496\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3233 - auc: 0.7998 - val_loss: 0.2740 - val_auc: 0.8508\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2783 - auc: 0.8081 - val_loss: 0.2486 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2602 - auc: 0.8133 - val_loss: 0.2382 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2523 - auc: 0.8176 - val_loss: 0.2335 - val_auc: 0.8533\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2484 - auc: 0.8203 - val_loss: 0.2313 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2461 - auc: 0.8238 - val_loss: 0.2300 - val_auc: 0.8537\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2447 - auc: 0.8254 - val_loss: 0.2293 - val_auc: 0.8518\n",
      "Model: \"sequential_110\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_330 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_333 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 1.5474 - auc: 0.6087 - val_loss: 1.0002 - val_auc: 0.8291\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7550 - auc: 0.7759 - val_loss: 0.5178 - val_auc: 0.8459\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4396 - auc: 0.7898 - val_loss: 0.3385 - val_auc: 0.8499\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3221 - auc: 0.7993 - val_loss: 0.2732 - val_auc: 0.8510\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2777 - auc: 0.8077 - val_loss: 0.2482 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2600 - auc: 0.8136 - val_loss: 0.2379 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2522 - auc: 0.8173 - val_loss: 0.2334 - val_auc: 0.8535\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8203 - val_loss: 0.2312 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2461 - auc: 0.8236 - val_loss: 0.2300 - val_auc: 0.8538\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2447 - auc: 0.8250 - val_loss: 0.2293 - val_auc: 0.8519\n",
      "Model: \"sequential_111\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_333 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_336 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5452 - auc: 0.6090 - val_loss: 0.9965 - val_auc: 0.8293\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7515 - auc: 0.7762 - val_loss: 0.5148 - val_auc: 0.8452\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4374 - auc: 0.7900 - val_loss: 0.3369 - val_auc: 0.8497\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3210 - auc: 0.7990 - val_loss: 0.2723 - val_auc: 0.8510\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2772 - auc: 0.8076 - val_loss: 0.2478 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2597 - auc: 0.8137 - val_loss: 0.2377 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2520 - auc: 0.8170 - val_loss: 0.2333 - val_auc: 0.8536\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8204 - val_loss: 0.2311 - val_auc: 0.8532\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2461 - auc: 0.8235 - val_loss: 0.2299 - val_auc: 0.8539\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2447 - auc: 0.8249 - val_loss: 0.2292 - val_auc: 0.8519\n",
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_336 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_339 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.5429 - auc: 0.6094 - val_loss: 0.9928 - val_auc: 0.8284\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7479 - auc: 0.7766 - val_loss: 0.5118 - val_auc: 0.8456\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4351 - auc: 0.7897 - val_loss: 0.3352 - val_auc: 0.8492\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3198 - auc: 0.7991 - val_loss: 0.2715 - val_auc: 0.8514\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2767 - auc: 0.8078 - val_loss: 0.2474 - val_auc: 0.8533\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2595 - auc: 0.8135 - val_loss: 0.2375 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2519 - auc: 0.8169 - val_loss: 0.2332 - val_auc: 0.8537\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8203 - val_loss: 0.2310 - val_auc: 0.8530\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8232 - val_loss: 0.2299 - val_auc: 0.8538\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2447 - auc: 0.8251 - val_loss: 0.2292 - val_auc: 0.8521\n",
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_339 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_342 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.5406 - auc: 0.6095 - val_loss: 0.9892 - val_auc: 0.8286\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.7444 - auc: 0.7769 - val_loss: 0.5089 - val_auc: 0.8457\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4329 - auc: 0.7897 - val_loss: 0.3336 - val_auc: 0.8492\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3187 - auc: 0.7987 - val_loss: 0.2708 - val_auc: 0.8513\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2761 - auc: 0.8075 - val_loss: 0.2470 - val_auc: 0.8535\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2592 - auc: 0.8134 - val_loss: 0.2373 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2518 - auc: 0.8169 - val_loss: 0.2331 - val_auc: 0.8538\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2481 - auc: 0.8198 - val_loss: 0.2310 - val_auc: 0.8532\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2460 - auc: 0.8232 - val_loss: 0.2298 - val_auc: 0.8533\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2447 - auc: 0.8251 - val_loss: 0.2292 - val_auc: 0.8522\n",
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_342 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_345 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 1.5384 - auc: 0.6100 - val_loss: 0.9856 - val_auc: 0.8292\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7410 - auc: 0.7775 - val_loss: 0.5060 - val_auc: 0.8457\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4307 - auc: 0.7896 - val_loss: 0.3320 - val_auc: 0.8493\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3176 - auc: 0.7986 - val_loss: 0.2700 - val_auc: 0.8513\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2756 - auc: 0.8077 - val_loss: 0.2466 - val_auc: 0.8536\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2590 - auc: 0.8129 - val_loss: 0.2371 - val_auc: 0.8527\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2517 - auc: 0.8164 - val_loss: 0.2330 - val_auc: 0.8535\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.8199 - val_loss: 0.2309 - val_auc: 0.8533\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2460 - auc: 0.8228 - val_loss: 0.2298 - val_auc: 0.8534\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2446 - auc: 0.8246 - val_loss: 0.2291 - val_auc: 0.8523\n",
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_345 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_348 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5361 - auc: 0.6101 - val_loss: 0.9820 - val_auc: 0.8281\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7375 - auc: 0.7777 - val_loss: 0.5031 - val_auc: 0.8452\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4285 - auc: 0.7890 - val_loss: 0.3304 - val_auc: 0.8497\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3165 - auc: 0.7983 - val_loss: 0.2692 - val_auc: 0.8517\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2751 - auc: 0.8075 - val_loss: 0.2463 - val_auc: 0.8536\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2587 - auc: 0.8128 - val_loss: 0.2370 - val_auc: 0.8528\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2516 - auc: 0.8160 - val_loss: 0.2328 - val_auc: 0.8536\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.8197 - val_loss: 0.2308 - val_auc: 0.8534\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2459 - auc: 0.8228 - val_loss: 0.2297 - val_auc: 0.8535\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2446 - auc: 0.8243 - val_loss: 0.2291 - val_auc: 0.8525\n",
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_348 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_349 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_351 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 1.5339 - auc: 0.6100 - val_loss: 0.9784 - val_auc: 0.8281\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7341 - auc: 0.7786 - val_loss: 0.5002 - val_auc: 0.8448\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4264 - auc: 0.7891 - val_loss: 0.3289 - val_auc: 0.8500\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3155 - auc: 0.7983 - val_loss: 0.2685 - val_auc: 0.8518\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2746 - auc: 0.8072 - val_loss: 0.2459 - val_auc: 0.8539\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2585 - auc: 0.8127 - val_loss: 0.2368 - val_auc: 0.8529\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.8162 - val_loss: 0.2327 - val_auc: 0.8538\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.8197 - val_loss: 0.2308 - val_auc: 0.8540\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2459 - auc: 0.8228 - val_loss: 0.2297 - val_auc: 0.8535\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2446 - auc: 0.8238 - val_loss: 0.2291 - val_auc: 0.8525\n",
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_351 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_352 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_354 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.5316 - auc: 0.6098 - val_loss: 0.9748 - val_auc: 0.8300\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7308 - auc: 0.7783 - val_loss: 0.4974 - val_auc: 0.8452\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4243 - auc: 0.7888 - val_loss: 0.3274 - val_auc: 0.8501\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3145 - auc: 0.7977 - val_loss: 0.2678 - val_auc: 0.8520\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2741 - auc: 0.8073 - val_loss: 0.2456 - val_auc: 0.8541\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2583 - auc: 0.8128 - val_loss: 0.2366 - val_auc: 0.8533\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2513 - auc: 0.8160 - val_loss: 0.2326 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.8197 - val_loss: 0.2307 - val_auc: 0.8540\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2459 - auc: 0.8224 - val_loss: 0.2296 - val_auc: 0.8536\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2446 - auc: 0.8238 - val_loss: 0.2290 - val_auc: 0.8525\n",
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_354 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_357 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.5294 - auc: 0.6103 - val_loss: 0.9713 - val_auc: 0.8308\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7274 - auc: 0.7786 - val_loss: 0.4947 - val_auc: 0.8453\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4222 - auc: 0.7890 - val_loss: 0.3259 - val_auc: 0.8498\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3134 - auc: 0.7981 - val_loss: 0.2671 - val_auc: 0.8520\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2737 - auc: 0.8074 - val_loss: 0.2452 - val_auc: 0.8542\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2581 - auc: 0.8124 - val_loss: 0.2364 - val_auc: 0.8535\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2512 - auc: 0.8156 - val_loss: 0.2325 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2478 - auc: 0.8199 - val_loss: 0.2306 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2458 - auc: 0.8223 - val_loss: 0.2296 - val_auc: 0.8536\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2446 - auc: 0.8235 - val_loss: 0.2290 - val_auc: 0.8525\n",
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_357 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_359 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_360 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.5272 - auc: 0.6106 - val_loss: 0.9677 - val_auc: 0.8306\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7241 - auc: 0.7787 - val_loss: 0.4919 - val_auc: 0.8449\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4202 - auc: 0.7888 - val_loss: 0.3244 - val_auc: 0.8494\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3124 - auc: 0.7982 - val_loss: 0.2664 - val_auc: 0.8520\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2732 - auc: 0.8070 - val_loss: 0.2449 - val_auc: 0.8544\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2578 - auc: 0.8124 - val_loss: 0.2362 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2511 - auc: 0.8157 - val_loss: 0.2324 - val_auc: 0.8541\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2478 - auc: 0.8198 - val_loss: 0.2306 - val_auc: 0.8540\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2458 - auc: 0.8221 - val_loss: 0.2295 - val_auc: 0.8538\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2446 - auc: 0.8235 - val_loss: 0.2290 - val_auc: 0.8525\n",
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_360 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_361 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_363 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 1.5250 - auc: 0.6101 - val_loss: 0.9642 - val_auc: 0.8314\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7208 - auc: 0.7786 - val_loss: 0.4892 - val_auc: 0.8451\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4182 - auc: 0.7890 - val_loss: 0.3230 - val_auc: 0.8494\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3115 - auc: 0.7984 - val_loss: 0.2657 - val_auc: 0.8524\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2728 - auc: 0.8071 - val_loss: 0.2446 - val_auc: 0.8546\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2576 - auc: 0.8122 - val_loss: 0.2361 - val_auc: 0.8529\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2510 - auc: 0.8162 - val_loss: 0.2323 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2477 - auc: 0.8199 - val_loss: 0.2305 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2458 - auc: 0.8220 - val_loss: 0.2295 - val_auc: 0.8536\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2445 - auc: 0.8237 - val_loss: 0.2289 - val_auc: 0.8530\n",
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_363 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_364 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_365 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_366 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 1.5228 - auc: 0.6094 - val_loss: 0.9608 - val_auc: 0.8320\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.7175 - auc: 0.7789 - val_loss: 0.4865 - val_auc: 0.8448\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4162 - auc: 0.7893 - val_loss: 0.3216 - val_auc: 0.8495\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3105 - auc: 0.7982 - val_loss: 0.2650 - val_auc: 0.8525\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2723 - auc: 0.8072 - val_loss: 0.2442 - val_auc: 0.8543\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2574 - auc: 0.8123 - val_loss: 0.2359 - val_auc: 0.8529\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.8161 - val_loss: 0.2322 - val_auc: 0.8541\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2477 - auc: 0.8196 - val_loss: 0.2304 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2458 - auc: 0.8218 - val_loss: 0.2295 - val_auc: 0.8535\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2445 - auc: 0.8236 - val_loss: 0.2289 - val_auc: 0.8531\n",
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_366 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_367 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_368 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_369 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5206 - auc: 0.6097 - val_loss: 0.9573 - val_auc: 0.8337\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7142 - auc: 0.7790 - val_loss: 0.4839 - val_auc: 0.8454\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4142 - auc: 0.7892 - val_loss: 0.3202 - val_auc: 0.8496\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3096 - auc: 0.7982 - val_loss: 0.2644 - val_auc: 0.8526\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2719 - auc: 0.8067 - val_loss: 0.2439 - val_auc: 0.8544\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2572 - auc: 0.8122 - val_loss: 0.2357 - val_auc: 0.8528\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2508 - auc: 0.8161 - val_loss: 0.2321 - val_auc: 0.8539\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.8197 - val_loss: 0.2304 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2457 - auc: 0.8221 - val_loss: 0.2294 - val_auc: 0.8534\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2445 - auc: 0.8235 - val_loss: 0.2289 - val_auc: 0.8532\n",
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_369 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_370 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_371 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_372 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.5184 - auc: 0.6092 - val_loss: 0.9539 - val_auc: 0.8335\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7110 - auc: 0.7790 - val_loss: 0.4813 - val_auc: 0.8455\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4123 - auc: 0.7892 - val_loss: 0.3188 - val_auc: 0.8499\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3086 - auc: 0.7978 - val_loss: 0.2637 - val_auc: 0.8526\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2715 - auc: 0.8065 - val_loss: 0.2436 - val_auc: 0.8539\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2570 - auc: 0.8119 - val_loss: 0.2356 - val_auc: 0.8528\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.8158 - val_loss: 0.2320 - val_auc: 0.8541\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.8195 - val_loss: 0.2303 - val_auc: 0.8540\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2457 - auc: 0.8218 - val_loss: 0.2294 - val_auc: 0.8536\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2445 - auc: 0.8235 - val_loss: 0.2288 - val_auc: 0.8533\n",
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_372 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_373 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_374 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_375 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5162 - auc: 0.6096 - val_loss: 0.9504 - val_auc: 0.8328\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7078 - auc: 0.7793 - val_loss: 0.4787 - val_auc: 0.8456\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4104 - auc: 0.7889 - val_loss: 0.3174 - val_auc: 0.8503\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3077 - auc: 0.7978 - val_loss: 0.2631 - val_auc: 0.8524\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2711 - auc: 0.8063 - val_loss: 0.2433 - val_auc: 0.8541\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2569 - auc: 0.8118 - val_loss: 0.2354 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.8156 - val_loss: 0.2319 - val_auc: 0.8542\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2475 - auc: 0.8196 - val_loss: 0.2302 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2457 - auc: 0.8219 - val_loss: 0.2293 - val_auc: 0.8536\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2445 - auc: 0.8232 - val_loss: 0.2288 - val_auc: 0.8532\n",
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_375 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_376 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_377 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_378 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.5140 - auc: 0.6102 - val_loss: 0.9470 - val_auc: 0.8324\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7047 - auc: 0.7799 - val_loss: 0.4761 - val_auc: 0.8458\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4085 - auc: 0.7890 - val_loss: 0.3161 - val_auc: 0.8503\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3069 - auc: 0.7978 - val_loss: 0.2625 - val_auc: 0.8528\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2707 - auc: 0.8062 - val_loss: 0.2430 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2567 - auc: 0.8114 - val_loss: 0.2353 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.8153 - val_loss: 0.2318 - val_auc: 0.8544\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2475 - auc: 0.8193 - val_loss: 0.2302 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2457 - auc: 0.8218 - val_loss: 0.2293 - val_auc: 0.8529\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2445 - auc: 0.8231 - val_loss: 0.2288 - val_auc: 0.8533\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_378 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_379 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_380 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_381 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.5118 - auc: 0.6104 - val_loss: 0.9436 - val_auc: 0.8326\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.7015 - auc: 0.7796 - val_loss: 0.4736 - val_auc: 0.8459\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4066 - auc: 0.7892 - val_loss: 0.3148 - val_auc: 0.8500\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3060 - auc: 0.7978 - val_loss: 0.2618 - val_auc: 0.8531\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2703 - auc: 0.8065 - val_loss: 0.2427 - val_auc: 0.8533\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2565 - auc: 0.8113 - val_loss: 0.2351 - val_auc: 0.8529\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2505 - auc: 0.8153 - val_loss: 0.2317 - val_auc: 0.8546\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2474 - auc: 0.8192 - val_loss: 0.2301 - val_auc: 0.8543\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2456 - auc: 0.8217 - val_loss: 0.2292 - val_auc: 0.8531\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2445 - auc: 0.8231 - val_loss: 0.2287 - val_auc: 0.8534\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_381 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_382 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_383 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_384 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.5097 - auc: 0.6106 - val_loss: 0.9403 - val_auc: 0.8334\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6984 - auc: 0.7797 - val_loss: 0.4711 - val_auc: 0.8448\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4048 - auc: 0.7895 - val_loss: 0.3135 - val_auc: 0.8502\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3051 - auc: 0.7979 - val_loss: 0.2612 - val_auc: 0.8532\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2699 - auc: 0.8065 - val_loss: 0.2425 - val_auc: 0.8533\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2563 - auc: 0.8111 - val_loss: 0.2350 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.8152 - val_loss: 0.2317 - val_auc: 0.8545\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2474 - auc: 0.8187 - val_loss: 0.2300 - val_auc: 0.8545\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2456 - auc: 0.8217 - val_loss: 0.2292 - val_auc: 0.8531\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2445 - auc: 0.8234 - val_loss: 0.2287 - val_auc: 0.8532\n",
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_384 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_385 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_386 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_387 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.5075 - auc: 0.6107 - val_loss: 0.9369 - val_auc: 0.8331\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6953 - auc: 0.7800 - val_loss: 0.4686 - val_auc: 0.8452\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4030 - auc: 0.7892 - val_loss: 0.3123 - val_auc: 0.8507\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3043 - auc: 0.7982 - val_loss: 0.2607 - val_auc: 0.8534\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2695 - auc: 0.8064 - val_loss: 0.2422 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2562 - auc: 0.8111 - val_loss: 0.2348 - val_auc: 0.8532\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.8150 - val_loss: 0.2316 - val_auc: 0.8546\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2473 - auc: 0.8188 - val_loss: 0.2300 - val_auc: 0.8545\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2456 - auc: 0.8215 - val_loss: 0.2291 - val_auc: 0.8531\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2445 - auc: 0.8233 - val_loss: 0.2287 - val_auc: 0.8532\n",
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_387 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_388 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_389 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_390 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.5053 - auc: 0.6111 - val_loss: 0.9336 - val_auc: 0.8341\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6922 - auc: 0.7795 - val_loss: 0.4662 - val_auc: 0.8455\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.4012 - auc: 0.7894 - val_loss: 0.3110 - val_auc: 0.8508\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3035 - auc: 0.7983 - val_loss: 0.2601 - val_auc: 0.8531\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2692 - auc: 0.8060 - val_loss: 0.2419 - val_auc: 0.8534\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2560 - auc: 0.8112 - val_loss: 0.2347 - val_auc: 0.8527\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.8150 - val_loss: 0.2315 - val_auc: 0.8545\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2473 - auc: 0.8184 - val_loss: 0.2299 - val_auc: 0.8547\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2456 - auc: 0.8214 - val_loss: 0.2291 - val_auc: 0.8531\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2444 - auc: 0.8234 - val_loss: 0.2286 - val_auc: 0.8533\n",
      "Model: \"sequential_130\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_390 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_392 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_393 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.5032 - auc: 0.6111 - val_loss: 0.9303 - val_auc: 0.8345\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.6892 - auc: 0.7797 - val_loss: 0.4638 - val_auc: 0.8449\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3995 - auc: 0.7891 - val_loss: 0.3098 - val_auc: 0.8500\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3027 - auc: 0.7977 - val_loss: 0.2595 - val_auc: 0.8534\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2688 - auc: 0.8060 - val_loss: 0.2416 - val_auc: 0.8534\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2558 - auc: 0.8111 - val_loss: 0.2345 - val_auc: 0.8526\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.8152 - val_loss: 0.2314 - val_auc: 0.8546\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2473 - auc: 0.8181 - val_loss: 0.2299 - val_auc: 0.8547\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2456 - auc: 0.8212 - val_loss: 0.2291 - val_auc: 0.8529\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2444 - auc: 0.8231 - val_loss: 0.2286 - val_auc: 0.8535\n",
      "Model: \"sequential_131\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_393 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_394 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_395 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8325638595996049 0.0020000000000000005\n",
      "[0.8313017882703977, 0.8313320295961775, 0.831392512247737, 0.8314408983689844, 0.8315013810205438, 0.831592104997883, 0.8316828289752223, 0.8317493598919378, 0.8317997621015706, 0.8318642769299006, 0.8319308078466159, 0.8319832261446342, 0.8320376605310377, 0.8321102397129089, 0.8321435051712667, 0.8321949154250923, 0.832231205016028, 0.832321928993367, 0.8323924920868531, 0.832454990826798, 0.8324932965061188, 0.8325638595996049]\n",
      "0.2099603839303558 0.0020000000000000005\n",
      "[0.21003305161532945, 0.21002990530936605, 0.21002673526327226, 0.2100235334622134, 0.21002030588445125, 0.2100170472831645, 0.21001376468388933, 0.21001043402223463, 0.21000707878822536, 0.21000369218182474, 0.21000026750580214, 0.20999680663561135, 0.20999331860032863, 0.20998979388482375, 0.20998623450949028, 0.20998263675982415, 0.209979013735688, 0.2099753508190589, 0.20997166056678082, 0.2099679345318962, 0.209964172028806, 0.2099603839303558]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0.00179, 0.002, 0.00001)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=i, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_396 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.5032 - auc: 0.6111 - val_loss: 0.9303 - val_auc: 0.8345\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.6892 - auc: 0.7797 - val_loss: 0.4638 - val_auc: 0.8449\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3995 - auc: 0.7891 - val_loss: 0.3098 - val_auc: 0.8500\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3027 - auc: 0.7977 - val_loss: 0.2595 - val_auc: 0.8534\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2688 - auc: 0.8060 - val_loss: 0.2416 - val_auc: 0.8534\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2558 - auc: 0.8111 - val_loss: 0.2345 - val_auc: 0.8526\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.8152 - val_loss: 0.2314 - val_auc: 0.8546\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2473 - auc: 0.8181 - val_loss: 0.2299 - val_auc: 0.8547\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2456 - auc: 0.8212 - val_loss: 0.2291 - val_auc: 0.8529\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2444 - auc: 0.8231 - val_loss: 0.2286 - val_auc: 0.8535\n",
      "Model: \"sequential_132\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_396 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_397 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_398 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_399 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 1.4038 - auc: 0.6077 - val_loss: 0.7852 - val_auc: 0.8381\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.5636 - auc: 0.7777 - val_loss: 0.3721 - val_auc: 0.8472\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3357 - auc: 0.7879 - val_loss: 0.2684 - val_auc: 0.8486\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2762 - auc: 0.7943 - val_loss: 0.2409 - val_auc: 0.8539\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2580 - auc: 0.8015 - val_loss: 0.2323 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.8076 - val_loss: 0.2290 - val_auc: 0.8528\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.8109 - val_loss: 0.2276 - val_auc: 0.8532\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2462 - auc: 0.8148 - val_loss: 0.2271 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2450 - auc: 0.8166 - val_loss: 0.2270 - val_auc: 0.8545\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2442 - auc: 0.8196 - val_loss: 0.2269 - val_auc: 0.8521\n",
      "Model: \"sequential_133\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_399 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_400 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_402 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.3180 - auc: 0.6059 - val_loss: 0.6697 - val_auc: 0.8376\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.4780 - auc: 0.7703 - val_loss: 0.3189 - val_auc: 0.8489\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3022 - auc: 0.7871 - val_loss: 0.2492 - val_auc: 0.8496\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2644 - auc: 0.7927 - val_loss: 0.2325 - val_auc: 0.8535\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2534 - auc: 0.7987 - val_loss: 0.2274 - val_auc: 0.8539\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2492 - auc: 0.8033 - val_loss: 0.2254 - val_auc: 0.8545\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.8075 - val_loss: 0.2247 - val_auc: 0.8564\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2456 - auc: 0.8101 - val_loss: 0.2246 - val_auc: 0.8552\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2446 - auc: 0.8145 - val_loss: 0.2243 - val_auc: 0.8551\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2438 - auc: 0.8174 - val_loss: 0.2244 - val_auc: 0.8522\n",
      "Model: \"sequential_134\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_402 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_404 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_405 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.2436 - auc: 0.6082 - val_loss: 0.5756 - val_auc: 0.8371\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.4190 - auc: 0.7623 - val_loss: 0.2872 - val_auc: 0.8463\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2838 - auc: 0.7831 - val_loss: 0.2393 - val_auc: 0.8507\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2583 - auc: 0.7909 - val_loss: 0.2286 - val_auc: 0.8532\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7988 - val_loss: 0.2252 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2477 - auc: 0.8049 - val_loss: 0.2239 - val_auc: 0.8546\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8084 - val_loss: 0.2233 - val_auc: 0.8535\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2449 - auc: 0.8116 - val_loss: 0.2232 - val_auc: 0.8553\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2440 - auc: 0.8156 - val_loss: 0.2234 - val_auc: 0.8533\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2435 - auc: 0.8184 - val_loss: 0.2235 - val_auc: 0.8512\n",
      "Model: \"sequential_135\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_405 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_406 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_408 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 1.1785 - auc: 0.6128 - val_loss: 0.5009 - val_auc: 0.8374\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3781 - auc: 0.7543 - val_loss: 0.2673 - val_auc: 0.8456\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2731 - auc: 0.7802 - val_loss: 0.2339 - val_auc: 0.8504\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2548 - auc: 0.7914 - val_loss: 0.2271 - val_auc: 0.8525\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8004 - val_loss: 0.2251 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.8074 - val_loss: 0.2241 - val_auc: 0.8519\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2449 - auc: 0.8118 - val_loss: 0.2235 - val_auc: 0.8534\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2441 - auc: 0.8132 - val_loss: 0.2231 - val_auc: 0.8554\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2436 - auc: 0.8153 - val_loss: 0.2232 - val_auc: 0.8530\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2431 - auc: 0.8191 - val_loss: 0.2242 - val_auc: 0.8529\n",
      "Model: \"sequential_136\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_408 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_411 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.1213 - auc: 0.6212 - val_loss: 0.4445 - val_auc: 0.8335\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3490 - auc: 0.7505 - val_loss: 0.2544 - val_auc: 0.8448\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2663 - auc: 0.7783 - val_loss: 0.2315 - val_auc: 0.8490\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2522 - auc: 0.7932 - val_loss: 0.2274 - val_auc: 0.8546\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2474 - auc: 0.8043 - val_loss: 0.2258 - val_auc: 0.8570\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2452 - auc: 0.8117 - val_loss: 0.2250 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2441 - auc: 0.8145 - val_loss: 0.2244 - val_auc: 0.8533\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2435 - auc: 0.8158 - val_loss: 0.2238 - val_auc: 0.8546\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2432 - auc: 0.8161 - val_loss: 0.2234 - val_auc: 0.8523\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2431 - auc: 0.8154 - val_loss: 0.2231 - val_auc: 0.8535\n",
      "Model: \"sequential_137\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_411 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_412 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8353601741900365 0.0045000000000000005\n",
      "[0.8325638595996049, 0.8341384246285357, 0.8340597971815084, 0.834787605088607, 0.8341041511259855, 0.8353601741900365]\n",
      "0.2095337267452733 0.003\n",
      "[0.2099603839303558, 0.20968199021631592, 0.2095337267452733, 0.20995622604358652, 0.212551545751845, 0.21267789198369477]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0.002, 0.005, 0.0005)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=i, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_414 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 1.0705 - auc: 0.6300 - val_loss: 0.4036 - val_auc: 0.8317\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3273 - auc: 0.7503 - val_loss: 0.2472 - val_auc: 0.8441\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2611 - auc: 0.7810 - val_loss: 0.2316 - val_auc: 0.8509\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7977 - val_loss: 0.2278 - val_auc: 0.8521\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2463 - auc: 0.8091 - val_loss: 0.2264 - val_auc: 0.8538\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2446 - auc: 0.8138 - val_loss: 0.2257 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2437 - auc: 0.8166 - val_loss: 0.2252 - val_auc: 0.8547\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2431 - auc: 0.8176 - val_loss: 0.2248 - val_auc: 0.8536\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2428 - auc: 0.8181 - val_loss: 0.2243 - val_auc: 0.8520\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2428 - auc: 0.8160 - val_loss: 0.2239 - val_auc: 0.8514\n",
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_414 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_415 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_416 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_417 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.0257 - auc: 0.6419 - val_loss: 0.3739 - val_auc: 0.8286\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3102 - auc: 0.7615 - val_loss: 0.2443 - val_auc: 0.8436\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2568 - auc: 0.7893 - val_loss: 0.2308 - val_auc: 0.8520\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.8025 - val_loss: 0.2278 - val_auc: 0.8539\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2462 - auc: 0.8077 - val_loss: 0.2269 - val_auc: 0.8556\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2447 - auc: 0.8129 - val_loss: 0.2263 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2437 - auc: 0.8158 - val_loss: 0.2258 - val_auc: 0.8525\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2431 - auc: 0.8168 - val_loss: 0.2254 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2427 - auc: 0.8176 - val_loss: 0.2251 - val_auc: 0.8510\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2426 - auc: 0.8165 - val_loss: 0.2251 - val_auc: 0.8515\n",
      "Model: \"sequential_139\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_417 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_418 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_419 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_420 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9867 - auc: 0.6523 - val_loss: 0.3499 - val_auc: 0.8335\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2971 - auc: 0.7748 - val_loss: 0.2406 - val_auc: 0.8453\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2548 - auc: 0.7915 - val_loss: 0.2299 - val_auc: 0.8528\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2490 - auc: 0.7971 - val_loss: 0.2282 - val_auc: 0.8539\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2464 - auc: 0.8037 - val_loss: 0.2271 - val_auc: 0.8542\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2447 - auc: 0.8106 - val_loss: 0.2265 - val_auc: 0.8542\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2437 - auc: 0.8147 - val_loss: 0.2261 - val_auc: 0.8544\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2434 - auc: 0.8153 - val_loss: 0.2262 - val_auc: 0.8539\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2432 - auc: 0.8156 - val_loss: 0.2256 - val_auc: 0.8530\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2429 - auc: 0.8162 - val_loss: 0.2261 - val_auc: 0.8503\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_420 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_421 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_423 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.9536 - auc: 0.6612 - val_loss: 0.3294 - val_auc: 0.8342\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2887 - auc: 0.7782 - val_loss: 0.2378 - val_auc: 0.8462\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2544 - auc: 0.7844 - val_loss: 0.2299 - val_auc: 0.8527\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2491 - auc: 0.7929 - val_loss: 0.2282 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2464 - auc: 0.8022 - val_loss: 0.2272 - val_auc: 0.8523\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2451 - auc: 0.8078 - val_loss: 0.2267 - val_auc: 0.8544\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2450 - auc: 0.8061 - val_loss: 0.2270 - val_auc: 0.8522\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2439 - auc: 0.8121 - val_loss: 0.2265 - val_auc: 0.8520\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2442 - auc: 0.8102 - val_loss: 0.2266 - val_auc: 0.8519\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2439 - auc: 0.8111 - val_loss: 0.2261 - val_auc: 0.8512\n",
      "Model: \"sequential_141\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_423 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_424 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_425 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_426 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.9261 - auc: 0.6704 - val_loss: 0.3138 - val_auc: 0.8369\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2836 - auc: 0.7740 - val_loss: 0.2363 - val_auc: 0.8488\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2543 - auc: 0.7793 - val_loss: 0.2297 - val_auc: 0.8532\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7906 - val_loss: 0.2279 - val_auc: 0.8531\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2469 - auc: 0.7963 - val_loss: 0.2272 - val_auc: 0.8519\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2462 - auc: 0.7994 - val_loss: 0.2276 - val_auc: 0.8512\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2452 - auc: 0.8042 - val_loss: 0.2272 - val_auc: 0.8537\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2452 - auc: 0.8044 - val_loss: 0.2268 - val_auc: 0.8502\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2456 - auc: 0.8044 - val_loss: 0.2266 - val_auc: 0.8471\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2458 - auc: 0.8067 - val_loss: 0.2269 - val_auc: 0.8485\n",
      "Model: \"sequential_142\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_426 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_427 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_428 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_429 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.9039 - auc: 0.6756 - val_loss: 0.3035 - val_auc: 0.8409\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2801 - auc: 0.7707 - val_loss: 0.2344 - val_auc: 0.8476\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2543 - auc: 0.7733 - val_loss: 0.2295 - val_auc: 0.8534\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.7855 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2478 - auc: 0.7899 - val_loss: 0.2283 - val_auc: 0.8500\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2462 - auc: 0.7990 - val_loss: 0.2278 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2457 - auc: 0.8028 - val_loss: 0.2269 - val_auc: 0.8512\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2461 - auc: 0.8019 - val_loss: 0.2262 - val_auc: 0.8474\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2460 - auc: 0.8048 - val_loss: 0.2262 - val_auc: 0.8500\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2461 - auc: 0.8035 - val_loss: 0.2270 - val_auc: 0.8474\n",
      "Model: \"sequential_143\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_429 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_430 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_431 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_432 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.8864 - auc: 0.6762 - val_loss: 0.2971 - val_auc: 0.8386\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2774 - auc: 0.7678 - val_loss: 0.2329 - val_auc: 0.8479\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2544 - auc: 0.7707 - val_loss: 0.2284 - val_auc: 0.8511\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.7779 - val_loss: 0.2277 - val_auc: 0.8528\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.7861 - val_loss: 0.2276 - val_auc: 0.8516\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2473 - auc: 0.7925 - val_loss: 0.2273 - val_auc: 0.8516\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2472 - auc: 0.7964 - val_loss: 0.2265 - val_auc: 0.8512\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.7969 - val_loss: 0.2271 - val_auc: 0.8470\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.8000 - val_loss: 0.2268 - val_auc: 0.8502\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8005 - val_loss: 0.2272 - val_auc: 0.8498\n",
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_432 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_433 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_435 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.8736 - auc: 0.6728 - val_loss: 0.2934 - val_auc: 0.8372\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2753 - auc: 0.7679 - val_loss: 0.2317 - val_auc: 0.8498\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2545 - auc: 0.7680 - val_loss: 0.2272 - val_auc: 0.8516\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.7728 - val_loss: 0.2273 - val_auc: 0.8537\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7812 - val_loss: 0.2273 - val_auc: 0.8536\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2484 - auc: 0.7865 - val_loss: 0.2279 - val_auc: 0.8502\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7905 - val_loss: 0.2267 - val_auc: 0.8503\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2477 - auc: 0.7929 - val_loss: 0.2272 - val_auc: 0.8472\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2476 - auc: 0.7960 - val_loss: 0.2272 - val_auc: 0.8497\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2473 - auc: 0.7970 - val_loss: 0.2272 - val_auc: 0.8463\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_435 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_436 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_437 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_438 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.8653 - auc: 0.6628 - val_loss: 0.2912 - val_auc: 0.8360\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2735 - auc: 0.7712 - val_loss: 0.2307 - val_auc: 0.8489\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2549 - auc: 0.7648 - val_loss: 0.2268 - val_auc: 0.8549\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2510 - auc: 0.7729 - val_loss: 0.2261 - val_auc: 0.8524\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7749 - val_loss: 0.2289 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2484 - auc: 0.7867 - val_loss: 0.2266 - val_auc: 0.8498\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7906 - val_loss: 0.2271 - val_auc: 0.8499\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.7871 - val_loss: 0.2279 - val_auc: 0.8456\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.7926 - val_loss: 0.2272 - val_auc: 0.8465\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2472 - auc: 0.7957 - val_loss: 0.2279 - val_auc: 0.8480\n",
      "Model: \"sequential_146\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_438 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_439 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_440 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_441 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.8595 - auc: 0.6504 - val_loss: 0.2885 - val_auc: 0.8298\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2722 - auc: 0.7722 - val_loss: 0.2302 - val_auc: 0.8512\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2550 - auc: 0.7627 - val_loss: 0.2275 - val_auc: 0.8505\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2508 - auc: 0.7753 - val_loss: 0.2254 - val_auc: 0.8510\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2501 - auc: 0.7735 - val_loss: 0.2285 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7824 - val_loss: 0.2269 - val_auc: 0.8502\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.7883 - val_loss: 0.2271 - val_auc: 0.8502\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.7896 - val_loss: 0.2273 - val_auc: 0.8480\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2481 - auc: 0.7918 - val_loss: 0.2274 - val_auc: 0.8487\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.7940 - val_loss: 0.2278 - val_auc: 0.8477\n",
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_441 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_442 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_443 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8364891836858127 0.007499999999999998\n",
      "[0.8353944476925869, 0.8352573536823853, 0.8349892139271385, 0.8344932561843511, 0.8358581480212093, 0.8364891836858127, 0.8359539122195117, 0.8352825547872018, 0.8341364085401505, 0.8362412048144191]\n",
      "0.21324498092683541 0.009499999999999996\n",
      "[0.2153021076247851, 0.21757166444044526, 0.2188247553837343, 0.2187654617081733, 0.21606068705369383, 0.21393756531489055, 0.21427128354941605, 0.21579779171591496, 0.21800480240068107, 0.21324498092683541]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0.005, 0.01, 0.0005)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=i, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_444 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.9261 - auc: 0.6704 - val_loss: 0.3138 - val_auc: 0.8369\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2836 - auc: 0.7740 - val_loss: 0.2363 - val_auc: 0.8488\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2543 - auc: 0.7793 - val_loss: 0.2297 - val_auc: 0.8532\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2512 - auc: 0.788 - 0s 5ms/step - loss: 0.2491 - auc: 0.7906 - val_loss: 0.2279 - val_auc: 0.8531\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2469 - auc: 0.7963 - val_loss: 0.2272 - val_auc: 0.8519\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2462 - auc: 0.7994 - val_loss: 0.2276 - val_auc: 0.8512\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2452 - auc: 0.8042 - val_loss: 0.2272 - val_auc: 0.8537\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2452 - auc: 0.8044 - val_loss: 0.2268 - val_auc: 0.8502\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2456 - auc: 0.8044 - val_loss: 0.2266 - val_auc: 0.8471\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2458 - auc: 0.8067 - val_loss: 0.2269 - val_auc: 0.8485\n",
      "Model: \"sequential_148\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_444 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_445 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_446 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_447 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.9213 - auc: 0.6720 - val_loss: 0.3113 - val_auc: 0.8384\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2828 - auc: 0.7729 - val_loss: 0.2359 - val_auc: 0.8486\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2543 - auc: 0.7781 - val_loss: 0.2297 - val_auc: 0.8533\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2491 - auc: 0.7900 - val_loss: 0.2279 - val_auc: 0.8524\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2471 - auc: 0.7967 - val_loss: 0.2273 - val_auc: 0.8535\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2462 - auc: 0.8000 - val_loss: 0.2275 - val_auc: 0.8517\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2454 - auc: 0.8035 - val_loss: 0.2271 - val_auc: 0.8517\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2455 - auc: 0.8055 - val_loss: 0.2266 - val_auc: 0.8510\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2458 - auc: 0.8040 - val_loss: 0.2266 - val_auc: 0.8476\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2459 - auc: 0.8046 - val_loss: 0.2271 - val_auc: 0.8490\n",
      "Model: \"sequential_149\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_447 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_448 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_449 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_450 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9167 - auc: 0.6727 - val_loss: 0.3091 - val_auc: 0.8375\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2821 - auc: 0.7721 - val_loss: 0.2355 - val_auc: 0.8477\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2543 - auc: 0.7761 - val_loss: 0.2297 - val_auc: 0.8533\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7888 - val_loss: 0.2278 - val_auc: 0.8532\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2472 - auc: 0.7949 - val_loss: 0.2276 - val_auc: 0.8525\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8002 - val_loss: 0.2274 - val_auc: 0.8521\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2455 - auc: 0.8034 - val_loss: 0.2270 - val_auc: 0.8529\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2457 - auc: 0.8033 - val_loss: 0.2263 - val_auc: 0.8487\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2459 - auc: 0.8042 - val_loss: 0.2267 - val_auc: 0.8476\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8040 - val_loss: 0.2270 - val_auc: 0.8463\n",
      "Model: \"sequential_150\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_450 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_451 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_452 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_453 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.9122 - auc: 0.6742 - val_loss: 0.3071 - val_auc: 0.8414\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2813 - auc: 0.7715 - val_loss: 0.2351 - val_auc: 0.8488\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2543 - auc: 0.7752 - val_loss: 0.2296 - val_auc: 0.8532\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2493 - auc: 0.7876 - val_loss: 0.2278 - val_auc: 0.8553\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2474 - auc: 0.7937 - val_loss: 0.2280 - val_auc: 0.8503\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8000 - val_loss: 0.2274 - val_auc: 0.8508\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2456 - auc: 0.8030 - val_loss: 0.2268 - val_auc: 0.8519\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2459 - auc: 0.8017 - val_loss: 0.2262 - val_auc: 0.8471\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8036 - val_loss: 0.2264 - val_auc: 0.8467\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2462 - auc: 0.8038 - val_loss: 0.2275 - val_auc: 0.8478\n",
      "Model: \"sequential_151\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_453 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_454 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_455 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_456 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9080 - auc: 0.6743 - val_loss: 0.3052 - val_auc: 0.8408\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2807 - auc: 0.7713 - val_loss: 0.2347 - val_auc: 0.8486\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2543 - auc: 0.7745 - val_loss: 0.2296 - val_auc: 0.8528\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7865 - val_loss: 0.2277 - val_auc: 0.8531\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.7913 - val_loss: 0.2282 - val_auc: 0.8506\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.7999 - val_loss: 0.2276 - val_auc: 0.8510\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2455 - auc: 0.8036 - val_loss: 0.2268 - val_auc: 0.8513\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8022 - val_loss: 0.2262 - val_auc: 0.8477\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8048 - val_loss: 0.2261 - val_auc: 0.8491\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8042 - val_loss: 0.2272 - val_auc: 0.8474\n",
      "Model: \"sequential_152\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_456 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_457 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_458 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_459 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.9039 - auc: 0.6756 - val_loss: 0.3035 - val_auc: 0.8409\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2801 - auc: 0.7707 - val_loss: 0.2344 - val_auc: 0.8476\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2543 - auc: 0.7733 - val_loss: 0.2295 - val_auc: 0.8534\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.7855 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2478 - auc: 0.7899 - val_loss: 0.2283 - val_auc: 0.8500\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2462 - auc: 0.7990 - val_loss: 0.2278 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2457 - auc: 0.8028 - val_loss: 0.2269 - val_auc: 0.8512\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2461 - auc: 0.8019 - val_loss: 0.2262 - val_auc: 0.8474\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2460 - auc: 0.8048 - val_loss: 0.2262 - val_auc: 0.8500\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2461 - auc: 0.8035 - val_loss: 0.2270 - val_auc: 0.8474\n",
      "Model: \"sequential_153\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_459 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_460 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_461 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_462 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.9000 - auc: 0.6753 - val_loss: 0.3020 - val_auc: 0.8408\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2795 - auc: 0.7700 - val_loss: 0.2340 - val_auc: 0.8509\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2543 - auc: 0.7731 - val_loss: 0.2293 - val_auc: 0.8533\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7840 - val_loss: 0.2275 - val_auc: 0.8523\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7889 - val_loss: 0.2283 - val_auc: 0.8509\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.7983 - val_loss: 0.2278 - val_auc: 0.8524\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2459 - auc: 0.8006 - val_loss: 0.2270 - val_auc: 0.8512\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2464 - auc: 0.8011 - val_loss: 0.2262 - val_auc: 0.8494\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2462 - auc: 0.8018 - val_loss: 0.2268 - val_auc: 0.8470\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.8044 - val_loss: 0.2264 - val_auc: 0.8479\n",
      "Model: \"sequential_154\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_462 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_463 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_464 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_465 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.8964 - auc: 0.6759 - val_loss: 0.3005 - val_auc: 0.8397\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2789 - auc: 0.7693 - val_loss: 0.2337 - val_auc: 0.8504\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2543 - auc: 0.7730 - val_loss: 0.2292 - val_auc: 0.8549\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7824 - val_loss: 0.2275 - val_auc: 0.8530\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.7884 - val_loss: 0.2282 - val_auc: 0.8519\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.7970 - val_loss: 0.2275 - val_auc: 0.8524\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2463 - auc: 0.7996 - val_loss: 0.2269 - val_auc: 0.8515\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2468 - auc: 0.7995 - val_loss: 0.2263 - val_auc: 0.8479\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2465 - auc: 0.7994 - val_loss: 0.2275 - val_auc: 0.8509\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2463 - auc: 0.8052 - val_loss: 0.2263 - val_auc: 0.8460\n",
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_465 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_466 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_467 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_468 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.8929 - auc: 0.6759 - val_loss: 0.2993 - val_auc: 0.8395\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2784 - auc: 0.7686 - val_loss: 0.2334 - val_auc: 0.8498\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2544 - auc: 0.7724 - val_loss: 0.2289 - val_auc: 0.8540\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7811 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2482 - auc: 0.7875 - val_loss: 0.2280 - val_auc: 0.8527\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2468 - auc: 0.7953 - val_loss: 0.2273 - val_auc: 0.8537\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2467 - auc: 0.7973 - val_loss: 0.2267 - val_auc: 0.8491\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2470 - auc: 0.7997 - val_loss: 0.2264 - val_auc: 0.8511\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2467 - auc: 0.7995 - val_loss: 0.2273 - val_auc: 0.8505\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2467 - auc: 0.8033 - val_loss: 0.2265 - val_auc: 0.8475\n",
      "Model: \"sequential_156\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_468 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_469 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_470 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_471 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.8895 - auc: 0.6760 - val_loss: 0.2981 - val_auc: 0.8378\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2779 - auc: 0.7681 - val_loss: 0.2331 - val_auc: 0.8490\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7717 - val_loss: 0.2287 - val_auc: 0.8525\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7794 - val_loss: 0.2276 - val_auc: 0.8528\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.7871 - val_loss: 0.2278 - val_auc: 0.8552\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.7944 - val_loss: 0.2272 - val_auc: 0.8520\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7965 - val_loss: 0.2266 - val_auc: 0.8489\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.7988 - val_loss: 0.2268 - val_auc: 0.8505\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7992 - val_loss: 0.2269 - val_auc: 0.8450\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.8029 - val_loss: 0.2268 - val_auc: 0.8480\n",
      "Model: \"sequential_157\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_471 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_472 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_473 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.837400455635975 0.007800000000000002\n",
      "[0.8358581480212093, 0.8355476704098708, 0.8355013003770085, 0.8356767000665309, 0.8361625773673919, 0.8364891836858127, 0.8372492490070764, 0.8373944073708193, 0.837400455635975, 0.8370577206104716]\n",
      "0.21067087416049365 0.007800000000000002\n",
      "[0.21606068705369383, 0.2164855150878699, 0.21561231951988016, 0.21624150117026683, 0.21560207057887182, 0.21393756531489055, 0.2116185479355525, 0.21079147437002901, 0.21067087416049365, 0.21162101071917122]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0.007, 0.008, 0.0001)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=i, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJoAAAHiCAYAAACgIKaNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeZzV1X3/8deHRVEUXMAVWTRoEG1QRwzGHRckbUxsYrWJiSYRNdE2NpsmNrHm18amMVsbRTRGk8YYY6tViwsqLklQgbjvS0AQF3AjiLLN5/fH+U7nMo4wwMCdGV7Px+M+5t5zz/fez/Uqybw553MiM5EkSZIkSZLWVLd6FyBJkiRJkqSuwaBJkiRJkiRJ7cKgSZIkSZIkSe3CoEmSJEmSJEntwqBJkiRJkiRJ7cKgSZIkSZIkSe3CoEmSJEmSJEntwqBJkiRJkiRJ7cKgSZIkSZIkSe3CoEmSJGkti4gzI+LZiPhzRDwWER+rxs+JiP+smTc4IjIielSPt4iIn0fEnIh4PSKurddnkCRJaose9S5AkiRpPfAssD/wEvAJ4D8j4n1tuO6XwAJgePVz37VWoSRJUjuIzKx3DZIkSeuViHgA+DawB/C+zPxUNT4Y+BPQE+gPvABsmZmv16dSSZKkVePWOUmSpLUsIj4dEQ9ExBsR8QawG9BvJZftALxmyCRJkjoTgyZJkqS1KCIGARcDp1FWJ20GPAIE8Bawcc30bWruzwK2iIjN1lWtkiRJa8qgSZIkae3qDSQwFyAiTqSsaAJ4ADggIgZGRF/grKaLMvNF4EbggojYPCJ6RsQB67Z0SZKkVWPQJEmStBZl5mPA+cAU4GVgd+D31XOTgN8ADwHTgRtaXH48sAR4AngF+NK6qVqSJGn12AxckiRJkiRJ7cIVTZIkSZIkSWoXBk2SJEmSJElqFwZNkiRJkiRJahcGTZIkSZIkSWoXBk2SJEmSJElqFz3qXcDa1K9fvxw8eHC9y5AkSZIkSeoypk+fPi8z+7f2XJcOmgYPHsy0adPqXYYkSZIkSVKXEREz3+s5t85JkiRJkiSpXRg0SZIkSZIkqV0YNEmSJEmSJKldGDRJkiRJkiSpXRg0SZIkSZIkqV0YNEmSJEmSJKld9Kh3AZIkSZKktSQT5s2DmTPh1VehsbGMNd1qH7/X/faY11Feo7PV2/Lx0KEwdiwceSQMHlzvf7ukVhk0SZIkSVJn1dgIL75YgqSZM2HGjOb7TbeFC+td5ZqJgG7dys+mW+3jtj7X3vNW5TW6d1/z18uEqVPhhhvKP5dhw0roNHYs7LcfbLBBfb8nqWLQJEmSJEkd1ZIlMGvWu8OjpkBp1qwyp1a/fjBoUAkixowp9wcPhv792xaMdJRQp+mmZpnw5JNw440wcSL85Cdw/vmwySZw6KHNq50GDKh3pVqPRWbWu4a1pqGhIadNm1bvMiRJkiSpdQsXwvPPv/eKpDlzyqqlJhGw7bYlPGoKkJruN916967Xp9G6tmAB3H57CZ0mTizBI8DuuzeHTvvuCz171rdOdTkRMT0zG1p9zqBJkiRJktaSN9987y1tM2bA3LnLz+/Ro6xGaS1AGjy4PLfhhuv+c6jjy4THHiuB0403wt13w9Kl0KcPHHZYCZ7GjIHttqt3peoCDJokSZIkqb1llqCotS1tTbc331z+ml693h0e1T7ebrvSz0daU/Pnw623Nm+zmzOnjI8Y0dzbaZ99SrgprSKDJkmSJElaVcuWNTfabm1F0syZ8Pbby1/Tp897b2lr6pNk3yGta5nw0EPNodMf/lD+/d58czj88ObVTlttVe9K1UkYNEmSJElSS4sXv7vRdm2gNGtW2XpUq3//1gOkpvubbVaPTyKtmjfegEmTmrfZvfxyGW9oaO7ttPferq7TezJokiRJkrT+Wbjwvbe0NTXarv19KKJsXXuvbW0DB9poW11PYyM88EBz6HTPPWVsyy3LKqcjj4QjjiinGUoVgyZJkiRJXc8bb7x3k+2ZM2HevOXn9+gBO+yw4kbbG2yw7j+H1JG8+irccksJnW68sfx3FFH6OR15ZFnxtOee0K1bvStVHRk0SZIkSepcMuGVV1a8Imn+/OWv2WijFW9r23ZbtwJJq6KxEaZPL6udJk6EqVPLf5tbbVVWO40dW3o8bb55vSvVOrbGQVNEjAF+DHQHLsnM81o8PxC4HNismnNmZk6MiJHAhKZpwDmZeU1E7AL8puYldgS+lZk/ioh/A/4KWAw8C5yYmW9ExGDgceDJ6pp7MvOUFdVt0CRJkiR1UMuWla1r77Ui6fnn4Z13lr+mb98VN9ru189G29LaNHcu3HxzCZ1uvhlee62sbBo1qrm304gR/ne4HlijoCkiugNPAYcBs4GpwHGZ+VjNnAnA/Zl5YUTsCkzMzMERsTGwODOXRsS2wIPAdpm5tMXrvwDsk5kzI+Jw4Pbqmn8FyMyvV0HTDZm5W1s/uEGTJEmSVCeLFq240fbs2e9utL3VVitekdS3bz0+iaTWLFsG993X3Ntp+vQyvu22JXA68kg47DD/u+2iVhQ09WjD9SOBZzLzuerFrgSOAh6rmZNAn+p+X2AOQGYurJnTq5rX0mjg2cycWV1zS81z9wAfb0ONkiRJktalt9567y1tM2bASy+9u9H29tuXwGjffVtvtL3xxnX6MJJWWffuZSXTqFHwne+U/+ZvuqmETv/1X3DppaUv2r77ltVOY8fCbru52mk90JagaXtgVs3j2cA+LeacA9wSEacDvYFDm56IiH2AS4FBwPG1q5kqxwK/fo/3/izLb7EbEhH3A/OBszPz7jbUL0mSJGlNPPssjB9ffjaFSa++uvycnj2bG22PGdN6o+2ePetRvaR1YZtt4IQTym3pUpgypYROEyfCmWeW24ABzQ3FR4+GTTetd9VaC9qyde4TwBGZ+fnq8fHAyMw8vWbOP1SvdX5EjAJ+BuyWmY01c4ZR+jgdkJnvVGMbUFY/Dc/Ml1u87zeBBuDozMyI2BDYJDNfjYi9gGur6+a3uG4cMA5g4MCBe82cOXPV/6lIkiRJKr8s/vCH8O1vl20yO+303tvattnGRtuSWvfCC2W108SJMGkS/PnPJXjef//m3k7DhrnaqRNZ0x5NoyhNvI+oHp8FkJnfrZnzKDAmM2dVj58DPpiZr7R4rcnAVzNzWvX4KOCLmXl4i3mfAU4BRrfYflc75w7gK02v1Rp7NEmSJEmr6Y9/hM9/Hu6/H446Cn7607L1TZLWxOLF8Ic/NPd2euSRMj5oUHPodMgh0Lt3fevUCq0oaOrWhuunAkMjYki1AulY4LoWc56n9FpqWrnUC5hbXdOjGh8E7ALMqLnuOFpsm6tOuPs68JHakCki+leNw4mIHYGhwHNtqF+SJElSWy1cCF/9Kuy9N7z4Ilx9NVxzjSGTpPaxwQZw0EHwve/Bww+Xrbjjx5fT6n7xC/jIR2CLLeCII+BHP4Knnlq+35s6vJWuaAKIiLHAj4DuwKWZ+c8RcS4wLTOvq06auxjYhNLw+2uZeUu1ze5MYAnQCJybmddWr7kxpffTjpn5Zs17PQNsCDRt+r4nM0+JiL8GzgWWAsuAb2fm9Suq2xVNkiRJ0iqYNAlOPhn+9Cc46aTyi+Bmm9W7Kknri0WL4O67m3s7PfFEGd9pp+beTgcdBBttVNcytYZb5zozgyZJkiSpDebNgy9/uawm2HlnmDABDjyw3lVJWt/96U/NodPtt8Pbb0OvXnDwwc3b7Hbaqd5VrpcMmiRJkiS9WyZccQV86UvwxhvlVKhvfrP8IidJHck778Cddzb3dnr66TK+887NodMBB/jn1zpi0CRJkiRpeTNmwKmnlpOg9tkHLr4Ydt+93lVJUts8/XQJnG68ESZPLtvuNt4YRo8uodORR5aTMbVWGDRJkiRJKpYtg5/8BM4+uxwl/i//Al/8InTvXu/KJGn1LFwId9xRVjtNnFi23AEMG1ZWO40dC/vtVxqRq10YNEmSJEmCBx8sTb6nToUPfxguuAAGDqx3VZLUfjLLSXVNodOdd8KSJbDJJnDooc3b7AYMqHelnZpBkyRJkrQ+e/ttOPdc+Ld/gy23LCuajjmmrGiSpK5swYLSSLwpeJo1q4zvvntz6LTvvtCzZ33r7GQMmiRJkqT11eTJMG4cPPMMnHgifP/7sMUW9a5Kkta9THjsseaG4nffDUuXQp8+cPjhzb2dtt223pV2eAZNkiRJ0vrm9dfhK1+BSy8tx39fdFFpkitJKubPh1tvLaHTxIkwZ04Z32OPEjiNHVsOS+jRo751dkAGTZIkSdL6IhN++1v4u7+DefNK2PStb5XTmCRJrcuEhx5qDp3+8IdyeMLmm5fVTmPHwpgxsNVW9a60QzBokiRJktYHs2bBF74AN9wAe+0Fl1wCI0bUuypJ6nzeeAMmTWreZvfyy2W8oaG5t9Pee6+3J3YaNEmSJEld2bJlcOGFcNZZ0NgI3/lOWdHkdg9JWnONjfDAA82h0z33lLEttyyrnI48Eo44Avr1q3el64xBkyRJktRVPfoofP7z5Refww+H8eNhyJB6VyVJXderr8Itt5TQ6cYbyzbliNLPqam30557Qrdu9a50rTFokiRJkrqad96Bf/kXOO+8cmLSj34En/xk+WVHkrRuNDbC9OlltdPEiTB1aun3tNVWZbXT2LHlLwE237zelbYrgyZJkiSpK7n7bjjpJHjySfjUp+AHP4D+/etdlSRp7ly4+eYSOt18M7z2WlnZNGpUCZ2OPRZ23LHeVa6xFQVNXXcdlyRJktTVvPkmnHIKHHAALFoEN90Ev/ylIZMkdRT9+5e/ALjiCnjllXJ63Te+UVahfvOb8Mc/1rvCtc4VTZIkSVJncM018MUvlpOPvvQlOPdc6N273lVJktrqpZfKVueNN653JWtsjVc0RcSYiHgyIp6JiDNbeX5gREyOiPsj4qGIGFuNj4yIB6rbgxHxsWp8l5rxByJifkR8qXpui4iYFBFPVz83r8YjIn5S1fBQROy5uv9AJEmSpE5jzhw4+uhy23pruPdeOP98QyZJ6my22aZLhEwrs9KgKSK6Az8FjgR2BY6LiF1bTDsbuCoz9wCOBS6oxh8BGjJzBDAGuCgiemTmk5k5ohrfC1gIXFNdcyZwW2YOBW6rHlO9/9DqNg64cHU+sCRJktQpNDaWE+SGDSunGp13Htx3HzS0+hfIkiR1CG1Z0TQSeCYzn8vMxcCVwFEt5iTQp7rfF5gDkJkLM3NpNd6rmtfSaODZzJxZPT4KuLy6fznw0ZrxX2RxD7BZRGzbhvolSZKkzuWJJ+DAA+HUU0uw9PDD8PWvQ8+e9a5MkqQVakvQtD0wq+bx7Gqs1jnApyJiNjAROL3piYjYJyIeBR4GTqkJnpocC/y65vHWmfkiQPVzq1WoQ5IkSeq8Fi8uvZc+8AF49FG49FK49VZ43/vqXZkkSW3SlqApWhlruTLpOOCyzBwAjAV+GRHdADLz3swcDuwNnBURvf7vhSM2AD4C/Lad6iAixkXEtIiYNnfu3Da8rCRJktQBTJkCe+4J3/526cf0+ONw4okQrf3fYEmSOqa2BE2zgR1qHg+g2hpX43PAVQCZOYWyTa5f7YTMfBx4C9itZvhI4I+Z+XLN2MtNW+Kqn6+sQh1k5oTMbMjMhv4e8ypJkqSObv58OO00+NCHyv0bboBf/7o0/pYkqZNpS9A0FRgaEUOqFUjHAte1mPM8pdcSETGMEjTNra7pUY0PAnYBZtRcdxzLb5ujeu3PVPc/A/xPzfinq9PnPgi82bTFTpIkSeqUrr8ehg+HCy6A008v2+U+/OF6VyVJ0mrrsbIJmbk0Ik4Dbga6A5dm5qMRcS4wLTOvA74MXBwRZ1C2s52QmRkR+wFnRsQSoBH4QmbOA4iIjYHDgJNbvOV5wFUR8TlKgPWJanwiZVveM5RT6k5ckw8uSZIk1c1LL8Hf/R389rew227l5wc/WO+qJElaY5HZ2kFwXUNDQ0NOmzat3mVIkiRJRWZp8P2Vr8DChfCP/whf+xpssEG9K5Mkqc0iYnpmNrT23EpXNEmSJElqB08/DePGwR13wAEHwIQJsMsu9a5KkqR21ZYeTZIkSZJW15Il8N3vwu67w/33l4Bp8mRDJklSl+SKJkmSJGltue8+OOkkeOgh+Ou/hn//d9h223pXJUnSWuOKJkmSJKm9LVgAZ5wBo0bBvHlwzTVw9dWGTJKkLs8VTZIkSVJ7uvFGOPVUmDmz/Pzud6Fv33pXJUnSOuGKJkmSJKk9zJ0Ln/wkjB0LG20Ed98NF1xgyCRJWq8YNEmSJElrIhMuvxze/3747W/h29+GBx6A/fard2WSJK1zbp2TJEmSVtdzz8HJJ8Ott8K++5YT5YYPr3dVkiTVjSuaJEmSpFW1dCl8//uw225w773w05+WrXKGTJKk9ZwrmiRJkqRV8cc/wkknlZ8f+UgJmQYMqHdVkiR1CK5okiRJktpi4UL46ldh5EiYM6f0Y7r2WkMmSZJquKJJkiRJWplbby29mJ57Dj7/efje92DzzetdlSRJHY4rmiRJkqT38uqrcMIJcNhh0L073HEHXHyxIZMkSe/BoEmSJElqKROuuAKGDYNf/Qq+8Q146CE48MB6VyZJUofm1jlJkiSp1syZcMopcNNNpR/TrbfCX/xFvauSJKlTaNOKpogYExFPRsQzEXFmK88PjIjJEXF/RDwUEWOr8ZER8UB1ezAiPlZzzWYRcXVEPBERj0fEqGr8NzXXzIiIB6rxwRHxds1z49vnH4EkSZIELFsGP/oRDB8Od99d7v/hD4ZMkiStgpWuaIqI7sBPgcOA2cDUiLguMx+rmXY2cFVmXhgRuwITgcHAI0BDZi6NiG2BByPi+sxcCvwYuCkzPx4RGwAbA2Tm39S89/nAmzXv82xmjliDzytJkiS920MPlSbfU6fC2LFwwQUwaFC9q5IkqdNpy4qmkcAzmflcZi4GrgSOajEngT7V/b7AHIDMXFiFSgC9qnlERB/gAOBn1bzFmflG7QtGRADHAL9e1Q8lSZIktcnbb5f+S3vtBTNmlL5MN9xgyCRJ0mpqS9C0PTCr5vHsaqzWOcCnImI2ZTXT6U1PRMQ+EfEo8DBwShU87QjMBX5ebbe7JCJ6t3jN/YGXM/PpmrEh1fw7I2L/1oqNiHERMS0ips2dO7cNH0+SJEnrpcmTy7a4734XPvUpePxxOO44iKh3ZZIkdVptCZpa+1/abPH4OOCyzBwAjAV+GRHdADLz3swcDuwNnBURvShb9vYELszMPYC3gJa9n45j+dVMLwIDq/n/AFxRrYxavrDMCZnZkJkN/fv3b8PHkyRJ0nrl9dfLNrlDDoHGRpg0CX7+c9hyy3pXJklSp9eWoGk2sEPN4wFUW+NqfA64CiAzp1C2yfWrnZCZj1MCpd2q15ydmfdWT19NCZ4AiIgewNHAb2quX5SZr1b3pwPPAju3oX5JkiQJMuG3v4Vhw+Cyy+BrX4OHH4ZDD613ZZIkdRltCZqmAkMjYkjVtPtY4LoWc54HRgNExDBK0DS3uqZHNT4I2AWYkZkvAbMiYpfq+tFAbXPxQ4EnMnN200BE9K8akxMROwJDgedW6dNKkiRp/TRrFhx1FBxzDGy/fWn6/a//ChtvXO/KJEnqUlZ66lx1YtxpwM1Ad+DSzHw0Is4FpmXmdcCXgYsj4gzKtroTMjMjYj/gzIhYAjQCX8jMedVLnw78qgqvngNOrHnbY3l3E/ADgHMjYimwjNLv6bXV/NySJElaHzQ2woUXwplnwrJl8P3vw9//PfRY6f8NliRJqyEyW7Zb6joaGhpy2rRp9S5DkiRJ9fDoo3DSSTBlChx2GIwfDzvuWO+qJEnq9CJiemY2tPZcW7bOSZIkSZ3HokXw7W/DHnvAU0/BL34BN99syCRJ0jrgmmFJkiR1Hb/7XVnF9MQT8MlPwg9/CJ5ELEnSOuOKJkmSJHV+b74Jp54K++8Pb78NN94I//mfhkySJK1jBk2SJEnq3K65BnbdFSZMgDPOgEcegTFj6l2VJEnrJYMmSZIkdU5z5sDRR5db//5wzz3wgx/AJpvUuzJJktZbBk2SJEnqXBob4aKLYNiwskXuu9+FqVNh773rXZkkSes9m4FLkiSp83jiCRg3Du6+Gw4+uAROQ4fWuypJklRxRZMkSZI6vsWL4TvfgQ98oPRg+tnP4LbbDJkkSepgXNEkSZKkjm3KFDjpJHj0Ufibv4Ef/xi23rreVUmSpFa4okmSJEkd05//DKefDh/6ELz5Jlx/PVx5pSGTJEkdmEGTJEmSOp4bboBdd4Wf/hS++EV47DH4y7+sd1WSJGklDJokSZLUcbz8ctke91d/BX37wu9/D//+77DppvWuTJIktYFBkyRJkuovEy69FIYNg2uvLY2///hHGDWq3pVJkqRVYDNwSZIk1dfTT8PJJ8PkybD//jBhArz//fWuSpIkrYY2rWiKiDER8WREPBMRZ7by/MCImBwR90fEQxExthofGREPVLcHI+JjNddsFhFXR8QTEfF4RIyqxs+JiBdqrhtbc81ZVQ1PRsQRa/7xJUmSVDdLlsB558Ff/AVMnw7jx8MddxgySZLUia10RVNEdAd+ChwGzAamRsR1mflYzbSzgasy88KI2BWYCAwGHgEaMnNpRGwLPBgR12fmUuDHwE2Z+fGI2ADYuOb1fpiZ329Rx67AscBwYDvg1ojYOTOXrd5HlyRJUt1MnQonnQQPPghHH136MG23Xb2rkiRJa6gtK5pGAs9k5nOZuRi4EjiqxZwE+lT3+wJzADJzYRUqAfSq5hERfYADgJ9V8xZn5hsrqeMo4MrMXJSZfwKeqWqTJElSZ7FgAfzDP8AHPwivvAL//d/wX/9lyCRJUhfRlqBpe2BWzePZ1Vitc4BPRcRsymqm05ueiIh9IuJR4GHglCp42hGYC/y82m53SUT0rnm906oteJdGxOarUIckSZI6qptugt12gx/+EMaNg8cfh499bOXXSZKkTqMtQVO0MpYtHh8HXJaZA4CxwC8johtAZt6bmcOBvYGzIqIXZcvensCFmbkH8BbQ1PvpQmAnYATwInD+KtRBRIyLiGkRMW3u3Llt+HiSJElaa15/vaxY+sQn4MgjYaON4K674MILoW/felcnSZLaWVtOnZsN7FDzeADV1rganwPGAGTmlCpM6ge80jQhMx+PiLeA3arXnJ2Z91ZPX00VNGXmy03XRMTFwA2rUAeZOQGYANDQ0PCuIEqSJElr0dKlcN99cMst5XbvvdDYCJtuCt/6FnzjG7DhhvWuUpIkrSVtCZqmAkMjYgjwAqUh99+2mPM8MBq4LCKGUfoxza2umVU1Ax8E7ALMyMx5ETErInbJzCerax8DiIhtM/PF6nU/RmkoDnAdcEVE/IDSDHwocN/qfWxJkiS1mz/9CW6+uQRLt90G8+dDt26w997wzW/C4YfDPvtAz571rlSSJK1lKw2aqpDoNOBmoDtwaWY+GhHnAtMy8zrgy8DFEXEGZTvbCZmZEbEfcGZELAEagS9k5rzqpU8HflWdOPcccGI1/r2IGFG9zgzg5KqORyPiKkogtRT4oifOSZIk1cH8+TB5cvOqpWeeKeM77ADHHFOCpdGjYYst6lunJEla5yKz6+4ua2hoyGnTptW7DEmSpM5t2TKYPr05WJoypWyR690bDj64BEuHHw477wzRWltNSZLUlUTE9MxsaO25tmydkyRJ0vrm+eebg6Vbby1NvQH22gu++tUSLI0aZb8lSZK0HIMmSZIkwYIFcOedzeHSE0+U8e22g6OOgiOOKNvh+vevb52SJKlDM2iSJElaHzU2wgMPNAdLv/sdLFkCG20EBx4I48aVVUu77up2OEmS1GYGTZIkSeuLOXNg0qRyQtykSTCvOqPlAx+AL32pBEv77Qe9etW3TkmS1GkZNEmSJHVVb78Nd93VvGrpkUfK+FZbwZgxJVg67DDYZpv61ilJkroMgyZJkqSuIhMefrg5WLrrLli0qDTs3n9/+PSnS7i0++7QrVu9q5UkSV2QQZMkSVJn9vLLZRvcLbeUny+9VMaHD4cvfKEESwccABtvXN86JUnSesGgSZIkqTN55x34/e+bVy098EAZ33LLsg3uiCPKz+23r2+dkiRpvWTQJEmS1JFlwuOPNwdLd9xRei/17Akf+hD8y7+UVUt77OF2OEmSVHcGTZIkSR3NvHlw223ldLhbboEXXijju+wCn/98CZYOOgg22aSuZUqSJLVk0CRJklRvixfDlCnNq5amTy8rmTbbDA49tHk73KBB9a5UkiRphQyaJEmS1rVMePrp5mBp8mRYsAC6d4dRo+Cf/qmsWmpoKGOSJEmdhEGTJEnSuvD663D77c3b4WbOLOM77QTHH1+CpYMPhr5961unJEnSGjBokiRJWhuWLoV7721etXTffdDYCH36wOjRcOaZZTvcTjvVu1JJkqR2Y9AkSZLUXp57rjlYuu02mD+/nAQ3ciScfXZZtTRyZDkxTpIkqQtqU9AUEWOAHwPdgUsy87wWzw8ELgc2q+acmZkTI2IkMKFpGnBOZl5TXbMZcAmwG5DAZzNzSkT8G/BXwGLgWeDEzHwjIgYDjwNPVq93T2aeslqfWpIkqT3Mn1+2wzWFS88+W8YHDoS/+ZsSLI0eDZtvXt86JUmS1pGVBk0R0R34KXAYMBuYGhHXZeZjNdPOBq7KzAsjYldgIjAYeARoyMylEbEt8GBEXJ+ZSynB1U2Z+fGI2ADYuHqtScBZ1TX/CpwFfL167tnMHLGmH1qSJGm1LFsG06Y1B0tTppSx3r1Lf6UvfamES0OHQkS9q5UkSVrn2rKiaSTwTGY+BxARVwJHAbVBUwJ9qvt9gTkAmbmwZk6vah4R0Qc4ADihmreYsoKJzLyl5pp7gI+vygeSJElqV88/3xws3XpraeodAXvtBV//egmWRo2CDTaod6WSJEl115agaXtgVs3j2cA+LeacA9wSEacDvYFDm56IiH2AS4FBwPHVSqUdgbnAzyPiA8B04O8z860Wr/tZ4Dc1j4dExP3AfODszLy7DfVLkiS13YIFcOedzQqox+IAACAASURBVKfDPVnt2t9+e/joR0uwdOih0K9ffeuUJEnqgNoSNLW27jtbPD4OuCwzz4+IUcAvI2K3zGzMzHuB4RExDLg8Im6s3ndP4PTMvDcifgycCfzj/71pxDeBpcCvqqEXgYGZ+WpE7AVcGxHDM3P+csVGjAPGAQwcOLANH0+SJK3XGhvh/vubVy39/vewZAlstBEcdBCcckoJl4YNczucJEnSSrQlaJoN7FDzeADV1rganwPGAFQNvXsB/YBXmiZk5uMR8Ral+fdsYHYVQgFcTQmaAIiIzwB/CYzOzKyuXwQsqu5Pj4hngZ2BabWFZOYEqgbkDQ0NLQMxSZIkeOEFmDSpBEuTJsG8eWV8xAg444wSLH3oQ9CrV33rlCRJ6mTaEjRNBYZGxBDgBeBY4G9bzHkeGA1cVq1c6gXMra6ZVW2XGwTsAszIzHkRMSsidsnMJ6trH4P/O+Hu68CBtT2eIqI/8FpmLqu23g0Fnlv9jy5JktYbCxfC3Xc3b4d79NEyvvXWcOSRcMQRZTvc1lvXt05JkqRObqVBUxUSnQbcDHQHLs3MRyPiXGBaZl4HfBm4OCLOoGyrOyEzMyL2A86MiCVAI/CFzKz+ypDTgV9VJ849B5xYjf8HsCEwKcry9Hsy8xRK8/BzI2IpsAw4JTNfa49/CJIkqYvJhIceat4Od/fdsGgRbLghHHAAnHBCWbW0++5uh5MkSWpHUe1M65IaGhpy2rRpK58oSZI6v5dfbt4Od8st5THAbruVUOnww2H//WHjjetbpyRJUicXEdMzs6G159qydU6SJKnjeeed0ri7aTvcgw+W8X794LDDSrB02GHltDhJkiStEwZNkiSpc8iExx5rXrF0553w9tvQsyfstx9897slXBoxArp1q3e1kiRJ6yWDJkmS1LE9+CBcdBFcd105LQ7g/e+Hk04qwdKBB8Imm9S3RkmSJAEGTZIkqSN6+2347W9h/HiYMgV69YK//MtyOtzhh8PAgfWuUJIkSa0waJIkSR3HU0+V1UuXXQavvQa77AI//CF8+tOwxRb1rk6SJEkrYdAkSZLqa8kS+J//KauXbrsNevSAj30MTj0VDjoIIupdoSRJktrIoEmSJNXH88/DxRfDJZfASy+V7XD//M/w2c/CNtvUuzpJkiStBoMmSZK07ixbBjffXFYv/e//lpPkPvxhOOUUGDMGunevd4WSJElaAwZNkiRp7Xv5Zbj0UpgwAWbMgK23hrPOKifHDRpU7+okSZLUTgyaJEnS2pEJd95ZVi/993+XXkwHHwzf+x4cdRRssEG9K5QkSVI7M2iSJEnt6/XX4Re/KAHTE0/A5pvDaafBuHHw/vfXuzpJkiStRQZNkiRpzWXC1KklXLrySnj7bdhnH7jsMjjmGNhoo3pXKEmSpHXAoEmSJK2+BQvg178uAdMf/wi9e8Pxx5fm3nvsUe/qJEmStI4ZNEmSpFX3yCMlXPrlL2H+fNh9d7jgAvjkJ6FPn3pXJ0mSpDoxaJIkSW2zaBFcfXUJmH73O9hwQ/jEJ+DUU2HUKIiod4WSJEmqs25tmRQRYyLiyYh4JiLObOX5gRExOSLuj4iHImJsNT4yIh6obg9GxMdqrtksIq6OiCci4vGIGFWNbxERkyLi6ern5tV4RMRPqhoeiog92+cfgSRJWqFnnoGvfQ0GDIBPfQpeegm+/32YPbusaNp3X0MmSZIkAW0ImiKiO/BT4EhgV+C4iNi1xbSzgasycw/gWOCCavwRoCEzRwBjgIsiomkV1Y+BmzLz/cAHgMer8TOB2zJzKHBb9Zjq/YdWt3HAhav4WSVJUlstXQrXXANHHAFDh8IPfgAHHACTJsGTT8KXvwz9+tW7SkmSJHUwbdk6NxJ4JjOfA4iIK4GjgMdq5iTQ1JChLzAHIDMX1szpVc0jIvoABwAnVPMWA4ureUcBB1X3LwfuAL5ejf8iMxO4p1oRtW1mvti2jypJklZq9my45BK4+GKYM6esYvqnf4LPfx62267e1UmSJKmDa0vQtD0wq+bxbGCfFnPOAW6JiNOB3sChTU9ExD7ApcAg4PjMXBoROwJzgZ9HxAeA6cDfZ+ZbwNZN4VFmvhgRW62gju2B5YKmiBhHWfHEwIED2/DxJElazzU2lpVK48fD9deXx0ccARdeCGPHQg9bOkqSJKlt2tKjqbWmC9ni8XHAZZk5ABgL/DIiugFk5r2ZORzYGzgrInpRAq49gQur7XZv0bxFbk3qIDMnZGZDZjb0799/JS8pSdJ6bO5c+N73yta4MWPg97+Hr3yl9GS68Ub4yEcMmSRJkrRK2vL/HmcDO9Q8HkC1Na7G5yg9mMjMKVWY1A94pWlCZj4eEW8Bu1WvOTsz762evprmoOnlpi1xEbFtzWu0pQ5JkrQimeXEuPHjywlyixeX3kv/7//B0UeXk+QkSZKk1dSWFU1TgaERMSQiNqA0+76uxZzngdEAETGM0o9pbnVNj2p8ELALMCMzXwJmRcQu1fWjae75dB3wmer+Z4D/qRn/dHX63AeBN+3PJElSG735JvzHf8Duu5dg6X//F04+GR59FO68E447zpBJkiRJa2ylK5qqnkqnATcD3YFLM/PRiDgXmJaZ1wFfBi6OiDMo29lOyMyMiP2AMyNiCdAIfCEz51UvfTrwqyq8eg44sRo/D7gqIj5HCbA+UY1PpGzLewZYWDNfkiS9l+nTy+qlK66AhQuhoaE0+z72WOjdu97VSZIkqYuJcohb19TQ0JDTpk2rdxmSJK1bCxfClVeWgGnqVNhoI/jbv4VTTilBkyRJkrQGImJ6Zrb6fyzt8ClJUlfx2GNw0UVw+eVlq9yuu8JPfgLHHw+bbVbv6iRJkrQeMGiSJKkzW7QIrrmmrF66807o2RM+/nE49VTYbz+I1g5tlSRJktYOgyZJkjqjP/0JJkyAn/0M5s6FIUPgvPPgxBNhq63qXZ0kSZLWUwZNkiR1FsuWldPixo+Hm24qq5X+6q/K6qXDDoNubTlMVpIkSVp7DJokSero5swpK5cuvhhmzYJtt4V//Ec46SQYMKDe1UmSJEn/x6BJkqSOqLERbr+9rF669tqymumww+BHPyqrmHr2rHeFkiRJ0rsYNHUGy5ZB9+71rkKStC68+ipcdlk5Pe7pp2HLLeGMM+Dkk+F976t3dZIkSdIKGTR1BieeCA88AKNHwyGHwIEHQp8+9a5KktReMmHKlLJ66aqryklyH/oQfOtb5QS5Xr3qXaEkSZLUJgZNncG++5b+HOPHly0T3bvD3nuX0Gn06PK8v4RIUuczfz786lflz/eHHoJNN4XPfa6sXvqLv6h3dZIkSdIqi8ysdw1rTUNDQ06bNq3eZbSfd94pf+N9223lNnVq2VbXq1f5m++m4GmvvaCHGaIkdVgPPFDCpV/9ChYsgBEjyslxf/u3sMkm9a5OkiRJWqGImJ6ZDa0+Z9DUic2fD3fd1Rw8PfxwGe/TBw46qDl4Gj68HIEtSaqft98u2+LGj4d77il/SXDssSVg2ntv/5yWJElSp2HQtL545RWYPLmETrffDs8+W8a32qo5dBo9GoYMqW+dkrQ+efLJ0tj7ssvg9ddhl13glFPgM5+BzTevd3WSJEnSKjNoWl/NnNm82un22+Gll8r4kCHNwdMhh8DWW9e3TknqapYsgWuvLauXbr+9bGc++uiyeunAA129JEmSpE7NoEnlRKPHH28Onu64A958szw3fHjzaqcDD4S+fetaqiR1WjNnwsUXw89+VsL9QYNg3Dj47Gdhm23qXZ0kSZLULtY4aIqIMcCPge7AJZl5XovnBwKXA5tVc87MzIkRMRKY0DQNOCczr6mumQH8GVgGLG0qMCJ+A+xSXbMZ8EZmjoiIwcDjwJPVc/dk5ikrqtugaQWWLYM//rF5tdPvflf6h3TrBg0NzcHTvvvCRhvVu1pJ6riWLYObbiqrlyZOLMH+hz9ctseNGVNOCpUkSZK6kDUKmiKiO/AUcBgwG5gKHJeZj9XMmQDcn5kXRsSuwMTMHBwRGwOLM3NpRGwLPAhsVz2eATRk5rwVvPf5wJuZeW4VNN2Qmbu19YMbNK2CRYvKiXa3317Cp3vvLb88bbhhCZuagqeGBk+0kyQoK5YuvRQmTCgrmbbeGj7/eTjppLKSSZIkSeqiVhQ0tSUxGAk8k5nPVS92JXAU8FjNnAT6VPf7AnMAMnNhzZxe1by2Fh3AMcAhbb1Ga2DDDctJdQcdBOeeC3/+cznRril4Ovvsctt007K9ril4Gj68rIKSpPVBZtl6PH48/Pd/w9Klpdfdv/0bfPSj0LNnvSuUJEmS6qotQdP2wKyax7OBfVrMOQe4JSJOB3oDhzY9ERH7AJcCg4DjM3Np9VRW1yRwUWZOWP4l2R94OTOfrhkbEhH3A/OBszPz7jbUr9Wx6aZl68eHP1wez51bTrRrCp5uuKGM9++/fGPxHXe0ya2kruf11+Hyy0vA9OST5bS400+Hk08up8hJkiRJAtoWNLWWGrRcmXQccFlmnh8Ro4BfRsRumdmYmfcCwyNiGHB5RNyYme8AH8rMORGxFTApIp7IzLtavOavax6/CAzMzFcjYi/g2ogYnpnzlys2YhwwDmDgwIFt+Hhqk/794Zhjyg3g+eebQ6fbboPf/KaMDxrUHDodcghsu239apakNZEJ991XwqUrr4R33oEPfhAuu6z8WWj/OkmSJOld2tKjaRSlifcR1eOzADLzuzVzHgXGZOas6vFzwAcz85UWrzUZ+GpmTmsxfg6wIDO/Xz3uAbwA7JWZs9+jrjuAr7R8rVr2aFpHMuGJJ5qDp8mT4Y03ynO77tocPB10EGy2WV1LlaSVWrAArriiBEz33w+9e8OnPlWae48YUe/qJEmSpLpbUY+mtjTXmQoMjYghEbEBcCxwXYs5zwOjqzcbRunHNLe6pkc1PohymtyMiOgdEZtW472Bw4FHal7vUOCJ2pApIvpXjcmJiB2BocBzbahfa1sEDBsGX/xi6Vkybx5Mmwb/+q8wYABccgl87GOw5ZYwciScdRZMmgQLF678tSVpXXn44fLn2HbblS1xS5fCBRfAnDkldDJkkiRJklZqpSuaACJiLPAjoDtwaWb+c0ScC0zLzOuqk+YuBjahbKv7WmbeEhHHA2cCS4BG4NzMvLYKiq6pXr4HcEVm/nPN+10G3JOZ42vG/ho4F1gKLAO+nZnXr6huVzR1EIsWlVPsmrbZ3Xtv+QVugw3KiXZNPZ723ttGupLWrXfegauvLkHS739fDkY45piyemnUKHvOSZIkSa1Y0YqmNgVNnZVBUwe1YAHcfXdz8PTAA2V8k03KiXZNwdPuu3uinaS145ln4KKL4Oc/h1dfhfe9r4RLJ5xQVl9KkiRJek8rCpra0gxcal+bbAJHHlluULba3XFHCZ1uvx3+93/LeL9+cPDBJXQaPRp22snVBZJW35IlcP31ZfXSpEnQvTt89KMlYDrkEINtSZIkqR24okkdz6xZJXBqai7+wgtlfODA5tVOhxxS+qhIUmvmz4enn4anniq3p58uBxXMmVN6x40bB5/7nH+OSJIkSavBrXPqvDLLL4lNq50mT4bXXivPvf/9zaudDjoINt+8rqVKWsfefhueffbdgdJTT8HLLzfPiyhB9YgR8NnPwtix0MMFvZIkSdLqMmhS19HYWHo6NQVPd91VTq+LgD33bA6e9tsPNt643tVKWlNLl8KMGcuHSE33n3++hNFNtt4adt4Zhg4tP5vu77QTbLRR3T6CJEmS1NUYNKnrWry4nGLXtM3unntKH5aePcuJUU3B08iRnmgndVSNjWVLW2th0rPPlrCpSd++7w6Tmh736VO/zyBJkiStRwyatP54661yol1T8HT//WXFQ+/ecMABzf2dPvABG/9K61JmOd2tZZj01FPlBLiFC5vn9urVHCS1XJ3Uv7+HAkiSJEl1ZtCk9derr8Kdd5bQ6bbb4Mkny/iWWzafaHfIIeUXWH95ldbcn//cHCS1XJ30+uvN87p3hx13XD5Earq//fYGwZIkSVIHZtAkNXnhhebVTrfdBrNnl/EBA5pDp9Gjyy+6klq3aFHZ0tayAfdTT8FLLy0/d4cdWg+TBg92O6skSZLUSRk0Sa3JLFt2mkKnyZPLCiiAXXZpDp4OPhi22KK+tUrr2rJlMHNm62HSzJnLN+Heaqt3b3HbeefShNum/JIkSVKXY9AktUVjIzz0UHPwdNddpedTBOyxR/Nqp/33Lz2fpM4uE158sfUw6dlnS2P9Jn36tN6Ae+hQ2Gyz+n0GSZIkSeucQZO0OpYsgfvuaw6epkxpPtHugx9sDp722Qc22KDe1Urv7dVX390vqennW281z9tww+bwqOXqpK22so+ZJEmSJMCgqd5lqKtYuBB+97sSOt1+O0yfXlaEbLxxWeU0enS5jRhhI2OtewsWlK2gra1Oeu215nndu8OQIa2f6LbDDv67K0mSJGmlDJqkteH11+GOO5qbiz/+eBnfYgs46KDm4GnnnV0JovaxaBE891zrq5PmzFl+7oABrYdJQ4a4Ak+SJEnSGjFoktaFOXNK6NQUPD3/fBnffvuyzW7IkLL6aaONys+23Hr1coXJ+mbZsvLvTmth0owZpZdYk379Wj/R7X3vswm3JEmSpLXGoEla1zJLM+Wm0OmOO+CVV1bvtVYlmFrZ7b1ea4MNXHW1LmXCSy+9e4vb00+X7W+LFzfP3XTT1nsmDR0Km29ev88gSZIkab21xkFTRIwBfgx0By7JzPNaPD8QuBzYrJpzZmZOjIiRwISmacA5mXlNdc0M4M/AMmBpU4ERcQ5wEjC3uu4bmTmxeu4s4HPVNX+XmTevqG6DJnUomfDOO6XX06rc3n571eYvWrTqtXXr1n5h1ooCrh492v+fa0f2+uvvDpOaHi9Y0Dxvww1hp53efaLbzjvD1lsbAkqSJEnqUFYUNK30t76I6A78FDgMmA1MjYjrMvOxmmlnA1dl5oURsSswERgMPAI0ZObSiNgWeDAirs/MpdV1B2fmvFbe9oeZ+f0WdewKHAsMB7YDbo2InTNz2co+g9QhRJTAZaONYMst1977LFu26uHUigKt116D2bOXH3vrrfI+q6pnz7UbaNVju+FbbzU34W65OmlezR9v3bqV7ZNDh5bm8bVh0g47lCbdkiRJktTJtWV5wUjgmcx8DiAirgSOAmqDpgT6VPf7AnMAMnNhzZxe1bzVdRRwZWYuAv4UEc9UtU1Zg9eUup7u3WGTTcptbVqyZNXDrBWFWi+91Prc1dne27SCqj23HXbvDn/607vDpNmzl3/v7bcv4dHRRy+/OmnHHW3CLUmSJKnLa0vQtD0wq+bxbGCfFnPOAW6JiNOB3sChTU9ExD7ApcAg4Pia1UxZXZPARZk5oeb1TouITwPTgC9n5utVHfe0qGP7NtQvaW3o2RP69i23tSWzbAVsz0Br3rx3j73zzqrVteWWJUA65JDlw6T3vW/tB3ySJEmS1IG1JWhqrTlIyyUGxwGXZeb5ETEK+GVE7JaZjZl5LzA8IoYBl0fEjZn5DvChzJwTEVsBkyLiicy8C7gQ+E71Ht8Bzgc+28Y6iIhxwDiAgQMHtuHjSeqwIspWuF69YIst1t77NDaufLvh4sUweHAJlNZmLZIkSZLUibUlaJoN7FDzeADV1rganwPGAGTmlIjoBfQD/u+Yrcx8PCLeAnYDpmVm0/a6VyLiGso2uLsy8+WmayLiYuCGVaiDamXUBCjNwNvw+SSt77p1g969y02SJEmStNra0jF3KjA0IoZExAaUhtzXtZjzPDAaoFq51AuYW13ToxofBOwCzIiI3hGxaTXeGzic0jicqml4k481jVfveWxEbBgRQ4ChwH2r+oElSZIkSZK0dqx0RVN1YtxpwM1Ad+DSzHw0Is6lrEy6DvgycHFEnEHZznZCZmZE7AecGRFLgEbgC5k5LyJ2BK6JcmR3D+CKzLypesvvRcSI6nVmACdXdTwaEVdRmpAvBb7oiXOSJEmSJEkdR+TqnOjUSTQ0NOS0adPqXYYkSZIkSVKXERHTM7OhtefasnVOkiRJkiRJWimDJkmSJEmSJLULgyZJkiRJkiS1C4MmSZIkSZIktYsu3Qw8IuYCM+tdRzvpB8yrdxFaI36HnZ/fYefm99f5+R12fn6HnZvfX+fnd9j5+R12fl3lOxyUmf1be6JLB01dSURMe6+O7uoc/A47P7/Dzs3vr/PzO+z8/A47N7+/zs/vsPPzO+z81ofv0K1zkiRJkiRJahcGTZIkSZIkSWoXBk2dx4R6F6A15nfY+fkddm5+f52f32Hn53fYufn9dX5+h52f32Hn1+W/Q3s0SZIkSZIkqV24okmSJEmSJEntwqBpHYmIMRHxZET8//buNEyuqtzb+P0kIYEQIAyJhIyMIRNTmnkmKIMCKnIAxcMROCiCvIiiIIqIogwekeOEijiiCKgIHBExTGEI0IEkhIQhQEJCIASQmczr/bCq7epOJ2Sort1Vff+ua1+pqr2r+tm9UpXuf9Z69vSIOLuN/T0i4o+l/Q9ExJCyfeeUHn8iIg4qPTY0IiaWbW9ExBmlfRtFxG0R8VTpzw2rdZ71rMpjeFREPBYRSyOirq9IUE1VHsNLI+LxiJgcEX+JiN7VOs96VuUx/GZp/CZGxD8iYrNqnWe9qub4lT3vixGRImKT9j6/zqDK78HzI+L5sn2HVus861m134cR8bnS8Y9FxCXVOMd6VuX34B/LHp8REROrdZ71rMpjuENEjC893hgRu1TrPOtZlcdw+4i4PyIejYibImL9ap3nGkkpubXzBnQFnga2ALoDk4DhrY75LHBF6fYxwB9Lt4eXju8BbF56na5tvP6LwODS/UuAs0u3zwYuLvp7UOtbAWM4DBgK3Ak0FH3+9bAVMIYfALqVbl/s+7Amx3D9sn2nN72uW22MX+mxgcCtwExgk6K/B7W+FfAePB/4YtHnXU9bAWO4P/BPoEfpft+ivwe1vBXxOVq273+A84r+HtT6VsB78B/AIaXbhwJ3Fv09qPWtgDF8CNi3dPsE4JtFfw9WZnNGU3XsAkxPKT2TUloIXAMc0eqYI4Bfl25fD4yJiCg9fk1KaUFK6Vlgeun1yo0Bnk4pzWzjtX4NfLiiZ9M5VXUMU0rTUkpPtNO5dFbVHsN/pJQWl/aNBwZU/Iw6n2qP4Rtl+9YFbGq4Zqr9byHAZcCXcOwqpYgxVGVVewxPAS5KKS0ASCm9VPEz6lwKeQ+Wnv8fwB8qejadU7XHMAFNM2A2AOZU9Gw6p2qP4VDg7tLt24AjK3o27cSgqTr6A7PK7s8uPdbmMaVfTl8HNl7J5x5Dyw/+96WUXii91gtA3zWsX9UfQ1VekWN4AnDLalWtclUfw4i4MCJmAZ8AzlvD+ju7qo5fRBwOPJ9SmlSJ4gUU8zl6WuQlrFeFrQAqodpjuA2wd2npyF0RsfMan0HnVtTPMnsDc1NKT6125WpS7TE8A7i09LPMd4Fz1rB+VX8MpwCHl24fRZ6t3eEZNFVHtPFY6/9dXd4xK3xuRHQn/8W7brWr08pwDGtfIWMYEecCi4GrV7pSLU/VxzCldG5KaSB5/E5bpWrVWtXGLyJ6AudiOFhp1X4P/gTYEtgBeIG8dEdrptpj2A3YENgNOAu4tvS/+lo9Rf08eiz+h2ilVHsMTwE+X/pZ5vPAL1apWrWl2mN4AnBqREwA1gMWrlK1BTFoqo7ZtEweB7DstMV/HxMR3chTG19dieceAjycUppb9tjciOhXeq1+gNOU11y1x1CVV/UxjIjjgQ8Bn0ilhdVaI0W+D39PjUxV7sCqOX5bknsfTIqIGaXjH46ITStyJp1XVd+DKaW5KaUlKaWlwM9ZdnmBVl21P0dnA39O2YPAUsDG/KuviJ9lugEfBf5YgfpV/TE8Hvhz6fZ1+DlaCdX+t/DxlNIHUkqjyYHv0xU6j3Zl0FQdDwFbR8TmpZTyGODGVsfcSP4gAPgYcHvpF9MbgWNKnes3B7YGHix7Xlv/w1D+WscDf63YmXRe1R5DVV5VxzAiDga+DByeUnqn4mfTOVV7DLcuu3s48HjFzqRzqtr4pZQeTSn1TSkNSSkNIf9gt1NK6cX2OLFOpNrvwX5ldz9CXj6gNVPtn2duAA4AiIhtyI1zX67g+XQ2Rfw8eiDweEppdgXPozOr9hjOAfYt3T4AcPnjmqv2v4V9S392Ab4KXFHh82kfrbuDu7XPRu7y/yQ5gTy39NgF5F9CAdYmp8zTyX/Ztih77rml5z1B6aoBpcd7Aq8AG7T6WhsDY8kfJGOBjYo+/3rYqjyGHyH/YrQAmAvcWvT518NW5TGcTl6DPbG0ecWy2hvDP5F/sZ0M3AT0L/r8a32r5vi1+roz8KpzNTeGwG+BR0vvwRuBfkWffz1sVR7D7sDvSp+lDwMHFH3+tb5V+3MU+BXwmaLPu562Kr8H9wImkK909gAwuujzr4etymP4/0pf60ngIiCKPv+V2aJUvCRJkiRJkrRGXDonSZIkSZKkijBokiRJkiRJUkUYNEmSJEmSJKkiDJokSZIkSZJUEQZNkiRJkiRJqgiDJkmSJEmSJFWEQZMkSZIkSZIqwqBJkiSpHUXEjIg4sOg6JEmSqsGgSZIkSZIkSRVh0CRJkiRJkqSKMGiSJEmqgojoERHfj4g5pe37EdGjtG+TiLg5Il6LiFcjYlxEdCnt+3JEPB8Rb0bEExExptgzkSRJWr5uRRcgSZLUSZwL7AbsACTgr8BXga8BXwBmA31Kx+4GpIgYCpwG7JxSmhMRQ4Cu1S1bkiRp5TmjSZIkqTo+AVyQUnoppTQP+AbwydK+RUA/YHBKaVFKaVxKKQFLgB7A8IhYK6U0I6X0dCHVS5IkrQSDJkmSpOrYDJhZdn9m6TGAS4HpwD8i4pmIOBsgpTQd149KTAAAIABJREFUOAM4H3gpIq6JiM2QJEnqoAyaJEmSqmMOMLjs/qDSY6SU3kwpfSGltAVwGHBmUy+mlNLvU0p7lZ6bgIurW7YkSdLKM2iSJEmqjj8AX42IPhGxCXAe8DuAiPhQRGwVEQG8QV4ytyQihkbEAaWm4fOBd0v7JEmSOiSDJkmSpOr4FtAITAYeBR4uPQawNfBP4C3gfuDHKaU7yf2ZLgJeBl4E+gJfqWrVkiRJqyByn0lJkiRJkiRpzTijSZIkSZIkSRVh0CRJkiRJkqSKMGiSJEmSJElSRRg0SZIkSZIkqSIMmiRJkiRJklQR3YouoD1tsskmaciQIUWXIUmSJEmSVDcmTJjwckqpT1v76jpoGjJkCI2NjUWXIUmSJEmSVDciYuby9rl0TpIkSZIkSRVh0CRJkiRJkqSKMGiSJEmSJElSRRg0SZIkSZIkqSIMmiRJkiRJklQRBk2SJEmSJEmqiG5FFyDVnXffhVmz4Lnnmv+cPRsGDYK994Zdd4V11im6SkmSJEmSKs6gSVoVS5fC3Lk5PCrfmgKl556DefNaPicC+vTJj6cEa60FO++cQ6e994Y994TevYs5H0mSJEmSKsigSSr35pvLD5CaZiYtWtTyOb16weDBecZSQwMMHJhvN239+0P37vCvf8F998G4cXD33fC978HFF+cgarvtmoOnvfeGfv2KOX9JkiRJktZApJSKrqHdNDQ0pMbGxqLLUEexaBHMmbNseFQeKL32WsvndO0KAwYsGx4NGtT82AYb5LBoVb3zDjz4YA6dxo2D+++Ht9/O+7baqjl02mcf2GKL1fsakiRJkiRVWERMSCk1tLnPoEl1IaU8Y2hFs5HmzMlL38pttFHb4VHT1q9fDpuqYdEimDixOXi65x545ZW8r1+/5tBp771h5EjoYi9/SZIkSVL1GTSp9s2fn5ettRUgNT3WNBuoSffubYdH5aHSuusWcz4rY+lSmDYth05Ny+1mz877evfOvZ2agqfRo/P5SpIkSZLUzgya1LEtXZobZbcOj8pDpblzl33e+9634tlIffrU16yflGDmzJbB0xNP5H3rrJOvZtcUPO2+e8cO0SRJkiRJNcugScV6662Ws5Baz0iaNQsWLmz5nJ49c4Pt5c1G6t8f1l67mPPpSF56KS+xa1puN3FiDu66ds2znJr6PO21F2y8cdHVSsVZvDj3RVt//aIrkSRJkmqeQZPaz+LF8MILK26w/eqrLZ/TpQtsttmKZyNtuKHNr1fHG2/kpuJNwdODD8KCBXnfiBEtr2w3cGCxtUrtIaX8uTNlSt4efTT/OW1aDrT794dRo1puw4ZBjx5FVy5JkiTVDIMmrZ6U4PXXV9xg+/nnYcmSls/r3XvFvZH69YO11irmnDqb+fPhoYeal9vdey+8+WbeN2RIywbj22xjuKfa8tJLywZKjz3W/Hcc8ufQyJF523BDmDo1H9sUPEGeAbj11ssGUJtvXl/LbyVJkqQKMWhS2xYufO8G2+W/sEEOiAYMWP5spIEDXZrSkS1ZApMmtezzNG9e3te3b15i1xQ8bb999a64J63IG2/kAKk8UJoypfnvLuSloaNGNYdKI0fmWXy9e7f9mosWwVNPNb9m0/bMM83HrLtufo2m120KoPr2bd/zlSRJkjo4g6bOKCV4+eUVN9h+8cV8XLk+fVY8G+l97/N/+OtJSvDkky2Dpxkz8r711oM99mgOnnbe2b5Yal/z58Pjj7cMk6ZMyZ9XTdZdt2WY1BQC9e1bmRl5b72VQ62mGpoCqPJQq2/fZWc/DR9uA35JkiR1GlUPmiLiYOByoCtwZUrpolb7zwROAhYD84ATUkozS/v+DuwG3JNS+lDZcwL4FnAUsAT4SUrpf1dUR10HTe+8894NtufPb/mctdduOzxqCpUGDsxXL1PnNnt2c+g0blz+pRtyD5tddmnu8bTHHs5e0+pZvBimT28ZJk2ZkmcYLV2aj1lrrdw7qXWgNGhQMWH33LktZz49+mh+b7z7bt4fAVtssWwAtdVW0K1b9euVJEmS2lFVg6aI6Ao8CbwfmA08BBybUppadsz+wAMppXci4hRgv5TS0aV9Y4CewKdbBU2fAvYH/iultDQi+qaUXlpRLXUTNF19NTzwQMtA6eWXWx4TkXsfrWg20sYb24NHq+6VV3Jvp6bgacKEvASvSxfYYYeWDcZdUqRyrRtzN23TpjU3qY/IYUx5mDRyZH6so/dyW7IEnn122QCqPDDr0SPPdmq9/G6zzfw8liRJUs2qdtC0O3B+Sumg0v1zAFJK31nO8TsCP0wp7Vn22H7AF1sFTQ8CH08pTV/ZWuomaDrySLjtthXPRurfH7p3L7pSdQZvvQXjxzcvt7v//ubZc0OHNodO++wDgwf7y3RnUd6Yu3wr7/M2YMCygdK220LPnsXV3R7efTeHaa2X382Z03zMhhsuO/tpxAjYYIPi6pYkSZJW0oqCpvaYz98fmFV2fzaw6wqOPxG4ZSVed0vg6Ij4CHm53ekppadWu8pa8oc/GCKp4+jVCw48MG+Qm8pPmNAcPF1/PVx5Zd43YEDLK9sNG2aPr1pX3pi7fHupbILpRhvl4OT441euMXe9WWcd2GmnvJV75ZVlm4//5jctw7hBg5YNoIYO9d8ASZIk1Yz2CJramr7Q5rSpiDgOaAD2XYnX7QHMTyk1RMRHgauAvdt4zZOBkwEGDRq0sjV3bP6CoY6se3fYffe8felLecnQlCnNfZ7uvDOHpZADiPIr2+24Y8dfHtVZNTXmbh0ozZzZfExTY+7DDmvZoPt973MmW1s23hj23TdvTZqWF7ZefnfrrbmXFeQeT9tu23Lp3ahRzhiUJElSh1TY0rmIOBD4AbBv615Ly1k69zhwcEppRqkx+GsppRWuMaibpXNSLUspXzK+vMH49NIK2HXXzQFV03K7XXetv2VUHd3ixfD00y3DpNZ9hlo35m7aBg92hlp7WbgQnnhi2RlQ5UHfeuu1DJ+abm+8cXF1S5IkqVOodo+mbuRm4GOA58nNwD+eUnqs7JgdgevJwdEyy9+WEzRdBDyZUrqqtP/SlNLOK6rFoEnqoF54oXmp3bhxMHlyDqTWWgsaGpqDpz33zL1stOZSyhcTaB0oLa8xd/m29dbOPOso3nijZfjUdPvVV5uP6ddv2eV3w4Z5VVFJkiRVTFWDptIXPBT4PtAVuCqldGFEXAA0ppRujIh/AqOAF0pPeS6ldHjpueOAbYFewCvAiSmlWyOiN3A1MAh4C/hMSmnSiuowaJJqxGuv5SvbNQVPDz0Eixbl4GPUqJZXtttss6Kr7fjmzWsZJq2oMXf5NmyYM8pqUUo5vG29/G7q1OYQsUuXHBi2Xn63xRbQtWux9UuSJKnmVD1o6igMmqQa9e678MADzcHTfffB22/nfVtu2fLKdltu2Xn71Lz5ZnNj7vJAqa3G3K1Dpc7SmLszW7w4L1Ntvfzu6adzOAV5ltOIES2X3o0aZZ8tSZIkrZBBk6TatmgRTJzY3OfpnnvyFbwANt205ZXtRo6svxkaCxY0N+YuD5RaN+YeMaJlmGRgoLa8/Xae7dR6+d3cuc3HbLLJssvvRozIV52UJElSp2fQJKm+LF2ag5fyBuOzZuV9G2yQezs1BU8NDbVz5cYlS/Jsk/IwacqU3Jh7yZJ8zFprNV+BrClMsjG3KmHevGWX3z32WPNsQoDNN182gNpmm3xlPEmSJHUaBk2S6t/Mmc2h07hxOYgCWHtt2G235uV2u+9e/KyMlGD27GUDpWnTYP78fExEXhbYOlCyMbeqaelSmDFj2QDqySebw8/u3XN/r9bL7wYMcDadJElSnTJoktT5vPRSXmLXFDw98kj+pblrV9hpp+bgaa+98jKh9vLyy8sGSlOm5KuHNenfv2WYZGNudXTz5+cwt3zp3aOP5gC1Se/eyzYftz+YJElSXTBokqQ33oD7729ebvfgg81X5Bo+vGWD8YEDV/31yxtzl2/lfW823LDlL9wjR+a+NxtuWJlzlIr2r38t23x8yhR4/fXmYwYMWHb53bbbQo8exdUtSZKkVWLQJEmtzZ8PjY3NwdO99+awCHK/o/IG40OHNi8BKm/MXb7NmNH82j17LnuVt5Ejc+NylxKpsylfKlq+TZuWG/1Dnmk4dOiyy++GDLH3mCRJUgdk0CRJ72XJEpg8uWWD8Zdeyvv69IEdd8wNx8t707RuzN20+cux9N4WLcrvp9bL7559tvmYXr3yrL+m4OnAA/MMREmSJBXKoEmSVlVK+WpvTaHT5Mk5QCoPlLbeunauaCfViqZlqK1nQL3ySt5/yCFw1lmw337OEJQkSSqIQZMkSapdKcGcOfDLX8IPfpBnG44enQOnI4+Ebt2KrlCSJKlTWVHQ5NoOSZLUsUXkqzN+9aswcyb89Kd55tMxx8A22+Tw6e23i65SkiRJGDRJkqRasvbacPLJuZn4DTfAZpvB6afDoEHwta+1vNKjJEmSqs6gSZIk1Z4uXeCII+Cee+C++2DffeHCC/NVI08+GZ54ougKJUmSOiWDJkmSVNt23x3+/Gd4/HH41Kfgt7+FYcPgwx+Ge+8tujpJkqROxaBJkiTVh222gZ/8JPdx+trX8mynvfaCPfbIQdSSJUVXKEmSVPcMmiRJUn3p2xe+8Y0cOP3wh7lv05FH5llOV1wB775bdIWSJEl1y6BJkiTVp3XXhVNPhSefhGuvhd694ZRTch+nCy6Al18uukJJkqS6Y9AkSZLqW9eucNRR8MADcNddsOuu8PWv5yvVnXoqPP100RVKkiTVDYMmSZLUOUTAPvvATTfBY4/BscfClVfm3k5HHQUPPlh0hZIkSTXPoEmSJHU+w4fDL34BM2bAl74Et92WZzrtu28OopYuLbpCSZKkmmTQJEmSOq9+/eA734FZs+Cyy3LwdPjhMHJkDqIWLCi6QkmSpJpi0CRJkrTeenDGGTB9Olx9NfToASedBEOG5CDqX/8qukJJkqSaYNAkSZLUZK214OMfh4cfhn/+E7bfHr7yFRg4MAdRM2cWXaEkSVKH1i5BU0QcHBFPRMT0iDi7jf1nRsTUiJgcEWMjYnDZvr9HxGsRcXOr5/wqIp6NiImlbYf2qF2SJIkIGDMG/v53mDQJPvpR+NGPYMstcxD1yCNFVyhJktQhVTxoioiuwI+AQ4DhwLERMbzVYY8ADSml7YDrgUvK9l0KfHI5L39WSmmH0jaxwqVLkiQta7vt4De/gWeeybOabr4ZdtoJDjwwB1EpFV2hJElSh9EeM5p2AaanlJ5JKS0ErgGOKD8gpXRHSumd0t3xwICyfWOBN9uhLkmSpNU3cCB897u5cfgll8C0aXDIIXl53W9+AwsXFl2hJElS4dojaOoPzCq7P7v02PKcCNyykq99YWm53WUR0WN1C5QkSVptG2wAZ50Fzz4Lv/pVntF0/PGwxRY5iHr99aIrlCRJKkx7BE3RxmNtzimPiOOABvJyufdyDrAtsDOwEfDl5bzmyRHRGBGN8+bNW7mKJUmSVlX37jlgmjwZbrkFhg7NAdSgQfnP2bOLrlCSJKnq2iNomg0MLLs/AJjT+qCIOBA4Fzg8pbTgvV40pfRCyhYAvyQv0WvruJ+llBpSSg19+vRZrROQJElaaRFw8MEwdiw0NsKhh8Jll8Hmm+cg6tFHi65QkiSpatojaHoI2DoiNo+I7sAxwI3lB0TEjsBPySHTSyvzohHRr/RnAB8GplS0akmSpDU1ejT84Q8wfTp89rPwpz/lZuKHHJKDKBuHS5KkOlfxoCmltBg4DbgVmAZcm1J6LCIuiIjDS4ddCvQCrouIiRHx7yAqIsYB1wFjImJ2RBxU2nV1RDwKPApsAnyr0rVLkiRVxJAhcPnl8NxzcOGF8Mgj+Sp1DQ05iFq8uOgKJUmS2kWkOv6ftYaGhtTY2Fh0GZIkqbObPx9+97vcLPyJJ2DwYPj85+HEE6FXr6KrkyRJWiURMSGl1NDWvvZYOidJkqRya68NJ50EU6fCjTfmhuFnnAEDB8JXvgIvvlh0hZIkSRVh0CRJklQtXbrAYYfB3XfD+PEwZgxcdFGe4XTSSTBtWtEVSpIkrRGDJkmSpCLsuitcfz08+WReQnf11TB8OBx+eA6i6ri9gSRJql8GTZIkSUXaaiv48Y9z4/Cvfx3uuw/23Rd22y0HUUuWFF2hJEnSSjNokiRJ6gj69IHzz8+B049/DK+8AkcdBUOH5vvvvFN0hZIkSe/JoEmSJKkj6dkTTjklX53u+uthk03g1FNzA/Gvfx3mzSu6QkmSpOUyaJIkSeqIunaFI4+E++/PPZv23BMuuCAHTqecAk89VXSFkiRJyzBokiRJ6sgiYO+94a9/zVelO+44uOqqvKSuKYiSJEnqIAyaJEmSasW228LPfw4zZ8I558Add8Aee8Bee+UgaunSoiuUJEmdnEGTJElSrdl0U7jwwtw4/PLLYfZs+PCHYfjwHETNn190hZIkqZMyaJIkSapVvXrB6afD9Onwhz/AuuvCySfD4MHwrW/Bq68WXaEkSepkDJokSZJqXbducMwx0NgIY8fC6NHwta/BwIE5iHr22aIrlCRJnYRBkyRJUr2IgAMOgL/9DR59FI46Cq64ArbaqjmIkiRJakcGTZIkSfVo5Ej41a/ybKYvfAFuuQV23hn23z8HUSkVXaEkSapDBk2SJEn1rH9/uOQSmDULvvvd3M/pgx+EUaNyELVwYdEVSpKkOmLQJEmS1Bmsv36e2fT00/Cb30CXLvCpT8Hmm8PFF8NrrxVdoSRJqgMGTZIkSZ1J9+7wyU/CpEnw97/D8OFw9tkwaFAOombNKrpCSZJUwwyaJEmSOqMIOOgguO02ePhhOOwwuPxy2GKL5iBKkiRpFRk0SZIkdXY77ghXX52X1Z12GvzlL7DDDvCBD+QgysbhkiRpJRk0SZIkKRs8GC67LC+f+8534NFHc9i00045iFq0qOgKJUlSB2fQJEmSpJY23DD3bZoxA37xC1iwAI47DrbcEr73PXjzzaIrlCRJHZRBkyRJktrWoweccAJMmQI33ZSvUPeFL8DAgTmImjOn6AolSVIH0y5BU0QcHBFPRMT0iDi7jf1nRsTUiJgcEWMjYnDZvr9HxGsRcfNyXvsHEfFWe9QtSZKkNnTpAh/6ENx1FzzwALz//XDppTBkSA6iHnus6AolSVIHUfGgKSK6Aj8CDgGGA8dGxPBWhz0CNKSUtgOuBy4p23cp8MnlvHYD0LvSNUuSJGkl7bILXHcdPPkknHwyXHMNjBwJH/wg3HmnjcMlSerk2mNG0y7A9JTSMymlhcA1wBHlB6SU7kgpvVO6Ox4YULZvLLDMwv9SgHUp8KV2qFmSJEmrYsst4Yc/hOeeg298Ax56CPbfPwdR114LixcXXaEkSSpAewRN/YFZZfdnlx5bnhOBW1bidU8DbkwpvbAGtUmSJKmSNtkEzjsPZs6EK66A11+Ho4+GbbaBH/wA3n676AolSVIVtUfQFG081uYc6og4Dmggz1Ra/gtGbAYcBfzgPb94xMkR0RgRjfPmzVuJciVJkrTG1lkHPv1pmDYN/vxn2HRTOP10GDQIvvY1mDu36AolSVIVtEfQNBsYWHZ/ALDMJUki4kDgXODwlNKC93jNHYGtgOkRMQPoGRHT2zowpfSzlFJDSqmhT58+q1O/JEmSVlfXrvCRj8B998E998Dee8OFF8LgwXDuuTB/ftEVSpKkdtQeQdNDwNYRsXlEdAeOAW4sPyAidgR+Sg6ZXnqvF0wp/V9KadOU0pCU0hDgnZTSVu1QuyRJkiplzz3hhhvyLKePfQy+/W3YbrvcNFySJNWligdNKaXF5H5KtwLTgGtTSo9FxAURcXjpsEuBXsB1ETExIv4dREXEOOA6YExEzI6IgypdoyRJkqpo6FD43e/gH/+AJUty0/CTToJXXy26MkmSVGGR6vgStA0NDamxsbHoMiRJktTknXfg/PPhe9+DjTeG//1f+I//gGirzackSeqIImJCSqmhrX3tsXROkiRJalvPnnDJJfDQQzBwIBxzDBx2GDz3XNGVSZKkCjBokiRJUvXtuCOMHw//8z9wxx0wfDhcfnleWidJkmqWQZMkSZKK0a0bnHkmPPZYvjrdGWfAHnvA5MlFVyZJklaTQZMkSZKKNWQI/O1vcPXV8OyzMHo0fOUr8O67RVcmSZJWkUGTJEmSihcBH/84TJsGxx0H3/kObLcd3H570ZVJkqRVYNAkSZKkjmPjjeGXv4R//hNSgjFj4IQT4NVXi65MkiStBIMmSZIkdTxjxuReTV/+MvzmNzBsGFxzTQ6fJElSh2XQJEmSpI6pZ0+46CKYMAEGD4Zjj4UPfhBmziy6MkmStBwGTZIkSerYtt8e7r8fLrsM7r4bRoyA738fliwpujJJktSKQZMkSZI6vq5d4Ywz4LHHYJ994POfh912g0mTiq5MkiSVMWiSJElS7Rg8GP7v/+APf4DnnoPRo+Hss+Hdd4uuTJIkYdAkSZKkWhMBxxwD06bBf/4nXHwxjBoFY8cWXZkkSZ2eQZMkSZJq00YbwVVX5YApAg48EP7rv+CVV4quTJKkTsugSZIkSbXtgANg8mQ45xy4+moYNgx+/3tIqejKJEnqdAyaJEmSVPvWWQe+/W2YMAGGDIFPfAIOPRRmzCi6MkmSOhWDJkmSJNWP7baD+++Hyy+HceNgxAj43vdg8eKiK5MkqVMwaJIkSVJ96doVTj8dpk6F/feHL3wBdtsNJk4sujJJkuqeQZMkSZLq06BBcNNNcM01MGsWNDTAl78M77xTdGWSJNUtgyZJkiTVrwg4+miYNi1fke6SS2DUKLjttqIrkySpLhk0SZIkqf5ttBFceSXccUdeWveBD8Dxx8PLLxddmSRJdcWgSZIkSZ3HfvvB5Mlw7rnw+9/DsGHwu99BSkVXJklSXTBokiRJUuey9trwrW/Bww/DllvCJz8JhxwCzz5bdGWSJNW8dgmaIuLgiHgiIqZHxNlt7D8zIqZGxOSIGBsRg8v2/T0iXouIm1s95xcRMan0nOsjold71C5JkqROYtQouPde+MEP8p8jRsB3vwuLFxddmSRJNaviQVNEdAV+BBwCDAeOjYjhrQ57BGhIKW0HXA9cUrbvUuCTbbz051NK25ee8xxwWqVrlyRJUifTtSucdhpMnQoHHghnnQW77ppnO0mSpFXWHjOadgGmp5SeSSktBK4Bjig/IKV0R0qp6bqy44EBZfvGAm+2ftGU0hsAERHAOoAL6SVJklQZAwfCX/8K114Lzz8Pu+ySQ6e33y66MkmSakp7BE39gVll92eXHlueE4FbVuaFI+KXwIvAtsAPVrdASZIkaRkRcNRRMG0anHBCXkY3ahT84x9FVyZJUs1oj6Ap2niszdlHEXEc0EBeLveeUkqfAjYDpgFHL+c1T46IxohonDdv3spVLEmSJDXZcEP42c/gzjthrbXgoINyw3B/tpQk6T21R9A0GxhYdn8AMKf1QRFxIHAucHhKacHKvnhKaQnwR+DI5ez/WUqpIaXU0KdPn1UqXJIkSfq3ffeFSZPgq1+Fa66BYcPgt7+FZAcHSZKWpz2CpoeArSNi84joDhwD3Fh+QETsCPyUHDK99F4vGNlWTbeBw4DHK165JEmSVG7tteGb34RHHoFttoH//M88w+mZZ4quTJKkDqniQVNKaTH5inC3kpe4XZtSeiwiLoiIw0uHXQr0Aq6LiIkR8e8gKiLGAdcBYyJidkQcRF6O9+uIeBR4FOgHXFDp2iVJkqQ2jRwJ99wDP/whjB+f7196KSxeXHRlkiR1KJHqeOpvQ0NDamxsLLoMSZIk1ZPZs+HUU+HGG2HHHeHnP4fRo4uuSpKkqomICSmlhrb2tcfSOUmSJKl+DRgAN9wA118PL7wAu+wCX/gCvP120ZVJklQ4gyZJkiRpVUXAkUfCtGlw0knwve/l5XS33lp0ZZIkFcqgSZIkSVpdvXvDT38Kd90FPXrAwQfDJz4B8+YVXZkkSYUwaJIkSZLW1D77wKRJcN55cN11sO228OtfQx33Q5UkqS0GTZIkSVIl9OgB3/gGPPJIDpr+67/g/e+Hp58uujJJkqrGoEmSJEmqpBEjYNw4+PGP4cEHc++miy+GRYuKrkySpHZn0CRJkiRVWpcucMopuVn4wQfD2WfDzjtDY2PRlUmS1K4MmiRJkqT20r8//OUv8Kc/wUsvwa67wplnwltvFV2ZJEntwqBJkiRJam8f/Wie3XTyyXDZZXk53S23FF2VJEkVZ9AkSZIkVcMGG8BPfpL7N62zDhx6KHz843mmkyRJdcKgSZIkSaqmvfaCiRPh/PPh+uvzFep++UtIqejKJElaYwZNkiRJUrX16AFf/zpMmgTDh8MJJ8CBB8L06UVXJknSGjFokiRJkooybBjcfXdeUtfYCKNGwUUXwaJFRVcmSdJqMWiSJEmSitSlC3zmMzB1au7bdM450NAADz5YdGWSJK0ygyZJkiSpI+jfH/70J/jLX+Dll2H33eGMM+Ctt4quTJKklWbQJEmSJHUkH/5wnt306U/D5ZfDiBHwt78VXZUkSSvFoEmSJEnqaDbYAH78Y7jnHujVCz74QTjmGJg7t+jKJElaIYMmSZIkqaPac094+GH4xjfykrphw+CqqyCloiuTJKlNBk2SJElSR9ajB5x3HkyaBCNHwoknwgEHwFNPFV2ZJEnLMGiSJEmSasG228Kdd8JPfwqPPAKjRsG3vw2LFhVdmSRJ/2bQJEmSJNWKLl3g5JNh2jQ47DA491wYPRoeeKDoyiRJAgyaJEmSpNrTrx9cdx389a/w6quw++5w+unw5ptFVyZJ6uTaJWiKiIMj4omImB4RZ7ex/8yImBoRkyNibEQMLtv394h4LSJubvWcq0uvOSUiroqItdqjdkk6xW/6AAAUCUlEQVSSJKlmHH44TJ0Kn/0s/PCHMGIE3Hzzez9PkqR2UvGgKSK6Aj8CDgGGA8dGxPBWhz0CNKSUtgOuBy4p23cp8Mk2XvpqYFtgFLAOcFKFS5ckSZJqz/rr55Dp3nvz7cMOg6OPhhdfLLoySVIn1B4zmnYBpqeUnkkpLQSuAY4oPyCldEdK6Z3S3fHAgLJ9Y4Fl5vymlP6WSoAHy58jSZIkdXq77w4PPwzf/CbccAMMGwZXXgkpFV2ZJKkTaY+gqT8wq+z+7NJjy3MicMvKvnhpydwngb+vVnWSJElSvereHb76VZg8GbbbDv77v2H//eHJJ4uuTJLUSbRH0BRtPNbmf6NExHFAA3m53Mr6MXB3Smnccl7z5IhojIjGefPmrcLLSpIkSXVi6FC44w74+c9h0qQcOl14ISxcWHRlkqQ61x5B02xgYNn9AcCc1gdFxIHAucDhKaUFK/PCEfF1oA9w5vKOSSn9LKXUkFJq6NOnzyoVLkmSJNWNLl3gpJNg2rTcNPyrX4XRo2H8+KIrkyTVsfYImh4Cto6IzSOiO3AMcGP5ARGxI/BTcsj00sq8aEScBBwEHJtSWlrhmiVJkqT6tOmmcO21cOON8NprsMce8LnPwZvLtEWVJGmNVTxoSiktBk4DbgWmAdemlB6LiAsi4vDSYZcCvYDrImJiRPw7iIqIccB1wJiImB0RB5V2XQG8D7i/9JzzKl27JEmSVLcOOwymToXTToMf/QiGD8/hkyRJFRSpjq9C0dDQkBobG4suQ5IkSepYxo/PjcKnTIGPfQz+93+hX7+iq5Ik1YiImJBSamhrX3ssnZMkSZLUke22G0yYkBuE33QTDBuWG4cvtUOFJGnNGDRJkiRJnVH37vCVr8DkybDjjnDyybD//vD440VXJkmqYQZNkiRJUme2zTZw++1w5ZU5dNp+e/jmN2HhwqIrkyTVIIMmSZIkqbOLgBNPhGnT4CMfgfPOg512gvvvL7oySVKNMWiSJEmSlG26KVxzDdx8M7zxBuy5J5x6ar4tSdJKMGiSJEmS1NIHPwiPPQaf+xz85CcwfDhcfz0sWFB0ZZJUm15/HW68EebOLbqSdmfQJEmSJGlZ660Hl18O48fDRhvBUUfB+uvnWU5nnQV/+Qu8+GLRVUpSx/TuuzB2bL7owm675c/RI47IM0brXKSUiq6h3TQ0NKTGxsaiy5AkSZJq26JF8Le/wb33wn33QWNj8+ymLbaAPfZo3kaOhK5di61Xkqpt8eL82Th2bN7uuy9/TnbtCrvuCgccAGPGwO67Q48eRVe7xiJiQkqpoc19Bk2SJEmSVsmCBfDII/kXqabwqWl2U69e+X/vm4Kn3XaDDTYotl5JqrSlS/MS46Zg6a674M03877tt28OlvbZJ88QrTMGTZIkSZLaT0owY0YOnJq2yZPzL2IRMGJEy1lPW22VH5ekWpESPPMM3H57DpZuvx3mzcv7ttoqh0oHHAD77w99+hRbaxUYNEmSJEmqrjffhAcfbA6e7r8/N8OF/EtYefA0ejSss06x9UpSay+8kAOlpnBp5sz8eL9+OVhqCpcGDSq2zgIYNEmSJEkq1tKlMG1ay1lPTz6Z9621Fuy0U8vwabPNiq1XUufz2mtw553NM5amTs2P9+6dZyo1hUtDh3b6WZkGTZIkSZI6nnnz8lXtmoKnBx+E+fPzvsGDWwZP220H3boVW6+k+vLOO7nPXFOfpYcfzqF4z56w997NfZZ22MGLHLRi0CRJkiSp41u4ECZNam4wfu+9MGdO3tezZ75yU3mT8Y02KrZeSbVl0SJ46KHmYOn++/PnTrdu+TOlaSncrrvWxZXh2pNBkyRJkqTakxLMmtVyud3EibBkSd4/bFjLWU8uZ5FUbunSfGGCph5Ld98Nb72VPyd22KF5Kdxee+UrZmqlGTRJkiRJqg9vv51nJJSHT//6V9630UYtg6edd84zoSR1DinB9OnNPZbuuANefjnv22ab5mBpv/1g440LLbXWrShocpGzJEmSpNqx7rr5l8T99sv3ly7NTcXLg6ebb877unXLsxbKw6eBA4uqXFJ7mDOnOVgaOzbPggTo3x8OPbR5OdyAAcXW2Yk4o0mSJElSfXn11ZZNxh94IDf9hfzLZnnwtMMO+ap3kmrDq6+2vDLc44/nxzfaKAdKTQ28t97apbTtyKVzkiRJkjqvRYtyn5byWU/PPZf3rbNOXmLXFDztvjtsskmx9Upq9vbbcM89zQ28H3kkL5Fbd13YZ5/mGUvbbw9duhRdbadh0CRJkiRJ5WbPzlecagqeHn4YFi/O+7bZpjl42nNP2HZbf4GVqmXhwjwLsWkp3PjxOSxea60cBDf1Wdp5Z+jevehqOy2DJkmSJElakXffhcbGlrOempoI9+6df8FtCp922cUrVEmVsnRpvppkU7A0blyexRQBo0c3L4Xbay+b+3cgNgOXJEmSpBVZZx3Ye++8QfPVq5pCp3vvhVtuyfu6dMnLdMp7PQ0ebD8YaWWklBv4l18Z7tVX875hw+BTn8rh0n77wYYbFlqqVk+7zGiKiIOBy4GuwJUppYta7T8TOAlYDMwDTkgpzSzt+zuwG3BPSulDZc85DTgD2BLok1J6+b3qcEaTJEmSpIp57bVlm4y/9Vbe169fy+Bpxx2hR49i65U6itmzm3ss3X47PP98fnzQoOYeSwccAJttVmydWmlVXToXEV2BJ4H3A7OBh4BjU0pTy47ZH3ggpfRORJwC7JdSOrq0bwzQE/h0q6BpR+BfwJ1Ag0GTJEmSpEItXgxTprRcbvfss3lfjx7Q0NCyyfj73ldsvVK1vPxy85Xhxo6Fp57Kj2+ySfNSuAMOgC23dCZgjap20LQ7cH5K6aDS/XMAUkrfWc7xOwI/TCntWfbYfsAXy4Omsn0zMGiSJEmS1BG98ELLJuMTJuTmxpB/qS6f9TRiBHTtWmy9UiW89VburdQULE2alJfI9eoF++7b3MB75Egb69eJavdo6g/MKrs/G9h1BcefCNzSDnVIkiRJUnX16wcf/WjeAObPz1e0awqebr0VfvvbvG+99WC33ZqvbrfrrrD++sXVLq2sBQvyMtKmBt4PPJBn+HXvnv8uX3BBDpYaGvLV4tSptEfQ1Na8tzanTUXEcUADsG/FvnjEycDJAIMGDarUy0qSJEnSqlt77eYZTJBneTz7bHOD8fvuy7+Up5SXEI0a1XLW0xZbuLRIxVuyBB55pLnH0rhx+UqNXbrkMOmss/JSuD33zI311am1R9A0GxhYdn8AMKf1QRFxIHAusG9KaUGlvnhK6WfAzyAvnavU60qSJEnSGovI4dEWW8Bxx+XH3ngjzwhpmvX0+9/DFVfkfX37tgyeRo/O4ZXUnlKCxx9vXgp35525GT7kJZ///d95xtI++0Dv3oWWqo6nPYKmh4CtI2Jz4HngGODj5QeU+jL9FDg4pfRSO9QgSZIkSbVh/fXh/e/PG+TZI1OntmwyfsMNed9aa+WwqTx86tevuNpVP2bObF4Kd/vtud8YwJAhcOSROVjaf3/YdNNCy1THV/Fm4AARcSjwfaArcFVK6cKIuABoTCndGBH/BEYBpb+5PJdSOrz03HHAtkAv4BXgxJTSrRFxOvAlYFPgJeBvKaWTVlSHzcAlSZIk1YWXXmrZZPyhh3KfHMhBQHnwNGoUdGuPOQWqK/PmwR13NM9aevrp/Hjfvs1XhhszBjbfvNg61SFV9apzHYlBkyRJkqS6tHBh7pnTFDzde2/zDJRevXJj8abgabfdXN6kvETz7rubZy1NnpwfX3992G+/5nBpxAj7guk9GTRJkiRJUj1LKS99Kl9uN2kSLF2a948YkbeePXOPp3XWWb0/y293724g0ZHNn59nwTUthXvwwbwsc+21c9PuMWNyuDR6tDPgtMoMmiRJkiSps3nrrRwuNM14euaZHD68+27zn4sXr/7rR6x+SLUmAdfaaxtwtWXxYnj44ealcPfem8e5a1fYeefmpXC7725Dea2xFQVNxpaSJEmSVI969cozVg44YPnHLF6cw4jWAdSK/lzZY996K/cBamv/woVrdm49elQn4Gr9Gl26rFndlZRSbhrfFCzddRe8/nret9128JnPNF8Zbv31i61VnYpBkyRJkiR1Vt265UCqV6/qft0lS3Iz81UJuFYl+PrXv5Z/7JpYa601m421us9tWtr27LMtrww3d25+fMst4eijc6i4//65obdUEIMmSZIkSVJ1de2a+0X17Fndr5tSDrhWd5bWe/355pvL37cmbWu6ds2zuN55J9/fdFM48MDmPkuDB1fm+yNVgEGTJEmSJKlzaOorVe0eRSnBokVrvjxx881zuDRsmH2q1GEZNEmSJEmS1J4i8lX6uneHDTYouhqpXXWgTmaSJEmSJEmqZQZNkiRJkiRJqgiDJkmSJEmSJFWEQZMkSZIkSZIqwqBJkiRJkiRJFWHQJEmSJEmSpIowaJIkSZIkSVJFREqp6BraTUTMA2YWXUeFbAK8XHQRWiOOYe1zDGub41f7HMPa5xjWNsev9jmGtc8xrH31MoaDU0p92tpR10FTPYmIxpRSQ9F1aPU5hrXPMaxtjl/tcwxrn2NY2xy/2ucY1j7HsPZ1hjF06ZwkSZIkSZIqwqBJkiRJkiRJFWHQVDt+VnQBWmOOYe1zDGub41f7HMPa5xjWNsev9jmGtc8xrH11P4b2aJIkSZIkSVJFOKNJkiRJkiRJFWHQVCURcXBEPBER0yPi7Db294iIP5b2PxARQ8r2nVN6/ImIOKj02NCImFi2vRERZ5T2bRQRt0XEU6U/N6zWedazKo/hURHxWEQsjYi6viJBNVV5DC+NiMcjYnJE/CUielfrPOtZlcfwm6XxmxgR/4iIzap1nvWqmuNX9rwvRkSKiE3a+/w6gyq/B8+PiOfL9h1arfOsZ9V+H0bE50rHPxYRl1TjHOtZld+Dfyx7fEZETKzWedazKo/hDhExvvR4Y0TsUq3zrGdVHsPtI+L+iHg0Im6KiPWrdZ5rJKXk1s4b0BV4GtgC6A5MAoa3OuazwBWl28cAfyzdHl46vgeweel1urbx+i8Cg0v3LwHOLt0+G7i46O9BrW8FjOEwYChwJ9BQ9PnXw1bAGH4A6Fa6fbHvw5ocw/XL9p3e9LputTF+pccGArcCM4FNiv4e1PpWwHvwfOCLRZ93PW0FjOH+wD+BHqX7fYv+HtTyVsTnaNm+/wHOK/p7UOtbAe/BfwCHlG4fCtxZ9Peg1rcCxvAhYN/S7ROAbxb9PViZzRlN1bELMD2l9ExKaSFwDXBEq2OOAH5dun09MCYiovT4NSmlBSmlZ4HppdcrNwZ4OqU0s43X+jXw4YqeTedU1TFMKU1LKT3RTufSWVV7DP+RUlpc2jceGFDxM+p8qj2Gb5TtWxewqeGaqfa/hQCXAV/CsauUIsZQlVXtMTwFuCiltAAgpfRSxc+ocynkPVh6/n8Af6jo2XRO1R7DBDTNgNkAmFPRs+mcqj2GQ4G7S7dvA46s6Nm0E4Om6ugPzCq7P7v0WJvHlH45fR3YeCWfewwtP/jfl1J6ofRaLwB917B+VX8MVXlFjuEJwC2rVbXKVX0MI+LCiJgFfAI4bw3r7+yqOn4RcTjwfEppUiWKF1DM5+hpkZewXhW2AqiEao/hNsDepaUjd0XEzmt8Bp1bUT/L7A3MTSk9tdqVq0m1x/AM4NLSzzLfBc5Zw/pV/TGcAhxeun0UebZ2h2fQVB3RxmOt/3d1eces8LkR0Z38F++61a5OK8MxrH2FjGFEnAssBq5e6Uq1PFUfw5TSuSmlgeTxO22VqlVrVRu/iOgJnIvhYKVV+z34E2BLYAfgBfLSHa2Zao9hN2BDYDfgLODa0v/qa/UU9fPosfgfopVS7TE8Bfh86WeZzwO/WKVq1ZZqj+EJwKkRMQFYD1i4StUWxKCpOmbTMnkcwLLTFv99TER0I09tfHUlnnsI8HBKaW7ZY3Mjol/ptfoBTlNec9UeQ1Ve1ccwIo4HPgR8IpUWVmuNFPk+/D01MlW5A6vm+G1J7n0wKSJmlI5/OCI2rciZdF5VfQ+mlOamlJaklJYCP2fZ5QVaddX+HJ0N/DllDwJLARvzr74ifpbpBnwU+GMF6lf1x/B44M+l29fh52glVPvfwsdTSh9IKY0mB75PV+g82pVBU3U8BGwdEZuXUspjgBtbHXMj+YMA4GPA7aVfTG8Ejil1rt8c2Bp4sOx5bf0PQ/lrHQ/8tWJn0nlVewxVeVUdw4g4GPgycHhK6Z2Kn03nVO0x3Lrs7uHA4xU7k86pauOXUno0pdQ3pTQkpTSE/IPdTimlF9vjxDqRar8H+5Xd/Qh5+YDWTLV/nrkBOAAgIrYhN859uYLn09kU8fPogcDjKaXZFTyPzqzaYzgH2Ld0+wDA5Y9rrtr/FvYt/dkF+CpwRYXPp3207g7u1j4bucv/k+QE8tzSYxeQfwkFWJucMk8n/2Xbouy555ae9wSlqwaUHu8JvAJs0OprbQyMJX+QjAU2Kvr862Gr8hh+hPyL0QJgLnBr0edfD1uVx3A6eQ32xNLmFctqbwz/RP7FdjJwE9C/6POv9a2a49fq687Aq87V3BgCvwUeLb0HbwT6FX3+9bBVeQy7A78rfZY+DBxQ9PnX+lbtz1HgV8Bnij7vetqq/B7cC5hAvtLZA8Doos+/HrYqj+H/K32tJ4GLgCj6/Fdmi1LxkiRJkiRJ0hpx6ZwkSZIkSZIqwqBJkiRJkiRJFWHQJEmSJEmSpIowaJIkSZIkSVJFGDRJkiRJkiSpIgyaJEmSJEmSVBEGTZIkSZIkSaoIgyZJkiRJkiRVxP8H9cKUFFgTlyYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_474 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8964 - auc: 0.6759 - val_loss: 0.3005 - val_auc: 0.8397\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2789 - auc: 0.7693 - val_loss: 0.2337 - val_auc: 0.8504\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2543 - auc: 0.7730 - val_loss: 0.2292 - val_auc: 0.8549\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7824 - val_loss: 0.2275 - val_auc: 0.8530\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7884 - val_loss: 0.2282 - val_auc: 0.8519\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2466 - auc: 0.7970 - val_loss: 0.2275 - val_auc: 0.8524\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2463 - auc: 0.7996 - val_loss: 0.2269 - val_auc: 0.8515\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2468 - auc: 0.7995 - val_loss: 0.2263 - val_auc: 0.8479\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2465 - auc: 0.7994 - val_loss: 0.2275 - val_auc: 0.8509\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2463 - auc: 0.8052 - val_loss: 0.2263 - val_auc: 0.8460\n",
      "Model: \"sequential_158\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_474 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_475 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_476 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_477 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.8960 - auc: 0.6757 - val_loss: 0.3004 - val_auc: 0.8387\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2789 - auc: 0.7693 - val_loss: 0.2337 - val_auc: 0.8503\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2543 - auc: 0.7726 - val_loss: 0.2291 - val_auc: 0.8548\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7823 - val_loss: 0.2275 - val_auc: 0.8530\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7885 - val_loss: 0.2282 - val_auc: 0.8522\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2466 - auc: 0.7970 - val_loss: 0.2275 - val_auc: 0.8515\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2464 - auc: 0.7993 - val_loss: 0.2269 - val_auc: 0.8508\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2468 - auc: 0.7991 - val_loss: 0.2263 - val_auc: 0.8506\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2465 - auc: 0.7994 - val_loss: 0.2275 - val_auc: 0.8510\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.8053 - val_loss: 0.2263 - val_auc: 0.8465\n",
      "Model: \"sequential_159\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_477 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_478 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_479 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_480 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.8956 - auc: 0.6758 - val_loss: 0.3003 - val_auc: 0.8389\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2788 - auc: 0.7693 - val_loss: 0.2336 - val_auc: 0.8502\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2543 - auc: 0.7726 - val_loss: 0.2291 - val_auc: 0.8544\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7822 - val_loss: 0.2275 - val_auc: 0.8529\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7884 - val_loss: 0.2282 - val_auc: 0.8519\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.7967 - val_loss: 0.2275 - val_auc: 0.8510\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2464 - auc: 0.7995 - val_loss: 0.2269 - val_auc: 0.8503\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7994 - val_loss: 0.2263 - val_auc: 0.8501\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2465 - auc: 0.7994 - val_loss: 0.2275 - val_auc: 0.8507\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.8049 - val_loss: 0.2263 - val_auc: 0.8463\n",
      "Model: \"sequential_160\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_480 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_481 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_482 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_483 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.8953 - auc: 0.6761 - val_loss: 0.3001 - val_auc: 0.8391\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2787 - auc: 0.7693 - val_loss: 0.2336 - val_auc: 0.8501\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2543 - auc: 0.7728 - val_loss: 0.2291 - val_auc: 0.8549\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7822 - val_loss: 0.2275 - val_auc: 0.8529\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.7883 - val_loss: 0.2282 - val_auc: 0.8515\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.7967 - val_loss: 0.2275 - val_auc: 0.8529\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.7993 - val_loss: 0.2269 - val_auc: 0.8499\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7992 - val_loss: 0.2263 - val_auc: 0.8517\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2465 - auc: 0.7996 - val_loss: 0.2275 - val_auc: 0.8501\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2465 - auc: 0.8044 - val_loss: 0.2263 - val_auc: 0.8463\n",
      "Model: \"sequential_161\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_483 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_484 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_485 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_486 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 18ms/step - loss: 0.8949 - auc: 0.6761 - val_loss: 0.3000 - val_auc: 0.8393\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2787 - auc: 0.7691 - val_loss: 0.2336 - val_auc: 0.8504\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2543 - auc: 0.7728 - val_loss: 0.2291 - val_auc: 0.8547\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7822 - val_loss: 0.2275 - val_auc: 0.8529\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.7882 - val_loss: 0.2281 - val_auc: 0.8511\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7965 - val_loss: 0.2274 - val_auc: 0.8526\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2465 - auc: 0.7988 - val_loss: 0.2269 - val_auc: 0.8520\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.7992 - val_loss: 0.2263 - val_auc: 0.8515\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2465 - auc: 0.7996 - val_loss: 0.2275 - val_auc: 0.8496\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2465 - auc: 0.8044 - val_loss: 0.2264 - val_auc: 0.8460\n",
      "Model: \"sequential_162\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_486 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_487 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_488 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_489 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.8946 - auc: 0.6760 - val_loss: 0.2999 - val_auc: 0.8395\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2786 - auc: 0.7690 - val_loss: 0.2335 - val_auc: 0.8504\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2510 - auc: 0.763 - 0s 6ms/step - loss: 0.2543 - auc: 0.7728 - val_loss: 0.2291 - val_auc: 0.8545\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2501 - auc: 0.7821 - val_loss: 0.2275 - val_auc: 0.8529\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7883 - val_loss: 0.2281 - val_auc: 0.8508\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7963 - val_loss: 0.2274 - val_auc: 0.8526\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2465 - auc: 0.7987 - val_loss: 0.2268 - val_auc: 0.8506\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.7992 - val_loss: 0.2263 - val_auc: 0.8514\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.7995 - val_loss: 0.2275 - val_auc: 0.8491\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2465 - auc: 0.8042 - val_loss: 0.2264 - val_auc: 0.8460\n",
      "Model: \"sequential_163\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_489 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_490 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_491 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_492 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.8942 - auc: 0.6761 - val_loss: 0.2998 - val_auc: 0.8394\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2786 - auc: 0.7688 - val_loss: 0.2335 - val_auc: 0.8503\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2543 - auc: 0.7728 - val_loss: 0.2290 - val_auc: 0.8552\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2501 - auc: 0.7820 - val_loss: 0.2275 - val_auc: 0.8529\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2480 - auc: 0.786 - 0s 4ms/step - loss: 0.2481 - auc: 0.7883 - val_loss: 0.2281 - val_auc: 0.8504\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7958 - val_loss: 0.2274 - val_auc: 0.8527\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2466 - auc: 0.7981 - val_loss: 0.2268 - val_auc: 0.8503\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2469 - auc: 0.7993 - val_loss: 0.2264 - val_auc: 0.8512\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2466 - auc: 0.7994 - val_loss: 0.2274 - val_auc: 0.8491\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2466 - auc: 0.8038 - val_loss: 0.2264 - val_auc: 0.8467\n",
      "Model: \"sequential_164\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_492 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_493 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_494 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_495 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8939 - auc: 0.6760 - val_loss: 0.2996 - val_auc: 0.8394\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2785 - auc: 0.7687 - val_loss: 0.2335 - val_auc: 0.8501\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2544 - auc: 0.7729 - val_loss: 0.2290 - val_auc: 0.8548\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2501 - auc: 0.7815 - val_loss: 0.2276 - val_auc: 0.8528\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.7883 - val_loss: 0.2281 - val_auc: 0.8501\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7961 - val_loss: 0.2274 - val_auc: 0.8528\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.7982 - val_loss: 0.2268 - val_auc: 0.8505\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.7997 - val_loss: 0.2264 - val_auc: 0.8511\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.7995 - val_loss: 0.2274 - val_auc: 0.8499\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2466 - auc: 0.8038 - val_loss: 0.2264 - val_auc: 0.8468\n",
      "Model: \"sequential_165\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_495 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_496 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_497 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_498 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.8935 - auc: 0.6753 - val_loss: 0.2995 - val_auc: 0.8396\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2785 - auc: 0.7687 - val_loss: 0.2334 - val_auc: 0.8502\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2544 - auc: 0.7726 - val_loss: 0.2290 - val_auc: 0.8545\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2501 - auc: 0.7815 - val_loss: 0.2276 - val_auc: 0.8528\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7877 - val_loss: 0.2281 - val_auc: 0.8519\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2468 - auc: 0.7956 - val_loss: 0.2274 - val_auc: 0.8526\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7977 - val_loss: 0.2268 - val_auc: 0.8503\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2469 - auc: 0.7997 - val_loss: 0.2264 - val_auc: 0.8511\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2466 - auc: 0.7994 - val_loss: 0.2274 - val_auc: 0.8500\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.8036 - val_loss: 0.2265 - val_auc: 0.8475\n",
      "Model: \"sequential_166\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_498 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_499 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_500 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_501 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.8932 - auc: 0.6757 - val_loss: 0.2994 - val_auc: 0.8399\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2784 - auc: 0.7686 - val_loss: 0.2334 - val_auc: 0.8501\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7726 - val_loss: 0.2290 - val_auc: 0.8543\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2501 - auc: 0.7812 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.7875 - val_loss: 0.2280 - val_auc: 0.8514\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7955 - val_loss: 0.2273 - val_auc: 0.8534\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2467 - auc: 0.7976 - val_loss: 0.2268 - val_auc: 0.8497\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2470 - auc: 0.7999 - val_loss: 0.2264 - val_auc: 0.8513\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.7995 - val_loss: 0.2274 - val_auc: 0.8495\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.8033 - val_loss: 0.2265 - val_auc: 0.8475\n",
      "Model: \"sequential_167\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_501 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_502 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_503 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_504 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.8929 - auc: 0.6759 - val_loss: 0.2993 - val_auc: 0.8395\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2784 - auc: 0.7686 - val_loss: 0.2334 - val_auc: 0.8498\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7724 - val_loss: 0.2289 - val_auc: 0.8540\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7811 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.7875 - val_loss: 0.2280 - val_auc: 0.8527\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7953 - val_loss: 0.2273 - val_auc: 0.8537\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7973 - val_loss: 0.2267 - val_auc: 0.8491\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7997 - val_loss: 0.2264 - val_auc: 0.8511\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7995 - val_loss: 0.2273 - val_auc: 0.8505\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.8033 - val_loss: 0.2265 - val_auc: 0.8475\n",
      "Model: \"sequential_168\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_504 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_505 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_506 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_507 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.8925 - auc: 0.6758 - val_loss: 0.2991 - val_auc: 0.8385\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2783 - auc: 0.7686 - val_loss: 0.2334 - val_auc: 0.8497\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7724 - val_loss: 0.2289 - val_auc: 0.8536\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7811 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.7875 - val_loss: 0.2280 - val_auc: 0.8525\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2468 - auc: 0.7958 - val_loss: 0.2273 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2468 - auc: 0.7978 - val_loss: 0.2267 - val_auc: 0.8485\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2470 - auc: 0.7995 - val_loss: 0.2265 - val_auc: 0.8507\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7994 - val_loss: 0.2273 - val_auc: 0.8499\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.8030 - val_loss: 0.2266 - val_auc: 0.8474\n",
      "Model: \"sequential_169\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_507 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_508 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_509 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_510 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.8922 - auc: 0.6758 - val_loss: 0.2990 - val_auc: 0.8387\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2783 - auc: 0.7686 - val_loss: 0.2333 - val_auc: 0.8495\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7721 - val_loss: 0.2289 - val_auc: 0.8532\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7811 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.7875 - val_loss: 0.2280 - val_auc: 0.8535\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.7955 - val_loss: 0.2273 - val_auc: 0.8538\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7979 - val_loss: 0.2267 - val_auc: 0.8494\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7994 - val_loss: 0.2265 - val_auc: 0.8487\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7991 - val_loss: 0.2273 - val_auc: 0.8488\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.8024 - val_loss: 0.2266 - val_auc: 0.8466\n",
      "Model: \"sequential_170\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_510 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_511 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_512 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_513 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.8918 - auc: 0.6757 - val_loss: 0.2989 - val_auc: 0.8384\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2782 - auc: 0.7685 - val_loss: 0.2333 - val_auc: 0.8494\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2544 - auc: 0.7721 - val_loss: 0.2289 - val_auc: 0.8530\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7809 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.7877 - val_loss: 0.2280 - val_auc: 0.8531\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.7950 - val_loss: 0.2273 - val_auc: 0.8532\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7983 - val_loss: 0.2267 - val_auc: 0.8492\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7994 - val_loss: 0.2265 - val_auc: 0.8493\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7993 - val_loss: 0.2272 - val_auc: 0.8482\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.8024 - val_loss: 0.2266 - val_auc: 0.8460\n",
      "Model: \"sequential_171\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_513 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_514 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_515 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_516 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8915 - auc: 0.6756 - val_loss: 0.2988 - val_auc: 0.8385\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2782 - auc: 0.7683 - val_loss: 0.2333 - val_auc: 0.8493\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7722 - val_loss: 0.2288 - val_auc: 0.8530\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.7811 - val_loss: 0.2276 - val_auc: 0.8526\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2482 - auc: 0.7874 - val_loss: 0.2279 - val_auc: 0.8528\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.7948 - val_loss: 0.2273 - val_auc: 0.8534\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2469 - auc: 0.7978 - val_loss: 0.2267 - val_auc: 0.8484\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2470 - auc: 0.7993 - val_loss: 0.2266 - val_auc: 0.8486\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2467 - auc: 0.7990 - val_loss: 0.2271 - val_auc: 0.8473\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8033 - val_loss: 0.2267 - val_auc: 0.8456\n",
      "Model: \"sequential_172\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_516 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_517 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_518 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_519 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8912 - auc: 0.6763 - val_loss: 0.2987 - val_auc: 0.8387\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2781 - auc: 0.7684 - val_loss: 0.2332 - val_auc: 0.8492\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7722 - val_loss: 0.2288 - val_auc: 0.8527\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.7805 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.7873 - val_loss: 0.2279 - val_auc: 0.8524\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7949 - val_loss: 0.2272 - val_auc: 0.8531\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.7973 - val_loss: 0.2266 - val_auc: 0.8477\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7991 - val_loss: 0.2266 - val_auc: 0.8481\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2467 - auc: 0.7988 - val_loss: 0.2271 - val_auc: 0.8464\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8037 - val_loss: 0.2267 - val_auc: 0.8462\n",
      "Model: \"sequential_173\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_519 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_520 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_521 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_522 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8908 - auc: 0.6765 - val_loss: 0.2986 - val_auc: 0.8390\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2781 - auc: 0.7684 - val_loss: 0.2332 - val_auc: 0.8491\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7721 - val_loss: 0.2288 - val_auc: 0.8524\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.7803 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.7872 - val_loss: 0.2279 - val_auc: 0.8561\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7947 - val_loss: 0.2272 - val_auc: 0.8528\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.7976 - val_loss: 0.2266 - val_auc: 0.8477\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7993 - val_loss: 0.2266 - val_auc: 0.8490\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7993 - val_loss: 0.2271 - val_auc: 0.8476\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8038 - val_loss: 0.2267 - val_auc: 0.8463\n",
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_522 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_523 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_524 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_525 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8905 - auc: 0.6763 - val_loss: 0.2984 - val_auc: 0.8392\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2780 - auc: 0.7682 - val_loss: 0.2332 - val_auc: 0.8489\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2544 - auc: 0.7721 - val_loss: 0.2288 - val_auc: 0.8520\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.7805 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.7873 - val_loss: 0.2279 - val_auc: 0.8557\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2470 - auc: 0.7946 - val_loss: 0.2272 - val_auc: 0.8525\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7972 - val_loss: 0.2266 - val_auc: 0.8473\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7991 - val_loss: 0.2267 - val_auc: 0.8495\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7992 - val_loss: 0.2270 - val_auc: 0.8467\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8036 - val_loss: 0.2267 - val_auc: 0.8466\n",
      "Model: \"sequential_175\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_525 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_526 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_527 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_528 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 17ms/step - loss: 0.8902 - auc: 0.6761 - val_loss: 0.2983 - val_auc: 0.8387\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2780 - auc: 0.7681 - val_loss: 0.2332 - val_auc: 0.8489\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7719 - val_loss: 0.2287 - val_auc: 0.8522\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.7801 - val_loss: 0.2276 - val_auc: 0.8526\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.7872 - val_loss: 0.2279 - val_auc: 0.8563\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7943 - val_loss: 0.2272 - val_auc: 0.8521\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2470 - auc: 0.7973 - val_loss: 0.2266 - val_auc: 0.8479\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.7994 - val_loss: 0.2267 - val_auc: 0.8502\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7990 - val_loss: 0.2270 - val_auc: 0.8464\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8034 - val_loss: 0.2268 - val_auc: 0.8474\n",
      "Model: \"sequential_176\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_528 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_529 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_530 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_531 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.8899 - auc: 0.6759 - val_loss: 0.2982 - val_auc: 0.8386\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2779 - auc: 0.7681 - val_loss: 0.2331 - val_auc: 0.8487\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2544 - auc: 0.7717 - val_loss: 0.2287 - val_auc: 0.8525\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7800 - val_loss: 0.2276 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.7870 - val_loss: 0.2278 - val_auc: 0.8559\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2471 - auc: 0.7941 - val_loss: 0.2272 - val_auc: 0.8518\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7973 - val_loss: 0.2266 - val_auc: 0.8476\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.7989 - val_loss: 0.2267 - val_auc: 0.8506\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.7989 - val_loss: 0.2269 - val_auc: 0.8457\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.8031 - val_loss: 0.2268 - val_auc: 0.8481\n",
      "Model: \"sequential_177\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_531 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_532 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_533 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_534 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8895 - auc: 0.6760 - val_loss: 0.2981 - val_auc: 0.8378\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2779 - auc: 0.7681 - val_loss: 0.2331 - val_auc: 0.8490\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7717 - val_loss: 0.2287 - val_auc: 0.8525\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7794 - val_loss: 0.2276 - val_auc: 0.8528\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.7871 - val_loss: 0.2278 - val_auc: 0.8552\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.7944 - val_loss: 0.2272 - val_auc: 0.8520\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.7965 - val_loss: 0.2266 - val_auc: 0.8489\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2471 - auc: 0.7988 - val_loss: 0.2268 - val_auc: 0.8505\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2468 - auc: 0.7992 - val_loss: 0.2269 - val_auc: 0.8450\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2469 - auc: 0.8029 - val_loss: 0.2268 - val_auc: 0.8480\n",
      "Model: \"sequential_178\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_534 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dense_535 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_536 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8374528739339931 0.007729999999999999\n",
      "[0.8373944073708193, 0.8374367452269107, 0.8374427934920667, 0.8374528739339931, 0.8374367452269108, 0.837438761315296, 0.8374407774036814, 0.8374266647849842, 0.8374306969617548, 0.837406503901131, 0.837400455635975, 0.8373843269288926, 0.8373843269288925, 0.8373520695147275, 0.8373157799237918, 0.8372925949073609, 0.8372613455373883, 0.8372210237696822, 0.8371383641458842, 0.8371081228201045, 0.8370577206104716]\n",
      "0.210658554029201 0.007769999999999997\n",
      "[0.21079147437002901, 0.21071618548997212, 0.2106815936600697, 0.21066893001096784, 0.21066404739950947, 0.21066139448181986, 0.21065958099519963, 0.210658554029201, 0.21065882031667277, 0.21066191475036197, 0.21067087416049365, 0.21069037393133222, 0.21072563029747488, 0.21078001982807154, 0.21085320330260998, 0.2109421039400592, 0.2110443900444134, 0.21116061472420594, 0.21129355070538822, 0.21144618361431955, 0.21162101071917122]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0.0077, 0.0079, 0.00001)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=i, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_537 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8953 - auc: 0.6761 - val_loss: 0.3001 - val_auc: 0.8391\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2787 - auc: 0.7693 - val_loss: 0.2336 - val_auc: 0.8501\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2543 - auc: 0.7728 - val_loss: 0.2291 - val_auc: 0.8549\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7822 - val_loss: 0.2275 - val_auc: 0.8529\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2481 - auc: 0.7883 - val_loss: 0.2282 - val_auc: 0.8515\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2466 - auc: 0.7967 - val_loss: 0.2275 - val_auc: 0.8529\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2464 - auc: 0.7993 - val_loss: 0.2269 - val_auc: 0.8499\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2468 - auc: 0.7992 - val_loss: 0.2263 - val_auc: 0.8517\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2465 - auc: 0.7996 - val_loss: 0.2275 - val_auc: 0.8501\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2465 - auc: 0.8044 - val_loss: 0.2263 - val_auc: 0.8463\n",
      "Model: \"sequential_179\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_537 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_538 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_539 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_540 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8999 - auc: 0.6686 - val_loss: 0.3017 - val_auc: 0.8360\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2800 - auc: 0.7651 - val_loss: 0.2343 - val_auc: 0.8498\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2552 - auc: 0.7697 - val_loss: 0.2301 - val_auc: 0.8545\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7819 - val_loss: 0.2282 - val_auc: 0.8520\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.7888 - val_loss: 0.2287 - val_auc: 0.8514\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.7922 - val_loss: 0.2284 - val_auc: 0.8535\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2466 - auc: 0.7987 - val_loss: 0.2273 - val_auc: 0.8527\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2470 - auc: 0.7995 - val_loss: 0.2263 - val_auc: 0.8466\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2470 - auc: 0.7999 - val_loss: 0.2285 - val_auc: 0.8473\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2478 - auc: 0.7971 - val_loss: 0.2272 - val_auc: 0.8484\n",
      "Model: \"sequential_180\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_540 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_541 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_542 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_543 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.8984 - auc: 0.6681 - val_loss: 0.3015 - val_auc: 0.8362\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2808 - auc: 0.7588 - val_loss: 0.2351 - val_auc: 0.8485\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2556 - auc: 0.7686 - val_loss: 0.2302 - val_auc: 0.8539\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2516 - auc: 0.7749 - val_loss: 0.2295 - val_auc: 0.8517\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2491 - auc: 0.7868 - val_loss: 0.2281 - val_auc: 0.8540\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.7883 - val_loss: 0.2282 - val_auc: 0.8544\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.7885 - val_loss: 0.2284 - val_auc: 0.8521\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7869 - val_loss: 0.2272 - val_auc: 0.8512\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.7918 - val_loss: 0.2287 - val_auc: 0.8477\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2477 - auc: 0.7979 - val_loss: 0.2288 - val_auc: 0.8474\n",
      "Model: \"sequential_181\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_543 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_544 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_545 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_546 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.9012 - auc: 0.6602 - val_loss: 0.3033 - val_auc: 0.8359\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2816 - auc: 0.7563 - val_loss: 0.2344 - val_auc: 0.8496\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2569 - auc: 0.7632 - val_loss: 0.2309 - val_auc: 0.8522\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2527 - auc: 0.7716 - val_loss: 0.2309 - val_auc: 0.8509\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7854 - val_loss: 0.2295 - val_auc: 0.8563\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.7909 - val_loss: 0.2287 - val_auc: 0.8511\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2484 - auc: 0.7918 - val_loss: 0.2272 - val_auc: 0.8512\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.7944 - val_loss: 0.2270 - val_auc: 0.8523\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.7922 - val_loss: 0.2284 - val_auc: 0.8487\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.7965 - val_loss: 0.2282 - val_auc: 0.8445\n",
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_546 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_547 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_548 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_549 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.8955 - auc: 0.6526 - val_loss: 0.3009 - val_auc: 0.8346\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2820 - auc: 0.7489 - val_loss: 0.2352 - val_auc: 0.8479\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2587 - auc: 0.7575 - val_loss: 0.2307 - val_auc: 0.8516\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2541 - auc: 0.7680 - val_loss: 0.2293 - val_auc: 0.8533\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2523 - auc: 0.7757 - val_loss: 0.2294 - val_auc: 0.8546\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7812 - val_loss: 0.2291 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7901 - val_loss: 0.2275 - val_auc: 0.8506\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7821 - val_loss: 0.2280 - val_auc: 0.8498\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.7880 - val_loss: 0.2300 - val_auc: 0.8472\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.7943 - val_loss: 0.2282 - val_auc: 0.8468\n",
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_549 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_550 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_551 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_552 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8841 - auc: 0.6353 - val_loss: 0.2969 - val_auc: 0.8337\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2806 - auc: 0.7469 - val_loss: 0.2355 - val_auc: 0.8489\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2592 - auc: 0.7614 - val_loss: 0.2299 - val_auc: 0.8516\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2552 - auc: 0.7673 - val_loss: 0.2290 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2540 - auc: 0.7693 - val_loss: 0.2286 - val_auc: 0.8529\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2531 - auc: 0.7688 - val_loss: 0.2286 - val_auc: 0.8511\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.7867 - val_loss: 0.2279 - val_auc: 0.8466\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7833 - val_loss: 0.2286 - val_auc: 0.8487\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2523 - auc: 0.7757 - val_loss: 0.2290 - val_auc: 0.8445\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2518 - auc: 0.7776 - val_loss: 0.2300 - val_auc: 0.8444\n",
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_552 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_553 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_554 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_555 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.8832 - auc: 0.6289 - val_loss: 0.2979 - val_auc: 0.8279\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2822 - auc: 0.7409 - val_loss: 0.2381 - val_auc: 0.8477\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2615 - auc: 0.7504 - val_loss: 0.2315 - val_auc: 0.8564\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2573 - auc: 0.7590 - val_loss: 0.2304 - val_auc: 0.8498\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2562 - auc: 0.7622 - val_loss: 0.2300 - val_auc: 0.8517\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2549 - auc: 0.7619 - val_loss: 0.2313 - val_auc: 0.8480\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2532 - auc: 0.7746 - val_loss: 0.2302 - val_auc: 0.8487\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2543 - auc: 0.7739 - val_loss: 0.2303 - val_auc: 0.8486\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2536 - auc: 0.7703 - val_loss: 0.2311 - val_auc: 0.8486\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2543 - auc: 0.7678 - val_loss: 0.2314 - val_auc: 0.8456\n",
      "Model: \"sequential_185\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_555 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_556 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_557 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_558 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.8862 - auc: 0.6102 - val_loss: 0.2984 - val_auc: 0.8241\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2845 - auc: 0.7281 - val_loss: 0.2424 - val_auc: 0.8445\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2654 - auc: 0.7435 - val_loss: 0.2334 - val_auc: 0.8524\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2599 - auc: 0.7534 - val_loss: 0.2315 - val_auc: 0.8496\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2584 - auc: 0.7566 - val_loss: 0.2330 - val_auc: 0.8482\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2578 - auc: 0.7533 - val_loss: 0.2326 - val_auc: 0.8460\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2564 - auc: 0.7656 - val_loss: 0.2318 - val_auc: 0.8488\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2568 - auc: 0.7568 - val_loss: 0.2307 - val_auc: 0.8456\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2561 - auc: 0.7581 - val_loss: 0.2323 - val_auc: 0.8464\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2568 - auc: 0.7509 - val_loss: 0.2337 - val_auc: 0.8458\n",
      "Model: \"sequential_186\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_558 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_559 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_560 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_561 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 0.8811 - auc: 0.5926 - val_loss: 0.2998 - val_auc: 0.8169\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2881 - auc: 0.7096 - val_loss: 0.2485 - val_auc: 0.8424\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2699 - auc: 0.7227 - val_loss: 0.2401 - val_auc: 0.8498\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2665 - auc: 0.7331 - val_loss: 0.2373 - val_auc: 0.8496\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2626 - auc: 0.7354 - val_loss: 0.2361 - val_auc: 0.8440\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2615 - auc: 0.7320 - val_loss: 0.2367 - val_auc: 0.8490\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2587 - auc: 0.7478 - val_loss: 0.2394 - val_auc: 0.8484\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2623 - auc: 0.7256 - val_loss: 0.2354 - val_auc: 0.8462\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2603 - auc: 0.7314 - val_loss: 0.2384 - val_auc: 0.8486\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2607 - auc: 0.7262 - val_loss: 0.2415 - val_auc: 0.8434\n",
      "Model: \"sequential_187\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_561 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_562 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_563 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_564 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8922 - auc: 0.5227 - val_loss: 0.3085 - val_auc: 0.7758\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3031 - auc: 0.5972 - val_loss: 0.2494 - val_auc: 0.8184\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2819 - auc: 0.6131 - val_loss: 0.2461 - val_auc: 0.8376\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2708 - auc: 0.6546 - val_loss: 0.2450 - val_auc: 0.8455\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2694 - auc: 0.6593 - val_loss: 0.2386 - val_auc: 0.8450\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2650 - auc: 0.6725 - val_loss: 0.2433 - val_auc: 0.8377\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2683 - auc: 0.6499 - val_loss: 0.2406 - val_auc: 0.8418\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2680 - auc: 0.6107 - val_loss: 0.2387 - val_auc: 0.8427\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2632 - auc: 0.6311 - val_loss: 0.2369 - val_auc: 0.8465\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2623 - auc: 0.6336 - val_loss: 0.2414 - val_auc: 0.8317\n",
      "Model: \"sequential_188\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_564 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_565 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_566 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8389467954275115 0.30000000000000004\n",
      "[0.8374528739339931, 0.8373177960121772, 0.8359871776778695, 0.8389467954275115, 0.8365496663373722, 0.8377038769379649, 0.8353843672506602, 0.8297836737162557, 0.8235227112356607, 0.7999022197133122]\n",
      "0.210353494775854 0.30000000000000004\n",
      "[0.21066893001096784, 0.21302797483166372, 0.21520170281697476, 0.210353494775854, 0.2136891454352397, 0.21329625282090103, 0.21599733007217647, 0.22411305845657467, 0.2315671285934587, 0.24508849186657608]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0, 1, 0.1)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(i, seed = 0),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color =\n",
    "           'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_597 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.9012 - auc: 0.6602 - val_loss: 0.3033 - val_auc: 0.8359\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2816 - auc: 0.7563 - val_loss: 0.2344 - val_auc: 0.8496\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2569 - auc: 0.7632 - val_loss: 0.2309 - val_auc: 0.8522\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2527 - auc: 0.7716 - val_loss: 0.2309 - val_auc: 0.8509\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2499 - auc: 0.7854 - val_loss: 0.2295 - val_auc: 0.8563\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2485 - auc: 0.7909 - val_loss: 0.2287 - val_auc: 0.8511\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2484 - auc: 0.791 - 0s 6ms/step - loss: 0.2484 - auc: 0.7918 - val_loss: 0.2272 - val_auc: 0.8512\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2480 - auc: 0.7944 - val_loss: 0.2270 - val_auc: 0.8523\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2485 - auc: 0.7922 - val_loss: 0.2284 - val_auc: 0.8487\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2486 - auc: 0.7965 - val_loss: 0.2282 - val_auc: 0.8445\n",
      "Model: \"sequential_199\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_597 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_598 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_599 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_600 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.9021 - auc: 0.6564 - val_loss: 0.3038 - val_auc: 0.8365\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2827 - auc: 0.7550 - val_loss: 0.2346 - val_auc: 0.8484\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2579 - auc: 0.7603 - val_loss: 0.2308 - val_auc: 0.8521\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2531 - auc: 0.7705 - val_loss: 0.2298 - val_auc: 0.8539\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2519 - auc: 0.7754 - val_loss: 0.2296 - val_auc: 0.8514\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2497 - auc: 0.7848 - val_loss: 0.2294 - val_auc: 0.8516\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2489 - auc: 0.7908 - val_loss: 0.2277 - val_auc: 0.8506\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7872 - val_loss: 0.2285 - val_auc: 0.8488\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7885 - val_loss: 0.2295 - val_auc: 0.8479\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2501 - auc: 0.7854 - val_loss: 0.2283 - val_auc: 0.8467\n",
      "Model: \"sequential_200\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_600 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_601 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_602 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_603 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.9044 - auc: 0.6566 - val_loss: 0.3061 - val_auc: 0.8372\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2841 - auc: 0.7543 - val_loss: 0.2359 - val_auc: 0.8501\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2587 - auc: 0.7574 - val_loss: 0.2316 - val_auc: 0.8546\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2534 - auc: 0.7695 - val_loss: 0.2297 - val_auc: 0.8541\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2527 - auc: 0.7683 - val_loss: 0.2302 - val_auc: 0.8533\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7842 - val_loss: 0.2293 - val_auc: 0.8510\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7879 - val_loss: 0.2293 - val_auc: 0.8483\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7914 - val_loss: 0.2300 - val_auc: 0.8466\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2498 - auc: 0.7865 - val_loss: 0.2304 - val_auc: 0.8468\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.7883 - val_loss: 0.2289 - val_auc: 0.8485\n",
      "Model: \"sequential_201\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_603 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_604 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_605 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_606 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.9100 - auc: 0.6534 - val_loss: 0.3084 - val_auc: 0.8360\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2858 - auc: 0.7506 - val_loss: 0.2360 - val_auc: 0.8479\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2597 - auc: 0.7569 - val_loss: 0.2324 - val_auc: 0.8541\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2535 - auc: 0.7703 - val_loss: 0.2294 - val_auc: 0.8531\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2527 - auc: 0.7724 - val_loss: 0.2291 - val_auc: 0.8532\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2507 - auc: 0.7824 - val_loss: 0.2286 - val_auc: 0.8504\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2500 - auc: 0.7861 - val_loss: 0.2289 - val_auc: 0.8487\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7867 - val_loss: 0.2301 - val_auc: 0.8489\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2509 - auc: 0.7815 - val_loss: 0.2305 - val_auc: 0.8464\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7915 - val_loss: 0.2297 - val_auc: 0.8443\n",
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_606 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_607 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_608 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_609 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.9087 - auc: 0.6496 - val_loss: 0.3078 - val_auc: 0.8369\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2862 - auc: 0.7506 - val_loss: 0.2358 - val_auc: 0.8490\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2611 - auc: 0.7511 - val_loss: 0.2329 - val_auc: 0.8534\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2549 - auc: 0.7653 - val_loss: 0.2300 - val_auc: 0.8538\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2535 - auc: 0.7667 - val_loss: 0.2289 - val_auc: 0.8527\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2517 - auc: 0.7765 - val_loss: 0.2299 - val_auc: 0.8509\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2510 - auc: 0.7812 - val_loss: 0.2294 - val_auc: 0.8496\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2506 - auc: 0.7835 - val_loss: 0.2313 - val_auc: 0.8488\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2521 - auc: 0.7781 - val_loss: 0.2301 - val_auc: 0.8456\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7930 - val_loss: 0.2307 - val_auc: 0.8447\n",
      "Model: \"sequential_203\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_609 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_610 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_611 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_612 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.9086 - auc: 0.6358 - val_loss: 0.3070 - val_auc: 0.8384\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2890 - auc: 0.7375 - val_loss: 0.2369 - val_auc: 0.8480\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2618 - auc: 0.7516 - val_loss: 0.2349 - val_auc: 0.8521\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2553 - auc: 0.7658 - val_loss: 0.2291 - val_auc: 0.8529\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2545 - auc: 0.7634 - val_loss: 0.2293 - val_auc: 0.8506\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2527 - auc: 0.7753 - val_loss: 0.2318 - val_auc: 0.8494\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2519 - auc: 0.7804 - val_loss: 0.2302 - val_auc: 0.8452\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2519 - auc: 0.7805 - val_loss: 0.2314 - val_auc: 0.8480\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2518 - auc: 0.7805 - val_loss: 0.2299 - val_auc: 0.8459\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2525 - auc: 0.7787 - val_loss: 0.2316 - val_auc: 0.8483\n",
      "Model: \"sequential_204\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_612 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_613 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_614 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_615 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.9267 - auc: 0.6337 - val_loss: 0.3146 - val_auc: 0.8400\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2952 - auc: 0.7272 - val_loss: 0.2410 - val_auc: 0.8469\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2630 - auc: 0.7528 - val_loss: 0.2357 - val_auc: 0.8519\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2568 - auc: 0.7644 - val_loss: 0.2298 - val_auc: 0.8535\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2531 - auc: 0.7738 - val_loss: 0.2295 - val_auc: 0.8508\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2555 - auc: 0.7617 - val_loss: 0.2326 - val_auc: 0.8520\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2541 - auc: 0.7779 - val_loss: 0.2321 - val_auc: 0.8469\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2551 - auc: 0.7675 - val_loss: 0.2347 - val_auc: 0.8475\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2533 - auc: 0.7767 - val_loss: 0.2304 - val_auc: 0.8452\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2516 - auc: 0.7847 - val_loss: 0.2314 - val_auc: 0.8462\n",
      "Model: \"sequential_205\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_615 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_616 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_617 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_618 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.9380 - auc: 0.6244 - val_loss: 0.3200 - val_auc: 0.8394\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2980 - auc: 0.7288 - val_loss: 0.2453 - val_auc: 0.8476\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2655 - auc: 0.7489 - val_loss: 0.2356 - val_auc: 0.8570\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2586 - auc: 0.7640 - val_loss: 0.2308 - val_auc: 0.8528\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2552 - auc: 0.7674 - val_loss: 0.2292 - val_auc: 0.8489\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2578 - auc: 0.7545 - val_loss: 0.2330 - val_auc: 0.8507\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2560 - auc: 0.7720 - val_loss: 0.2354 - val_auc: 0.8469\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2583 - auc: 0.7556 - val_loss: 0.2332 - val_auc: 0.8488\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2549 - auc: 0.7761 - val_loss: 0.2322 - val_auc: 0.8460\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2549 - auc: 0.7796 - val_loss: 0.2332 - val_auc: 0.8474\n",
      "Model: \"sequential_206\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_618 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_619 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_620 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_621 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.9633 - auc: 0.6099 - val_loss: 0.3319 - val_auc: 0.8379\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3066 - auc: 0.7244 - val_loss: 0.2450 - val_auc: 0.8465\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2708 - auc: 0.7405 - val_loss: 0.2380 - val_auc: 0.8537\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2646 - auc: 0.7513 - val_loss: 0.2326 - val_auc: 0.8523\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2596 - auc: 0.7603 - val_loss: 0.2325 - val_auc: 0.8514\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2604 - auc: 0.7499 - val_loss: 0.2348 - val_auc: 0.8519\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2590 - auc: 0.7600 - val_loss: 0.2348 - val_auc: 0.8488\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2590 - auc: 0.7542 - val_loss: 0.2316 - val_auc: 0.8494\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2557 - auc: 0.7658 - val_loss: 0.2300 - val_auc: 0.8450\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2542 - auc: 0.7782 - val_loss: 0.2340 - val_auc: 0.8450\n",
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_621 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_622 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_623 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_624 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 1.0452 - auc: 0.5937 - val_loss: 0.3782 - val_auc: 0.8408\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3370 - auc: 0.7175 - val_loss: 0.2549 - val_auc: 0.8485\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2862 - auc: 0.7162 - val_loss: 0.2422 - val_auc: 0.8540\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2730 - auc: 0.7386 - val_loss: 0.2375 - val_auc: 0.8526\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2653 - auc: 0.7534 - val_loss: 0.2356 - val_auc: 0.8511\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2689 - auc: 0.7388 - val_loss: 0.2402 - val_auc: 0.8533\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2661 - auc: 0.7401 - val_loss: 0.2391 - val_auc: 0.8481\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2702 - auc: 0.7270 - val_loss: 0.2359 - val_auc: 0.8528\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2653 - auc: 0.7329 - val_loss: 0.2358 - val_auc: 0.8456\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2659 - auc: 0.7430 - val_loss: 0.2436 - val_auc: 0.8474\n",
      "Model: \"sequential_208\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_624 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_625 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_626 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8389467954275115 0.0\n",
      "[0.8389467954275115, 0.8356242817685128, 0.8361887865164008, 0.8360154029152638, 0.8357351666297049, 0.8340416523860406, 0.8351787262353583, 0.8362250761073365, 0.8338037539565734, 0.8300397169411907]\n",
      "0.210353494775854 0.0\n",
      "[0.210353494775854, 0.21523306440761555, 0.21464585721219068, 0.21321615561306304, 0.2147168040257372, 0.21773909669945174, 0.22012311760491213, 0.21539964898982547, 0.22286692269010266, 0.22365065209279014]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(0, 1, 0.1)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(0.3, seed = 0),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(i, seed = 0),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_627 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.3916 - auc: 0.5503 - val_loss: 0.2596 - val_auc: 0.8246\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2629 - auc: 0.7409 - val_loss: 0.2274 - val_auc: 0.8486\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7812 - val_loss: 0.2250 - val_auc: 0.8517\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2472 - auc: 0.8000 - val_loss: 0.2249 - val_auc: 0.8517\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2461 - auc: 0.8014 - val_loss: 0.2247 - val_auc: 0.8461\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2453 - auc: 0.7996 - val_loss: 0.2259 - val_auc: 0.8461\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2460 - auc: 0.8013 - val_loss: 0.2250 - val_auc: 0.8467\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2454 - auc: 0.8017 - val_loss: 0.2249 - val_auc: 0.8492\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2456 - auc: 0.7973 - val_loss: 0.2254 - val_auc: 0.8468\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2471 - auc: 0.7929 - val_loss: 0.2254 - val_auc: 0.8480\n",
      "Model: \"sequential_209\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_627 (Dense)            (None, 8)                 240       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_628 (Dense)            (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dense_629 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,521\n",
      "Trainable params: 1,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_630 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.5549 - auc: 0.5717 - val_loss: 0.3138 - val_auc: 0.8288\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2934 - auc: 0.7649 - val_loss: 0.2425 - val_auc: 0.8507\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2594 - auc: 0.7941 - val_loss: 0.2306 - val_auc: 0.8515\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2519 - auc: 0.7976 - val_loss: 0.2269 - val_auc: 0.8537\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7992 - val_loss: 0.2255 - val_auc: 0.8521\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2473 - auc: 0.8019 - val_loss: 0.2249 - val_auc: 0.8515\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2467 - auc: 0.8012 - val_loss: 0.2244 - val_auc: 0.8471\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2455 - auc: 0.8011 - val_loss: 0.2251 - val_auc: 0.8476\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2453 - auc: 0.8075 - val_loss: 0.2244 - val_auc: 0.8477\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2463 - auc: 0.7966 - val_loss: 0.2246 - val_auc: 0.8483\n",
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_630 (Dense)            (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_631 (Dense)            (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dense_632 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,785\n",
      "Trainable params: 2,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_633 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.5062 - auc: 0.6351 - val_loss: 0.2650 - val_auc: 0.8437\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2661 - auc: 0.7700 - val_loss: 0.2349 - val_auc: 0.8521\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.8023 - val_loss: 0.2279 - val_auc: 0.8538\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2455 - auc: 0.8126 - val_loss: 0.2269 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2449 - auc: 0.8132 - val_loss: 0.2259 - val_auc: 0.8523\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2427 - auc: 0.8206 - val_loss: 0.2267 - val_auc: 0.8490\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2444 - auc: 0.8110 - val_loss: 0.2278 - val_auc: 0.8504\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2449 - auc: 0.8076 - val_loss: 0.2276 - val_auc: 0.8495\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2438 - auc: 0.8146 - val_loss: 0.2263 - val_auc: 0.8486\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2443 - auc: 0.8142 - val_loss: 0.2269 - val_auc: 0.8487\n",
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_633 (Dense)            (None, 24)                720       \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_634 (Dense)            (None, 128)               3200      \n",
      "_________________________________________________________________\n",
      "dense_635 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,049\n",
      "Trainable params: 4,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_636 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.7777 - auc: 0.5752 - val_loss: 0.3910 - val_auc: 0.8346\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3276 - auc: 0.7608 - val_loss: 0.2542 - val_auc: 0.8498\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2666 - auc: 0.7836 - val_loss: 0.2318 - val_auc: 0.8507\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2520 - auc: 0.7967 - val_loss: 0.2278 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.8021 - val_loss: 0.2266 - val_auc: 0.8538\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2465 - auc: 0.8043 - val_loss: 0.2256 - val_auc: 0.8523\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2458 - auc: 0.8060 - val_loss: 0.2255 - val_auc: 0.8524\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2436 - auc: 0.8190 - val_loss: 0.2266 - val_auc: 0.8538\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2439 - auc: 0.8166 - val_loss: 0.2249 - val_auc: 0.8514\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2436 - auc: 0.8151 - val_loss: 0.2257 - val_auc: 0.8511\n",
      "Model: \"sequential_212\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_636 (Dense)            (None, 32)                960       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_637 (Dense)            (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_638 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 5,313\n",
      "Trainable params: 5,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_639 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.8258 - auc: 0.5625 - val_loss: 0.3999 - val_auc: 0.8271\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3325 - auc: 0.7478 - val_loss: 0.2559 - val_auc: 0.8446\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2686 - auc: 0.7708 - val_loss: 0.2336 - val_auc: 0.8544\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2544 - auc: 0.7855 - val_loss: 0.2288 - val_auc: 0.8538\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2479 - auc: 0.8059 - val_loss: 0.2275 - val_auc: 0.8553\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2465 - auc: 0.8069 - val_loss: 0.2271 - val_auc: 0.8554\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2455 - auc: 0.8110 - val_loss: 0.2264 - val_auc: 0.8516\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2448 - auc: 0.8114 - val_loss: 0.2259 - val_auc: 0.8542\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2443 - auc: 0.8099 - val_loss: 0.2256 - val_auc: 0.8534\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2439 - auc: 0.8150 - val_loss: 0.2262 - val_auc: 0.8502\n",
      "Model: \"sequential_213\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_639 (Dense)            (None, 40)                1200      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_640 (Dense)            (None, 128)               5248      \n",
      "_________________________________________________________________\n",
      "dense_641 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 6,577\n",
      "Trainable params: 6,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_642 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.6895 - auc: 0.6294 - val_loss: 0.2964 - val_auc: 0.8326\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2758 - auc: 0.7704 - val_loss: 0.2344 - val_auc: 0.8508\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2522 - auc: 0.7901 - val_loss: 0.2297 - val_auc: 0.8518\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2474 - auc: 0.8030 - val_loss: 0.2275 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2463 - auc: 0.8024 - val_loss: 0.2273 - val_auc: 0.8542\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2456 - auc: 0.8088 - val_loss: 0.2261 - val_auc: 0.8516\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2442 - auc: 0.8157 - val_loss: 0.2270 - val_auc: 0.8508\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2448 - auc: 0.8093 - val_loss: 0.2265 - val_auc: 0.8491\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2458 - auc: 0.8052 - val_loss: 0.2280 - val_auc: 0.8490\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2454 - auc: 0.8060 - val_loss: 0.2282 - val_auc: 0.8500\n",
      "Model: \"sequential_214\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_642 (Dense)            (None, 48)                1440      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_643 (Dense)            (None, 128)               6272      \n",
      "_________________________________________________________________\n",
      "dense_644 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 7,841\n",
      "Trainable params: 7,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_645 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.6894 - auc: 0.6529 - val_loss: 0.2784 - val_auc: 0.8428\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2687 - auc: 0.7697 - val_loss: 0.2336 - val_auc: 0.8505\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2518 - auc: 0.7803 - val_loss: 0.2283 - val_auc: 0.8535\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7871 - val_loss: 0.2296 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2472 - auc: 0.7963 - val_loss: 0.2286 - val_auc: 0.8507\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2445 - auc: 0.8109 - val_loss: 0.2268 - val_auc: 0.8510\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2441 - auc: 0.8139 - val_loss: 0.2274 - val_auc: 0.8502\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2457 - auc: 0.8059 - val_loss: 0.2272 - val_auc: 0.8514\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2449 - auc: 0.8070 - val_loss: 0.2283 - val_auc: 0.8515\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2452 - auc: 0.8054 - val_loss: 0.2280 - val_auc: 0.8505\n",
      "Model: \"sequential_215\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_645 (Dense)            (None, 56)                1680      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 56)                0         \n",
      "_________________________________________________________________\n",
      "dense_646 (Dense)            (None, 128)               7296      \n",
      "_________________________________________________________________\n",
      "dense_647 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,105\n",
      "Trainable params: 9,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_648 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9507 - auc: 0.6008 - val_loss: 0.4084 - val_auc: 0.8446\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3363 - auc: 0.7400 - val_loss: 0.2548 - val_auc: 0.8482\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2680 - auc: 0.7695 - val_loss: 0.2330 - val_auc: 0.8539\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2536 - auc: 0.7882 - val_loss: 0.2299 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8055 - val_loss: 0.2288 - val_auc: 0.8566\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2461 - auc: 0.8098 - val_loss: 0.2274 - val_auc: 0.8533\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2458 - auc: 0.8130 - val_loss: 0.2274 - val_auc: 0.8507\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2461 - auc: 0.8050 - val_loss: 0.2267 - val_auc: 0.8516\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2444 - auc: 0.8139 - val_loss: 0.2263 - val_auc: 0.8563\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2466 - auc: 0.812 - 0s 5ms/step - loss: 0.2444 - auc: 0.8131 - val_loss: 0.2256 - val_auc: 0.8517\n",
      "Model: \"sequential_216\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_648 (Dense)            (None, 64)                1920      \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_649 (Dense)            (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_650 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 10,369\n",
      "Trainable params: 10,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_651 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.6799 - auc: 0.6575 - val_loss: 0.2624 - val_auc: 0.8450\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2646 - auc: 0.7700 - val_loss: 0.2288 - val_auc: 0.8528\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2503 - auc: 0.7877 - val_loss: 0.2272 - val_auc: 0.8545\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7839 - val_loss: 0.2256 - val_auc: 0.8505\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2487 - auc: 0.7860 - val_loss: 0.2280 - val_auc: 0.8523\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.7867 - val_loss: 0.2277 - val_auc: 0.8459\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.7902 - val_loss: 0.2282 - val_auc: 0.8502\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7870 - val_loss: 0.2300 - val_auc: 0.8490\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.7897 - val_loss: 0.2292 - val_auc: 0.8485\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.7947 - val_loss: 0.2274 - val_auc: 0.8467\n",
      "Model: \"sequential_217\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_651 (Dense)            (None, 72)                2160      \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_652 (Dense)            (None, 128)               9344      \n",
      "_________________________________________________________________\n",
      "dense_653 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 11,633\n",
      "Trainable params: 11,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_654 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.8118 - auc: 0.6626 - val_loss: 0.3047 - val_auc: 0.8436\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2825 - auc: 0.7701 - val_loss: 0.2366 - val_auc: 0.8506\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2567 - auc: 0.7739 - val_loss: 0.2313 - val_auc: 0.8524\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2523 - auc: 0.7774 - val_loss: 0.2285 - val_auc: 0.8555\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2491 - auc: 0.7914 - val_loss: 0.2301 - val_auc: 0.8509\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.7968 - val_loss: 0.2289 - val_auc: 0.8524\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2464 - auc: 0.8038 - val_loss: 0.2297 - val_auc: 0.8504\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2463 - auc: 0.8019 - val_loss: 0.2287 - val_auc: 0.8510\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2458 - auc: 0.8075 - val_loss: 0.2293 - val_auc: 0.8494\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2468 - auc: 0.8003 - val_loss: 0.2275 - val_auc: 0.8492\n",
      "Model: \"sequential_218\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_654 (Dense)            (None, 80)                2400      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_655 (Dense)            (None, 128)               10368     \n",
      "_________________________________________________________________\n",
      "dense_656 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 12,897\n",
      "Trainable params: 12,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_657 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9370 - auc: 0.6761 - val_loss: 0.3692 - val_auc: 0.8418\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3128 - auc: 0.7799 - val_loss: 0.2503 - val_auc: 0.8489\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2616 - auc: 0.7845 - val_loss: 0.2355 - val_auc: 0.8532\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2525 - auc: 0.7916 - val_loss: 0.2312 - val_auc: 0.8550\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8019 - val_loss: 0.2274 - val_auc: 0.8564\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7996 - val_loss: 0.2288 - val_auc: 0.8532\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2462 - auc: 0.8067 - val_loss: 0.2270 - val_auc: 0.8517\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2462 - auc: 0.8045 - val_loss: 0.2282 - val_auc: 0.8524\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2459 - auc: 0.802 - 0s 5ms/step - loss: 0.2460 - auc: 0.8021 - val_loss: 0.2283 - val_auc: 0.8525\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2459 - auc: 0.8052 - val_loss: 0.2277 - val_auc: 0.8475\n",
      "Model: \"sequential_219\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_657 (Dense)            (None, 88)                2640      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 88)                0         \n",
      "_________________________________________________________________\n",
      "dense_658 (Dense)            (None, 128)               11392     \n",
      "_________________________________________________________________\n",
      "dense_659 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 14,161\n",
      "Trainable params: 14,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_660 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8705 - auc: 0.6860 - val_loss: 0.3184 - val_auc: 0.8411\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2884 - auc: 0.7720 - val_loss: 0.2407 - val_auc: 0.8493\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2571 - auc: 0.7816 - val_loss: 0.2302 - val_auc: 0.8506\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2521 - auc: 0.7825 - val_loss: 0.2303 - val_auc: 0.8531\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7803 - val_loss: 0.2291 - val_auc: 0.8534\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2477 - auc: 0.7949 - val_loss: 0.2286 - val_auc: 0.8497\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2467 - auc: 0.8008 - val_loss: 0.2271 - val_auc: 0.8533\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2467 - auc: 0.7989 - val_loss: 0.2285 - val_auc: 0.8514\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2456 - auc: 0.8061 - val_loss: 0.2274 - val_auc: 0.8508\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2456 - auc: 0.8052 - val_loss: 0.2289 - val_auc: 0.8516\n",
      "Model: \"sequential_220\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_660 (Dense)            (None, 96)                2880      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_661 (Dense)            (None, 128)               12416     \n",
      "_________________________________________________________________\n",
      "dense_662 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 15,425\n",
      "Trainable params: 15,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_663 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.8996 - auc: 0.6615 - val_loss: 0.3206 - val_auc: 0.8428\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2889 - auc: 0.7693 - val_loss: 0.2385 - val_auc: 0.8493\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2571 - auc: 0.7720 - val_loss: 0.2299 - val_auc: 0.8519\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2508 - auc: 0.7879 - val_loss: 0.2276 - val_auc: 0.8540\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7850 - val_loss: 0.2269 - val_auc: 0.8506\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2499 - auc: 0.7832 - val_loss: 0.2292 - val_auc: 0.8521\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2485 - auc: 0.7908 - val_loss: 0.2307 - val_auc: 0.8504\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2468 - auc: 0.8012 - val_loss: 0.2284 - val_auc: 0.8500\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2481 - auc: 0.7936 - val_loss: 0.2285 - val_auc: 0.8499\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2476 - auc: 0.7976 - val_loss: 0.2287 - val_auc: 0.8489\n",
      "Model: \"sequential_221\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_663 (Dense)            (None, 104)               3120      \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 104)               0         \n",
      "_________________________________________________________________\n",
      "dense_664 (Dense)            (None, 128)               13440     \n",
      "_________________________________________________________________\n",
      "dense_665 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 16,689\n",
      "Trainable params: 16,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_666 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 1.0329 - auc: 0.6795 - val_loss: 0.3964 - val_auc: 0.8510\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3271 - auc: 0.7677 - val_loss: 0.2566 - val_auc: 0.8401\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2638 - auc: 0.7793 - val_loss: 0.2335 - val_auc: 0.8517\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2530 - auc: 0.7873 - val_loss: 0.2303 - val_auc: 0.8536\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2506 - auc: 0.7914 - val_loss: 0.2288 - val_auc: 0.8553\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2509 - auc: 0.7843 - val_loss: 0.2292 - val_auc: 0.8540\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2484 - auc: 0.7940 - val_loss: 0.2271 - val_auc: 0.8527\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2479 - auc: 0.7952 - val_loss: 0.2275 - val_auc: 0.8525\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2483 - auc: 0.7929 - val_loss: 0.2292 - val_auc: 0.8516\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2467 - auc: 0.7989 - val_loss: 0.2296 - val_auc: 0.8506\n",
      "Model: \"sequential_222\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_666 (Dense)            (None, 112)               3360      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_667 (Dense)            (None, 128)               14464     \n",
      "_________________________________________________________________\n",
      "dense_668 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 17,953\n",
      "Trainable params: 17,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_669 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.7978 - auc: 0.6730 - val_loss: 0.2763 - val_auc: 0.8432\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2708 - auc: 0.7621 - val_loss: 0.2297 - val_auc: 0.8518\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2546 - auc: 0.7716 - val_loss: 0.2269 - val_auc: 0.8549\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2515 - auc: 0.7791 - val_loss: 0.2267 - val_auc: 0.8522\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7839 - val_loss: 0.2269 - val_auc: 0.8504\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7881 - val_loss: 0.2287 - val_auc: 0.8521\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2493 - auc: 0.7883 - val_loss: 0.2271 - val_auc: 0.8484\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7854 - val_loss: 0.2286 - val_auc: 0.8447\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7959 - val_loss: 0.2284 - val_auc: 0.8463\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7904 - val_loss: 0.2278 - val_auc: 0.8447\n",
      "Model: \"sequential_223\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_669 (Dense)            (None, 120)               3600      \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_670 (Dense)            (None, 128)               15488     \n",
      "_________________________________________________________________\n",
      "dense_671 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 19,217\n",
      "Trainable params: 19,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_672 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.9012 - auc: 0.6602 - val_loss: 0.3033 - val_auc: 0.8359\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2816 - auc: 0.7563 - val_loss: 0.2344 - val_auc: 0.8496\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2569 - auc: 0.7632 - val_loss: 0.2309 - val_auc: 0.8522\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2527 - auc: 0.7716 - val_loss: 0.2309 - val_auc: 0.8509\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7854 - val_loss: 0.2295 - val_auc: 0.8563\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.7909 - val_loss: 0.2287 - val_auc: 0.8511\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2484 - auc: 0.7918 - val_loss: 0.2272 - val_auc: 0.8512\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.7944 - val_loss: 0.2270 - val_auc: 0.8523\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.7922 - val_loss: 0.2284 - val_auc: 0.8487\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2486 - auc: 0.7965 - val_loss: 0.2282 - val_auc: 0.8445\n",
      "Model: \"sequential_224\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_672 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_674 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,481\n",
      "Trainable params: 20,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_675 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.9001 - auc: 0.6754 - val_loss: 0.2998 - val_auc: 0.8438\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2800 - auc: 0.7578 - val_loss: 0.2338 - val_auc: 0.8514\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2561 - auc: 0.7661 - val_loss: 0.2273 - val_auc: 0.8512\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2523 - auc: 0.7728 - val_loss: 0.2274 - val_auc: 0.8517\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2518 - auc: 0.7723 - val_loss: 0.2282 - val_auc: 0.8523\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2511 - auc: 0.7797 - val_loss: 0.2288 - val_auc: 0.8483\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2499 - auc: 0.7848 - val_loss: 0.2299 - val_auc: 0.8496\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7859 - val_loss: 0.2281 - val_auc: 0.8446\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2487 - auc: 0.7909 - val_loss: 0.2293 - val_auc: 0.8459\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2489 - auc: 0.7897 - val_loss: 0.2278 - val_auc: 0.8506\n",
      "Model: \"sequential_225\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_675 (Dense)            (None, 136)               4080      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 136)               0         \n",
      "_________________________________________________________________\n",
      "dense_676 (Dense)            (None, 128)               17536     \n",
      "_________________________________________________________________\n",
      "dense_677 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 21,745\n",
      "Trainable params: 21,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_678 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.8961 - auc: 0.6625 - val_loss: 0.2914 - val_auc: 0.8439\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2757 - auc: 0.7660 - val_loss: 0.2312 - val_auc: 0.8506\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2555 - auc: 0.7690 - val_loss: 0.2278 - val_auc: 0.8548\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2522 - auc: 0.7722 - val_loss: 0.2272 - val_auc: 0.8509\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.7780 - val_loss: 0.2270 - val_auc: 0.8535\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2498 - auc: 0.7836 - val_loss: 0.2269 - val_auc: 0.8516\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7893 - val_loss: 0.2272 - val_auc: 0.8466\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.7915 - val_loss: 0.2276 - val_auc: 0.8492\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7911 - val_loss: 0.2279 - val_auc: 0.8487\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7920 - val_loss: 0.2277 - val_auc: 0.8474\n",
      "Model: \"sequential_226\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_678 (Dense)            (None, 144)               4320      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_679 (Dense)            (None, 128)               18560     \n",
      "_________________________________________________________________\n",
      "dense_680 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 23,009\n",
      "Trainable params: 23,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8389467954275115 128\n",
      "[0.8384145480937885, 0.836029515533961, 0.8338864135803713, 0.8348662325356343, 0.8321404810386889, 0.833852140077821, 0.8353682385435778, 0.832936835950888, 0.8351021148767163, 0.8326868409911091, 0.834908570391726, 0.8340295558557287, 0.8342855990806636, 0.8314005766012781, 0.8371464284994254, 0.8389467954275115, 0.8344327735327918, 0.8361948347815568]\n",
      "0.210353494775854 128\n",
      "[0.2142837232931332, 0.21426912682981022, 0.22084793621061388, 0.21908467518818947, 0.2193089101758155, 0.22093809978214676, 0.22214016840273093, 0.2194401587154332, 0.21499584919974946, 0.22232850129812837, 0.2199268177983567, 0.22301019674893086, 0.22342588001854752, 0.2250165040448033, 0.21221382944995335, 0.210353494775854, 0.21763006031683096, 0.21357172674968317]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(8, 150, 8)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(i, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(0.3, seed = 0),\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'red')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_681 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 2s 43ms/step - loss: 0.5249 - auc: 0.4939 - val_loss: 0.3344 - val_auc: 0.5070\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3221 - auc: 0.5513 - val_loss: 0.2877 - val_auc: 0.7076\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2986 - auc: 0.6755 - val_loss: 0.2743 - val_auc: 0.8340\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2886 - auc: 0.7576 - val_loss: 0.2659 - val_auc: 0.8417\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2836 - auc: 0.7188 - val_loss: 0.2584 - val_auc: 0.8480\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2756 - auc: 0.7607 - val_loss: 0.2531 - val_auc: 0.8491\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2717 - auc: 0.7529 - val_loss: 0.2479 - val_auc: 0.8498\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2674 - auc: 0.7499 - val_loss: 0.2436 - val_auc: 0.8433\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2630 - auc: 0.7703 - val_loss: 0.2401 - val_auc: 0.8485\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2594 - auc: 0.7836 - val_loss: 0.2380 - val_auc: 0.8461\n",
      "Model: \"sequential_227\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_681 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_682 (Dense)            (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dense_683 (Dense)            (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 3,971\n",
      "Trainable params: 3,971\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_684 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.6006 - auc: 0.5591 - val_loss: 0.3380 - val_auc: 0.8010\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3122 - auc: 0.6784 - val_loss: 0.2583 - val_auc: 0.8310\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2726 - auc: 0.7548 - val_loss: 0.2484 - val_auc: 0.8518\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2620 - auc: 0.7787 - val_loss: 0.2395 - val_auc: 0.8500\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2584 - auc: 0.7838 - val_loss: 0.2369 - val_auc: 0.8544\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2541 - auc: 0.8015 - val_loss: 0.2350 - val_auc: 0.8507\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2534 - auc: 0.7995 - val_loss: 0.2352 - val_auc: 0.8525\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2521 - auc: 0.7990 - val_loss: 0.2343 - val_auc: 0.8529\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2522 - auc: 0.7979 - val_loss: 0.2338 - val_auc: 0.8565\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.8027 - val_loss: 0.2341 - val_auc: 0.8552\n",
      "Model: \"sequential_228\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_684 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_685 (Dense)            (None, 11)                1419      \n",
      "_________________________________________________________________\n",
      "dense_686 (Dense)            (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 5,271\n",
      "Trainable params: 5,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_687 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.6350 - auc: 0.5730 - val_loss: 0.3163 - val_auc: 0.8311\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2985 - auc: 0.7138 - val_loss: 0.2483 - val_auc: 0.8384\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2642 - auc: 0.7597 - val_loss: 0.2396 - val_auc: 0.8523\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2573 - auc: 0.7754 - val_loss: 0.2343 - val_auc: 0.8538\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2549 - auc: 0.7789 - val_loss: 0.2330 - val_auc: 0.8555\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2538 - auc: 0.7799 - val_loss: 0.2334 - val_auc: 0.8520\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2525 - auc: 0.7858 - val_loss: 0.2327 - val_auc: 0.8495\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2506 - auc: 0.7926 - val_loss: 0.2338 - val_auc: 0.8524\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2503 - auc: 0.7968 - val_loss: 0.2308 - val_auc: 0.8532\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2495 - auc: 0.8000 - val_loss: 0.2316 - val_auc: 0.8510\n",
      "Model: \"sequential_229\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_687 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_688 (Dense)            (None, 21)                2709      \n",
      "_________________________________________________________________\n",
      "dense_689 (Dense)            (None, 1)                 22        \n",
      "=================================================================\n",
      "Total params: 6,571\n",
      "Trainable params: 6,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_690 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 28ms/step - loss: 0.7406 - auc: 0.5603 - val_loss: 0.3494 - val_auc: 0.8245\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 0.3111 - auc: 0.7257 - val_loss: 0.2534 - val_auc: 0.8413\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2655 - auc: 0.7726 - val_loss: 0.2386 - val_auc: 0.8479\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2564 - auc: 0.7837 - val_loss: 0.2337 - val_auc: 0.8565\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2540 - auc: 0.7878 - val_loss: 0.2331 - val_auc: 0.8548\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2518 - auc: 0.7916 - val_loss: 0.2323 - val_auc: 0.8537\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2519 - auc: 0.7882 - val_loss: 0.2320 - val_auc: 0.8552\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2502 - auc: 0.7944 - val_loss: 0.2312 - val_auc: 0.8529\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2497 - auc: 0.7986 - val_loss: 0.2302 - val_auc: 0.8525\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2492 - auc: 0.7995 - val_loss: 0.2316 - val_auc: 0.8495\n",
      "Model: \"sequential_230\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_690 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_691 (Dense)            (None, 31)                3999      \n",
      "_________________________________________________________________\n",
      "dense_692 (Dense)            (None, 1)                 32        \n",
      "=================================================================\n",
      "Total params: 7,871\n",
      "Trainable params: 7,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_693 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.8285 - auc: 0.5761 - val_loss: 0.3803 - val_auc: 0.8423\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3245 - auc: 0.7389 - val_loss: 0.2551 - val_auc: 0.8419\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2680 - auc: 0.7641 - val_loss: 0.2409 - val_auc: 0.8492\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2559 - auc: 0.7832 - val_loss: 0.2325 - val_auc: 0.8532\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2530 - auc: 0.7891 - val_loss: 0.2325 - val_auc: 0.8521\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2513 - auc: 0.7925 - val_loss: 0.2303 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2494 - auc: 0.8006 - val_loss: 0.2310 - val_auc: 0.8523\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2498 - auc: 0.7952 - val_loss: 0.2316 - val_auc: 0.8541\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2488 - auc: 0.7988 - val_loss: 0.2298 - val_auc: 0.8534\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2481 - auc: 0.8018 - val_loss: 0.2304 - val_auc: 0.8520\n",
      "Model: \"sequential_231\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_693 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_694 (Dense)            (None, 41)                5289      \n",
      "_________________________________________________________________\n",
      "dense_695 (Dense)            (None, 1)                 42        \n",
      "=================================================================\n",
      "Total params: 9,171\n",
      "Trainable params: 9,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_696 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 0.8126 - auc: 0.5839 - val_loss: 0.3457 - val_auc: 0.8325\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3070 - auc: 0.7292 - val_loss: 0.2483 - val_auc: 0.8364\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2624 - auc: 0.7650 - val_loss: 0.2364 - val_auc: 0.8478\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2540 - auc: 0.7853 - val_loss: 0.2317 - val_auc: 0.8538\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2518 - auc: 0.7894 - val_loss: 0.2308 - val_auc: 0.8542\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2513 - auc: 0.7864 - val_loss: 0.2318 - val_auc: 0.8535\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7903 - val_loss: 0.2307 - val_auc: 0.8548\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2483 - auc: 0.8013 - val_loss: 0.2298 - val_auc: 0.8535\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2489 - auc: 0.7958 - val_loss: 0.2289 - val_auc: 0.8524\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2467 - auc: 0.8063 - val_loss: 0.2281 - val_auc: 0.8483\n",
      "Model: \"sequential_232\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_696 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_697 (Dense)            (None, 51)                6579      \n",
      "_________________________________________________________________\n",
      "dense_698 (Dense)            (None, 1)                 52        \n",
      "=================================================================\n",
      "Total params: 10,471\n",
      "Trainable params: 10,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_699 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 29ms/step - loss: 0.8118 - auc: 0.6237 - val_loss: 0.3325 - val_auc: 0.8228\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2954 - auc: 0.7426 - val_loss: 0.2451 - val_auc: 0.8443\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2589 - auc: 0.7759 - val_loss: 0.2329 - val_auc: 0.8531\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2543 - auc: 0.7727 - val_loss: 0.2311 - val_auc: 0.8532\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2522 - auc: 0.7793 - val_loss: 0.2315 - val_auc: 0.8553\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2512 - auc: 0.7811 - val_loss: 0.2310 - val_auc: 0.8537\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2512 - auc: 0.7819 - val_loss: 0.2308 - val_auc: 0.8534\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2481 - auc: 0.7967 - val_loss: 0.2294 - val_auc: 0.8514\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2484 - auc: 0.7926 - val_loss: 0.2293 - val_auc: 0.8477\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2482 - auc: 0.7980 - val_loss: 0.2291 - val_auc: 0.8469\n",
      "Model: \"sequential_233\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_699 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_700 (Dense)            (None, 61)                7869      \n",
      "_________________________________________________________________\n",
      "dense_701 (Dense)            (None, 1)                 62        \n",
      "=================================================================\n",
      "Total params: 11,771\n",
      "Trainable params: 11,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_702 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 27ms/step - loss: 0.9819 - auc: 0.6116 - val_loss: 0.4160 - val_auc: 0.8382\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3422 - auc: 0.7281 - val_loss: 0.2579 - val_auc: 0.8426\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2696 - auc: 0.7650 - val_loss: 0.2384 - val_auc: 0.8505\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2547 - auc: 0.7877 - val_loss: 0.2312 - val_auc: 0.8509\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2513 - auc: 0.7948 - val_loss: 0.2301 - val_auc: 0.8546\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2495 - auc: 0.7987 - val_loss: 0.2290 - val_auc: 0.8559\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2483 - auc: 0.8003 - val_loss: 0.2296 - val_auc: 0.8542\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2475 - auc: 0.8035 - val_loss: 0.2292 - val_auc: 0.8550\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2476 - auc: 0.8005 - val_loss: 0.2302 - val_auc: 0.8507\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2486 - auc: 0.7967 - val_loss: 0.2288 - val_auc: 0.8494\n",
      "Model: \"sequential_234\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_702 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_703 (Dense)            (None, 71)                9159      \n",
      "_________________________________________________________________\n",
      "dense_704 (Dense)            (None, 1)                 72        \n",
      "=================================================================\n",
      "Total params: 13,071\n",
      "Trainable params: 13,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_705 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.9132 - auc: 0.6499 - val_loss: 0.3576 - val_auc: 0.8400\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3047 - auc: 0.7693 - val_loss: 0.2466 - val_auc: 0.8448\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2597 - auc: 0.7817 - val_loss: 0.2342 - val_auc: 0.8528\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2535 - auc: 0.7830 - val_loss: 0.2308 - val_auc: 0.8542\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2513 - auc: 0.7856 - val_loss: 0.2288 - val_auc: 0.8526\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.7865 - val_loss: 0.2309 - val_auc: 0.8556\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7948 - val_loss: 0.2300 - val_auc: 0.8512\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2481 - auc: 0.7966 - val_loss: 0.2289 - val_auc: 0.8509\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2488 - auc: 0.7944 - val_loss: 0.2295 - val_auc: 0.8512\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2478 - auc: 0.7992 - val_loss: 0.2306 - val_auc: 0.8525\n",
      "Model: \"sequential_235\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_705 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_706 (Dense)            (None, 81)                10449     \n",
      "_________________________________________________________________\n",
      "dense_707 (Dense)            (None, 1)                 82        \n",
      "=================================================================\n",
      "Total params: 14,371\n",
      "Trainable params: 14,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_708 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 26ms/step - loss: 0.9360 - auc: 0.6488 - val_loss: 0.3581 - val_auc: 0.8372\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3064 - auc: 0.7620 - val_loss: 0.2457 - val_auc: 0.8473\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2611 - auc: 0.7725 - val_loss: 0.2342 - val_auc: 0.8495\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2530 - auc: 0.7823 - val_loss: 0.2299 - val_auc: 0.8542\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2509 - auc: 0.7872 - val_loss: 0.2278 - val_auc: 0.8515\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2505 - auc: 0.7838 - val_loss: 0.2311 - val_auc: 0.8506\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2480 - auc: 0.7973 - val_loss: 0.2292 - val_auc: 0.8540\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2472 - auc: 0.8031 - val_loss: 0.2288 - val_auc: 0.8500\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2482 - auc: 0.7943 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2489 - auc: 0.7914 - val_loss: 0.2285 - val_auc: 0.8494\n",
      "Model: \"sequential_236\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_708 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_709 (Dense)            (None, 91)                11739     \n",
      "_________________________________________________________________\n",
      "dense_710 (Dense)            (None, 1)                 92        \n",
      "=================================================================\n",
      "Total params: 15,671\n",
      "Trainable params: 15,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_711 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.9794 - auc: 0.6495 - val_loss: 0.3668 - val_auc: 0.8358\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3082 - auc: 0.7680 - val_loss: 0.2463 - val_auc: 0.8440\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2600 - auc: 0.7789 - val_loss: 0.2334 - val_auc: 0.8508\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2536 - auc: 0.7793 - val_loss: 0.2311 - val_auc: 0.8546\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2504 - auc: 0.7894 - val_loss: 0.2295 - val_auc: 0.8525\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2489 - auc: 0.7934 - val_loss: 0.2286 - val_auc: 0.8544\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2490 - auc: 0.7920 - val_loss: 0.2294 - val_auc: 0.8532\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2493 - auc: 0.7899 - val_loss: 0.2287 - val_auc: 0.8527\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2496 - auc: 0.7867 - val_loss: 0.2302 - val_auc: 0.8498\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2493 - auc: 0.7906 - val_loss: 0.2280 - val_auc: 0.8490\n",
      "Model: \"sequential_237\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_711 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_712 (Dense)            (None, 101)               13029     \n",
      "_________________________________________________________________\n",
      "dense_713 (Dense)            (None, 1)                 102       \n",
      "=================================================================\n",
      "Total params: 16,971\n",
      "Trainable params: 16,971\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_714 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 1.0618 - auc: 0.6343 - val_loss: 0.4156 - val_auc: 0.8323\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3340 - auc: 0.7482 - val_loss: 0.2575 - val_auc: 0.8421\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2647 - auc: 0.7768 - val_loss: 0.2358 - val_auc: 0.8469\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2553 - auc: 0.7797 - val_loss: 0.2313 - val_auc: 0.8532\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2507 - auc: 0.7929 - val_loss: 0.2305 - val_auc: 0.8528\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2500 - auc: 0.7896 - val_loss: 0.2287 - val_auc: 0.8549\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2489 - auc: 0.7925 - val_loss: 0.2299 - val_auc: 0.8545\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2495 - auc: 0.7882 - val_loss: 0.2290 - val_auc: 0.8532\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2496 - auc: 0.7869 - val_loss: 0.2289 - val_auc: 0.8496\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2491 - auc: 0.7929 - val_loss: 0.2282 - val_auc: 0.8482\n",
      "Model: \"sequential_238\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_714 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_715 (Dense)            (None, 111)               14319     \n",
      "_________________________________________________________________\n",
      "dense_716 (Dense)            (None, 1)                 112       \n",
      "=================================================================\n",
      "Total params: 18,271\n",
      "Trainable params: 18,271\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_717 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 30ms/step - loss: 1.0143 - auc: 0.6486 - val_loss: 0.3697 - val_auc: 0.8403\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.3093 - auc: 0.7679 - val_loss: 0.2466 - val_auc: 0.8454\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2608 - auc: 0.7725 - val_loss: 0.2331 - val_auc: 0.8499\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2536 - auc: 0.7767 - val_loss: 0.2286 - val_auc: 0.8534\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2514 - auc: 0.7814 - val_loss: 0.2301 - val_auc: 0.8511\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2489 - auc: 0.7923 - val_loss: 0.2291 - val_auc: 0.8560\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2483 - auc: 0.7928 - val_loss: 0.2286 - val_auc: 0.8525\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2484 - auc: 0.7906 - val_loss: 0.2291 - val_auc: 0.8524\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2484 - auc: 0.7894 - val_loss: 0.2293 - val_auc: 0.8506\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2475 - auc: 0.7972 - val_loss: 0.2278 - val_auc: 0.8480\n",
      "Model: \"sequential_239\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_717 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_718 (Dense)            (None, 121)               15609     \n",
      "_________________________________________________________________\n",
      "dense_719 (Dense)            (None, 1)                 122       \n",
      "=================================================================\n",
      "Total params: 19,571\n",
      "Trainable params: 19,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_720 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 1.0556 - auc: 0.6686 - val_loss: 0.3845 - val_auc: 0.8447\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3195 - auc: 0.7626 - val_loss: 0.2502 - val_auc: 0.8425\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2628 - auc: 0.7714 - val_loss: 0.2349 - val_auc: 0.8495\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2528 - auc: 0.7820 - val_loss: 0.2294 - val_auc: 0.8540\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2514 - auc: 0.7823 - val_loss: 0.2292 - val_auc: 0.8518\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2498 - auc: 0.7874 - val_loss: 0.2279 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2490 - auc: 0.7888 - val_loss: 0.2297 - val_auc: 0.8508\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2476 - auc: 0.7951 - val_loss: 0.2289 - val_auc: 0.8516\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2486 - auc: 0.7882 - val_loss: 0.2286 - val_auc: 0.8513\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2475 - auc: 0.7962 - val_loss: 0.2283 - val_auc: 0.8492\n",
      "Model: \"sequential_240\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_720 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_721 (Dense)            (None, 131)               16899     \n",
      "_________________________________________________________________\n",
      "dense_722 (Dense)            (None, 1)                 132       \n",
      "=================================================================\n",
      "Total params: 20,871\n",
      "Trainable params: 20,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_723 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 24ms/step - loss: 1.0720 - auc: 0.6707 - val_loss: 0.3859 - val_auc: 0.8412\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3180 - auc: 0.7608 - val_loss: 0.2485 - val_auc: 0.8439\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2602 - auc: 0.7775 - val_loss: 0.2330 - val_auc: 0.8516\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2531 - auc: 0.7798 - val_loss: 0.2294 - val_auc: 0.8528\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2506 - auc: 0.7872 - val_loss: 0.2290 - val_auc: 0.8537\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2496 - auc: 0.7893 - val_loss: 0.2279 - val_auc: 0.8529\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2489 - auc: 0.7915 - val_loss: 0.2293 - val_auc: 0.8505\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2489 - auc: 0.7898 - val_loss: 0.2291 - val_auc: 0.8513\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2490 - auc: 0.7900 - val_loss: 0.2284 - val_auc: 0.8498\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2494 - auc: 0.7914 - val_loss: 0.2284 - val_auc: 0.8485\n",
      "Model: \"sequential_241\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_723 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_724 (Dense)            (None, 141)               18189     \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_725 (Dense)            (None, 1)                 142       \n",
      "=================================================================\n",
      "Total params: 22,171\n",
      "Trainable params: 22,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8356928287736135 141\n",
      "[0.826949053446503, 0.8285074897683514, 0.8315800084675713, 0.8312695308562328, 0.8323703151146146, 0.8353238845991009, 0.8338037539565735, 0.8338057700449588, 0.8331747343803553, 0.8347089776415798, 0.8332412652970707, 0.8343743069696176, 0.8339589927622427, 0.8335285578919779, 0.8356928287736135]\n",
      "0.2126271566574961 111\n",
      "[0.23113648367858952, 0.22510089484992943, 0.22335524053336095, 0.22247795248252464, 0.2212295930130172, 0.21793359942994459, 0.21895342899154072, 0.21642662869268167, 0.22278659038348148, 0.21661569487331808, 0.2175935753228475, 0.2126271566574961, 0.218092760769229, 0.2196332057108789, 0.21428684460102346]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(1, 150, 10)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(0.3, seed = 0),\n",
    "            tf.keras.layers.Dense(i, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'orange')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_726 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.0300 - auc: 0.6624 - val_loss: 0.3695 - val_auc: 0.8416\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3092 - auc: 0.7716 - val_loss: 0.2464 - val_auc: 0.8448\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2600 - auc: 0.7761 - val_loss: 0.2333 - val_auc: 0.8511\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2528 - auc: 0.7821 - val_loss: 0.2299 - val_auc: 0.8545\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2495 - auc: 0.7932 - val_loss: 0.2290 - val_auc: 0.8539\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.7947 - val_loss: 0.2284 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2487 - auc: 0.7901 - val_loss: 0.2279 - val_auc: 0.8509\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2476 - auc: 0.7959 - val_loss: 0.2286 - val_auc: 0.8505\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2485 - auc: 0.7890 - val_loss: 0.2288 - val_auc: 0.8491\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2484 - auc: 0.7934 - val_loss: 0.2286 - val_auc: 0.8467\n",
      "Model: \"sequential_242\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_726 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_727 (Dense)            (None, 130)               16770     \n",
      "_________________________________________________________________\n",
      "dense_728 (Dense)            (None, 1)                 131       \n",
      "=================================================================\n",
      "Total params: 20,741\n",
      "Trainable params: 20,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_729 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.0556 - auc: 0.6686 - val_loss: 0.3845 - val_auc: 0.8447\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3195 - auc: 0.7626 - val_loss: 0.2502 - val_auc: 0.8425\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2628 - auc: 0.7714 - val_loss: 0.2349 - val_auc: 0.8495\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2528 - auc: 0.7820 - val_loss: 0.2294 - val_auc: 0.8540\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2514 - auc: 0.7823 - val_loss: 0.2292 - val_auc: 0.8518\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.7874 - val_loss: 0.2279 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.7888 - val_loss: 0.2297 - val_auc: 0.8508\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.7951 - val_loss: 0.2289 - val_auc: 0.8516\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.7882 - val_loss: 0.2286 - val_auc: 0.8513\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2475 - auc: 0.7962 - val_loss: 0.2283 - val_auc: 0.8492\n",
      "Model: \"sequential_243\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_729 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_730 (Dense)            (None, 131)               16899     \n",
      "_________________________________________________________________\n",
      "dense_731 (Dense)            (None, 1)                 132       \n",
      "=================================================================\n",
      "Total params: 20,871\n",
      "Trainable params: 20,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_732 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.0657 - auc: 0.6603 - val_loss: 0.3894 - val_auc: 0.8392\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3199 - auc: 0.7675 - val_loss: 0.2500 - val_auc: 0.8434\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2618 - auc: 0.7774 - val_loss: 0.2338 - val_auc: 0.8492\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2535 - auc: 0.7787 - val_loss: 0.2290 - val_auc: 0.8540\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2508 - auc: 0.7854 - val_loss: 0.2280 - val_auc: 0.8542\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2508 - auc: 0.7798 - val_loss: 0.2316 - val_auc: 0.8524\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2486 - auc: 0.7923 - val_loss: 0.2285 - val_auc: 0.8523\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2471 - auc: 0.7983 - val_loss: 0.2293 - val_auc: 0.8500\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2471 - auc: 0.8001 - val_loss: 0.2277 - val_auc: 0.8511\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7936 - val_loss: 0.2281 - val_auc: 0.8492\n",
      "Model: \"sequential_244\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_732 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_733 (Dense)            (None, 132)               17028     \n",
      "_________________________________________________________________\n",
      "dense_734 (Dense)            (None, 1)                 133       \n",
      "=================================================================\n",
      "Total params: 21,001\n",
      "Trainable params: 21,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_735 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9948 - auc: 0.6637 - val_loss: 0.3453 - val_auc: 0.8372\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2991 - auc: 0.7628 - val_loss: 0.2426 - val_auc: 0.8456\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2589 - auc: 0.7703 - val_loss: 0.2319 - val_auc: 0.8513\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2531 - auc: 0.7743 - val_loss: 0.2285 - val_auc: 0.8542\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2501 - auc: 0.7864 - val_loss: 0.2278 - val_auc: 0.8541\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2501 - auc: 0.7828 - val_loss: 0.2300 - val_auc: 0.8566\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7890 - val_loss: 0.2276 - val_auc: 0.8515\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7890 - val_loss: 0.2281 - val_auc: 0.8480\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7943 - val_loss: 0.2279 - val_auc: 0.8515\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.7971 - val_loss: 0.2274 - val_auc: 0.8486\n",
      "Model: \"sequential_245\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_735 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_736 (Dense)            (None, 133)               17157     \n",
      "_________________________________________________________________\n",
      "dense_737 (Dense)            (None, 1)                 134       \n",
      "=================================================================\n",
      "Total params: 21,131\n",
      "Trainable params: 21,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_738 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 1.1498 - auc: 0.6504 - val_loss: 0.4381 - val_auc: 0.8364\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.3429 - auc: 0.7657 - val_loss: 0.2577 - val_auc: 0.8395\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2655 - auc: 0.7827 - val_loss: 0.2361 - val_auc: 0.8496\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2542 - auc: 0.7863 - val_loss: 0.2302 - val_auc: 0.8526\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2518 - auc: 0.7854 - val_loss: 0.2290 - val_auc: 0.8542\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2514 - auc: 0.7806 - val_loss: 0.2314 - val_auc: 0.8503\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.7920 - val_loss: 0.2291 - val_auc: 0.8538\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.7962 - val_loss: 0.2282 - val_auc: 0.8524\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2477 - auc: 0.7982 - val_loss: 0.2275 - val_auc: 0.8521\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.7965 - val_loss: 0.2296 - val_auc: 0.8524\n",
      "Model: \"sequential_246\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_738 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_739 (Dense)            (None, 134)               17286     \n",
      "_________________________________________________________________\n",
      "dense_740 (Dense)            (None, 1)                 135       \n",
      "=================================================================\n",
      "Total params: 21,261\n",
      "Trainable params: 21,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_741 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.9974 - auc: 0.6636 - val_loss: 0.3470 - val_auc: 0.8379\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2997 - auc: 0.7637 - val_loss: 0.2430 - val_auc: 0.8449\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2588 - auc: 0.7708 - val_loss: 0.2322 - val_auc: 0.8535\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2530 - auc: 0.7767 - val_loss: 0.2293 - val_auc: 0.8525\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7881 - val_loss: 0.2283 - val_auc: 0.8546\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.7902 - val_loss: 0.2288 - val_auc: 0.8556\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2489 - auc: 0.7897 - val_loss: 0.2282 - val_auc: 0.8516\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.7943 - val_loss: 0.2279 - val_auc: 0.8502\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2477 - auc: 0.7961 - val_loss: 0.2292 - val_auc: 0.8500\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2479 - auc: 0.7967 - val_loss: 0.2279 - val_auc: 0.8500\n",
      "Model: \"sequential_247\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_741 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 128)               0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "dense_742 (Dense)            (None, 135)               17415     \n",
      "_________________________________________________________________\n",
      "dense_743 (Dense)            (None, 1)                 136       \n",
      "=================================================================\n",
      "Total params: 21,391\n",
      "Trainable params: 21,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_744 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.0216 - auc: 0.6640 - val_loss: 0.3559 - val_auc: 0.8396\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3036 - auc: 0.7675 - val_loss: 0.2438 - val_auc: 0.8470\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2598 - auc: 0.7719 - val_loss: 0.2336 - val_auc: 0.8523\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2528 - auc: 0.7781 - val_loss: 0.2301 - val_auc: 0.8534\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2502 - auc: 0.7857 - val_loss: 0.2289 - val_auc: 0.8519\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7832 - val_loss: 0.2289 - val_auc: 0.8549\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2477 - auc: 0.7976 - val_loss: 0.2292 - val_auc: 0.8515\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2484 - auc: 0.7930 - val_loss: 0.2272 - val_auc: 0.8494\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2491 - auc: 0.7879 - val_loss: 0.2286 - val_auc: 0.8488\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2482 - auc: 0.7994 - val_loss: 0.2287 - val_auc: 0.8472\n",
      "Model: \"sequential_248\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_744 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_745 (Dense)            (None, 136)               17544     \n",
      "_________________________________________________________________\n",
      "dense_746 (Dense)            (None, 1)                 137       \n",
      "=================================================================\n",
      "Total params: 21,521\n",
      "Trainable params: 21,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_747 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 1.0245 - auc: 0.6610 - val_loss: 0.3564 - val_auc: 0.8395\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3038 - auc: 0.7650 - val_loss: 0.2445 - val_auc: 0.8437\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2594 - auc: 0.7741 - val_loss: 0.2335 - val_auc: 0.8521\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2530 - auc: 0.7766 - val_loss: 0.2298 - val_auc: 0.8539\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2501 - auc: 0.7864 - val_loss: 0.2300 - val_auc: 0.8523\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.7922 - val_loss: 0.2296 - val_auc: 0.8525\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.7899 - val_loss: 0.2289 - val_auc: 0.8518\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.7934 - val_loss: 0.2290 - val_auc: 0.8511\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2476 - auc: 0.7962 - val_loss: 0.2286 - val_auc: 0.8498\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2478 - auc: 0.7979 - val_loss: 0.2275 - val_auc: 0.8483\n",
      "Model: \"sequential_249\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_747 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_748 (Dense)            (None, 137)               17673     \n",
      "_________________________________________________________________\n",
      "dense_749 (Dense)            (None, 1)                 138       \n",
      "=================================================================\n",
      "Total params: 21,651\n",
      "Trainable params: 21,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_750 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.9849 - auc: 0.6718 - val_loss: 0.3338 - val_auc: 0.8425\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2947 - auc: 0.7582 - val_loss: 0.2402 - val_auc: 0.8462\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2578 - auc: 0.7728 - val_loss: 0.2316 - val_auc: 0.8535\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2528 - auc: 0.7760 - val_loss: 0.2292 - val_auc: 0.8536\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2499 - auc: 0.7876 - val_loss: 0.2296 - val_auc: 0.8500\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.7953 - val_loss: 0.2279 - val_auc: 0.8516\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7936 - val_loss: 0.2276 - val_auc: 0.8496\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2484 - auc: 0.7898 - val_loss: 0.2294 - val_auc: 0.8489\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2485 - auc: 0.7891 - val_loss: 0.2293 - val_auc: 0.8487\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2469 - auc: 0.8026 - val_loss: 0.2281 - val_auc: 0.8472\n",
      "Model: \"sequential_250\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_750 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_751 (Dense)            (None, 138)               17802     \n",
      "_________________________________________________________________\n",
      "dense_752 (Dense)            (None, 1)                 139       \n",
      "=================================================================\n",
      "Total params: 21,781\n",
      "Trainable params: 21,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_753 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.0291 - auc: 0.6535 - val_loss: 0.3552 - val_auc: 0.8349\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.3041 - auc: 0.7595 - val_loss: 0.2447 - val_auc: 0.8447\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2593 - auc: 0.7723 - val_loss: 0.2324 - val_auc: 0.8500\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2527 - auc: 0.7770 - val_loss: 0.2290 - val_auc: 0.8539\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2507 - auc: 0.7837 - val_loss: 0.2287 - val_auc: 0.8539\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2505 - auc: 0.7810 - val_loss: 0.2284 - val_auc: 0.8508\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.7838 - val_loss: 0.2283 - val_auc: 0.8500\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7839 - val_loss: 0.2290 - val_auc: 0.8512\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.7893 - val_loss: 0.2283 - val_auc: 0.8492\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.7973 - val_loss: 0.2277 - val_auc: 0.8473\n",
      "Model: \"sequential_251\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_753 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_754 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_755 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_756 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.0062 - auc: 0.6681 - val_loss: 0.3485 - val_auc: 0.8368\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3003 - auc: 0.7606 - val_loss: 0.2420 - val_auc: 0.8451\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2589 - auc: 0.7704 - val_loss: 0.2322 - val_auc: 0.8505\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2525 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8524\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2510 - auc: 0.7814 - val_loss: 0.2290 - val_auc: 0.8576\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2495 - auc: 0.7870 - val_loss: 0.2278 - val_auc: 0.8558\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.7810 - val_loss: 0.2305 - val_auc: 0.8509\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.2500 - auc: 0.790 - 0s 6ms/step - loss: 0.2475 - auc: 0.7948 - val_loss: 0.2291 - val_auc: 0.8529\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.7929 - val_loss: 0.2271 - val_auc: 0.8479\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.7950 - val_loss: 0.2286 - val_auc: 0.8481\n",
      "Model: \"sequential_252\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_756 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_757 (Dense)            (None, 140)               18060     \n",
      "_________________________________________________________________\n",
      "dense_758 (Dense)            (None, 1)                 141       \n",
      "=================================================================\n",
      "Total params: 22,041\n",
      "Trainable params: 22,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_759 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.0720 - auc: 0.6707 - val_loss: 0.3859 - val_auc: 0.8412\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3180 - auc: 0.7608 - val_loss: 0.2485 - val_auc: 0.8439\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2602 - auc: 0.7775 - val_loss: 0.2330 - val_auc: 0.8516\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2531 - auc: 0.7798 - val_loss: 0.2294 - val_auc: 0.8528\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.7872 - val_loss: 0.2290 - val_auc: 0.8537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2496 - auc: 0.7893 - val_loss: 0.2279 - val_auc: 0.8529\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7915 - val_loss: 0.2293 - val_auc: 0.8505\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7898 - val_loss: 0.2291 - val_auc: 0.8513\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2490 - auc: 0.7900 - val_loss: 0.2284 - val_auc: 0.8498\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7914 - val_loss: 0.2284 - val_auc: 0.8485\n",
      "Model: \"sequential_253\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_759 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_760 (Dense)            (None, 141)               18189     \n",
      "_________________________________________________________________\n",
      "dense_761 (Dense)            (None, 1)                 142       \n",
      "=================================================================\n",
      "Total params: 22,171\n",
      "Trainable params: 22,171\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_762 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 13ms/step - loss: 0.9763 - auc: 0.6704 - val_loss: 0.3301 - val_auc: 0.8414\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2909 - auc: 0.7707 - val_loss: 0.2391 - val_auc: 0.8480\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2579 - auc: 0.7688 - val_loss: 0.2317 - val_auc: 0.8529\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2523 - auc: 0.7770 - val_loss: 0.2278 - val_auc: 0.8560\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.7835 - val_loss: 0.2288 - val_auc: 0.8534\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7794 - val_loss: 0.2300 - val_auc: 0.8554\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2484 - auc: 0.7925 - val_loss: 0.2282 - val_auc: 0.8511\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2481 - auc: 0.7930 - val_loss: 0.2294 - val_auc: 0.8512\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7873 - val_loss: 0.2281 - val_auc: 0.8488\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7933 - val_loss: 0.2272 - val_auc: 0.8498\n",
      "Model: \"sequential_254\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_762 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_763 (Dense)            (None, 142)               18318     \n",
      "_________________________________________________________________\n",
      "dense_764 (Dense)            (None, 1)                 143       \n",
      "=================================================================\n",
      "Total params: 22,301\n",
      "Trainable params: 22,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_765 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 1.0364 - auc: 0.6654 - val_loss: 0.3585 - val_auc: 0.8411\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3059 - auc: 0.7645 - val_loss: 0.2451 - val_auc: 0.8432\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2590 - auc: 0.7767 - val_loss: 0.2323 - val_auc: 0.8505\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2519 - auc: 0.7837 - val_loss: 0.2283 - val_auc: 0.8538\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7878 - val_loss: 0.2294 - val_auc: 0.8512\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2490 - auc: 0.7911 - val_loss: 0.2278 - val_auc: 0.8554\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.7896 - val_loss: 0.2293 - val_auc: 0.8519\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.7897 - val_loss: 0.2292 - val_auc: 0.8490\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.7933 - val_loss: 0.2277 - val_auc: 0.8496\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2476 - auc: 0.7952 - val_loss: 0.2297 - val_auc: 0.8504\n",
      "Model: \"sequential_255\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_765 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_766 (Dense)            (None, 143)               18447     \n",
      "_________________________________________________________________\n",
      "dense_767 (Dense)            (None, 1)                 144       \n",
      "=================================================================\n",
      "Total params: 22,431\n",
      "Trainable params: 22,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_768 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 16ms/step - loss: 1.0568 - auc: 0.6635 - val_loss: 0.3690 - val_auc: 0.8392\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3107 - auc: 0.7640 - val_loss: 0.2478 - val_auc: 0.8461\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2607 - auc: 0.7752 - val_loss: 0.2336 - val_auc: 0.8532\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2536 - auc: 0.7772 - val_loss: 0.2310 - val_auc: 0.8529\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2520 - auc: 0.7792 - val_loss: 0.2291 - val_auc: 0.8533\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2498 - auc: 0.7873 - val_loss: 0.2284 - val_auc: 0.8554\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2481 - auc: 0.7937 - val_loss: 0.2292 - val_auc: 0.8517\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.7928 - val_loss: 0.2297 - val_auc: 0.8531\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2470 - auc: 0.7977 - val_loss: 0.2285 - val_auc: 0.8506\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2474 - auc: 0.8018 - val_loss: 0.2275 - val_auc: 0.8471\n",
      "Model: \"sequential_256\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_768 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_769 (Dense)            (None, 144)               18576     \n",
      "_________________________________________________________________\n",
      "dense_770 (Dense)            (None, 1)                 145       \n",
      "=================================================================\n",
      "Total params: 22,561\n",
      "Trainable params: 22,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_771 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 1.0596 - auc: 0.6666 - val_loss: 0.3757 - val_auc: 0.8399\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.3128 - auc: 0.7604 - val_loss: 0.2473 - val_auc: 0.8453\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2599 - auc: 0.7749 - val_loss: 0.2326 - val_auc: 0.8505\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2528 - auc: 0.7799 - val_loss: 0.2277 - val_auc: 0.8531\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2518 - auc: 0.7781 - val_loss: 0.2282 - val_auc: 0.8530\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2507 - auc: 0.7810 - val_loss: 0.2299 - val_auc: 0.8532\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2488 - auc: 0.7892 - val_loss: 0.2294 - val_auc: 0.8526\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.7884 - val_loss: 0.2299 - val_auc: 0.8490\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2467 - auc: 0.8000 - val_loss: 0.2285 - val_auc: 0.8509\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2469 - auc: 0.8018 - val_loss: 0.2269 - val_auc: 0.8507\n",
      "Model: \"sequential_257\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_771 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_772 (Dense)            (None, 145)               18705     \n",
      "_________________________________________________________________\n",
      "dense_773 (Dense)            (None, 1)                 146       \n",
      "=================================================================\n",
      "Total params: 22,691\n",
      "Trainable params: 22,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_774 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9448 - auc: 0.6639 - val_loss: 0.3147 - val_auc: 0.8357\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2846 - auc: 0.7629 - val_loss: 0.2362 - val_auc: 0.8480\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2574 - auc: 0.7651 - val_loss: 0.2305 - val_auc: 0.8529\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2528 - auc: 0.7720 - val_loss: 0.2285 - val_auc: 0.8547\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2516 - auc: 0.7751 - val_loss: 0.2278 - val_auc: 0.8534\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2499 - auc: 0.7824 - val_loss: 0.2290 - val_auc: 0.8497\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.7911 - val_loss: 0.2300 - val_auc: 0.8504\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.7895 - val_loss: 0.2273 - val_auc: 0.8509\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.7908 - val_loss: 0.2291 - val_auc: 0.8498\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2479 - auc: 0.7922 - val_loss: 0.2295 - val_auc: 0.8489\n",
      "Model: \"sequential_258\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_774 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_775 (Dense)            (None, 146)               18834     \n",
      "_________________________________________________________________\n",
      "dense_776 (Dense)            (None, 1)                 147       \n",
      "=================================================================\n",
      "Total params: 22,821\n",
      "Trainable params: 22,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_777 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 15ms/step - loss: 1.0116 - auc: 0.6630 - val_loss: 0.3449 - val_auc: 0.8386\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2984 - auc: 0.7642 - val_loss: 0.2416 - val_auc: 0.8478\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2594 - auc: 0.7648 - val_loss: 0.2333 - val_auc: 0.8506\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2528 - auc: 0.7749 - val_loss: 0.2281 - val_auc: 0.8527\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2517 - auc: 0.7765 - val_loss: 0.2292 - val_auc: 0.8578\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2501 - auc: 0.7825 - val_loss: 0.2285 - val_auc: 0.8516\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2493 - auc: 0.7872 - val_loss: 0.2300 - val_auc: 0.8524\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7840 - val_loss: 0.2295 - val_auc: 0.8501\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2498 - auc: 0.7877 - val_loss: 0.2282 - val_auc: 0.8486\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7925 - val_loss: 0.2280 - val_auc: 0.8474\n",
      "Model: \"sequential_259\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_777 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_778 (Dense)            (None, 147)               18963     \n",
      "_________________________________________________________________\n",
      "dense_779 (Dense)            (None, 1)                 148       \n",
      "=================================================================\n",
      "Total params: 22,951\n",
      "Trainable params: 22,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_780 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.0825 - auc: 0.6631 - val_loss: 0.3843 - val_auc: 0.8410\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.3171 - auc: 0.7607 - val_loss: 0.2499 - val_auc: 0.8462\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2616 - auc: 0.7766 - val_loss: 0.2341 - val_auc: 0.8500\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2522 - auc: 0.7881 - val_loss: 0.2294 - val_auc: 0.8536\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.2512 - auc: 0.7862 - val_loss: 0.2300 - val_auc: 0.8504\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7900 - val_loss: 0.2291 - val_auc: 0.8541\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2490 - auc: 0.7904 - val_loss: 0.2296 - val_auc: 0.8507\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2485 - auc: 0.7914 - val_loss: 0.2289 - val_auc: 0.8516\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.2466 - auc: 0.8028 - val_loss: 0.2275 - val_auc: 0.8508\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2455 - auc: 0.8068 - val_loss: 0.2280 - val_auc: 0.8507\n",
      "Model: \"sequential_260\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_780 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_781 (Dense)            (None, 148)               19092     \n",
      "_________________________________________________________________\n",
      "dense_782 (Dense)            (None, 1)                 149       \n",
      "=================================================================\n",
      "Total params: 23,081\n",
      "Trainable params: 23,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_783 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.9958 - auc: 0.6603 - val_loss: 0.3372 - val_auc: 0.8358\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2943 - auc: 0.7612 - val_loss: 0.2396 - val_auc: 0.8472\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2587 - auc: 0.7664 - val_loss: 0.2320 - val_auc: 0.8517\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2530 - auc: 0.7762 - val_loss: 0.2282 - val_auc: 0.8519\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2520 - auc: 0.7733 - val_loss: 0.2283 - val_auc: 0.8504\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2508 - auc: 0.7811 - val_loss: 0.2285 - val_auc: 0.8539\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2491 - auc: 0.7901 - val_loss: 0.2284 - val_auc: 0.8502\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2496 - auc: 0.7833 - val_loss: 0.2293 - val_auc: 0.8507\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7809 - val_loss: 0.2284 - val_auc: 0.8500\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2487 - auc: 0.7928 - val_loss: 0.2281 - val_auc: 0.8502\n",
      "Model: \"sequential_261\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_783 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_784 (Dense)            (None, 149)               19221     \n",
      "_________________________________________________________________\n",
      "dense_785 (Dense)            (None, 1)                 150       \n",
      "=================================================================\n",
      "Total params: 23,211\n",
      "Trainable params: 23,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8374367452269107 139\n",
      "[0.8346444628132497, 0.8335285578919779, 0.8333763432188865, 0.8354841636257333, 0.8329640531440898, 0.8356484748291366, 0.8348541360053223, 0.8347896211769924, 0.834031571944114, 0.8374367452269107, 0.833807786133344, 0.8356928287736135, 0.8354065442228987, 0.8320033870284873, 0.8357916171044938, 0.8358460514908974, 0.8338067780891515, 0.8364861595532347, 0.8351000987883309, 0.8343077760529021]\n",
      "0.2132915668074922 144\n",
      "[0.21807314160876878, 0.2196332057108789, 0.21610883771874337, 0.21409757379503125, 0.22088513390298958, 0.21558443003968134, 0.21438786596831014, 0.21555690874065497, 0.2178486031336879, 0.2132968133874305, 0.2171677389481131, 0.21428684460102346, 0.21628796387635038, 0.2228258961598971, 0.2132915668074922, 0.21604839939330148, 0.22107469815716357, 0.2136248447630626, 0.21878566866278126, 0.217336085956332]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(130, 150)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(0.3, seed = 0),\n",
    "            tf.keras.layers.Dense(i, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 128, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'orange')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_786 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "150/150 [==============================] - 1s 5ms/step - loss: 0.4836 - auc: 0.6902 - val_loss: 0.2404 - val_auc: 0.8388\n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 1s 4ms/step - loss: 0.2615 - auc: 0.7456 - val_loss: 0.2406 - val_auc: 0.8416\n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2587 - auc: 0.7563 - val_loss: 0.2457 - val_auc: 0.8461\n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2566 - auc: 0.7613 - val_loss: 0.2422 - val_auc: 0.8493\n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 1s 3ms/step - loss: 0.2575 - auc: 0.7583 - val_loss: 0.2409 - val_auc: 0.8468\n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2588 - auc: 0.7506 - val_loss: 0.2412 - val_auc: 0.8444\n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2577 - auc: 0.7571 - val_loss: 0.2495 - val_auc: 0.8502\n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2576 - auc: 0.7512 - val_loss: 0.2411 - val_auc: 0.8458\n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.2574 - auc: 0.7560 - val_loss: 0.2457 - val_auc: 0.8472\n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.2629 - auc: 0.7322 - val_loss: 0.2422 - val_auc: 0.8421\n",
      "Model: \"sequential_262\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_786 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_787 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_788 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_789 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "120/120 [==============================] - 1s 5ms/step - loss: 0.5352 - auc: 0.7009 - val_loss: 0.2420 - val_auc: 0.8355\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2590 - auc: 0.7658 - val_loss: 0.2372 - val_auc: 0.8470\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2560 - auc: 0.7749 - val_loss: 0.2348 - val_auc: 0.8458\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2556 - auc: 0.7767 - val_loss: 0.2386 - val_auc: 0.8469\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2552 - auc: 0.7781 - val_loss: 0.2407 - val_auc: 0.8464\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2555 - auc: 0.7710 - val_loss: 0.2366 - val_auc: 0.8465\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2548 - auc: 0.7770 - val_loss: 0.2403 - val_auc: 0.8439\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2553 - auc: 0.7768 - val_loss: 0.2432 - val_auc: 0.8461\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2559 - auc: 0.7689 - val_loss: 0.2395 - val_auc: 0.8443\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 0.2533 - auc: 0.7787 - val_loss: 0.2389 - val_auc: 0.8450\n",
      "Model: \"sequential_263\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_789 (Dense)            (40, 128)                 3840      \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (40, 128)                 0         \n",
      "_________________________________________________________________\n",
      "dense_790 (Dense)            (40, 139)                 17931     \n",
      "_________________________________________________________________\n",
      "dense_791 (Dense)            (40, 1)                   140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_792 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.5741 - auc: 0.7174 - val_loss: 0.2403 - val_auc: 0.8399\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2588 - auc: 0.7697 - val_loss: 0.2377 - val_auc: 0.8436\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2566 - auc: 0.7699 - val_loss: 0.2376 - val_auc: 0.8506\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.2555 - auc: 0.7700 - val_loss: 0.2360 - val_auc: 0.8438\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2543 - auc: 0.7750 - val_loss: 0.2344 - val_auc: 0.8414\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2530 - auc: 0.7832 - val_loss: 0.2352 - val_auc: 0.8449\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2536 - auc: 0.7815 - val_loss: 0.2403 - val_auc: 0.8471\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2541 - auc: 0.7757 - val_loss: 0.2385 - val_auc: 0.8448\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.2548 - auc: 0.7751 - val_loss: 0.2388 - val_auc: 0.8427\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.2540 - auc: 0.7795 - val_loss: 0.2364 - val_auc: 0.8476\n",
      "Model: \"sequential_264\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_792 (Dense)            (48, 128)                 3840      \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (48, 128)                 0         \n",
      "_________________________________________________________________\n",
      "dense_793 (Dense)            (48, 139)                 17931     \n",
      "_________________________________________________________________\n",
      "dense_794 (Dense)            (48, 1)                   140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_795 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.6290 - auc: 0.6694 - val_loss: 0.2381 - val_auc: 0.8413\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2596 - auc: 0.7661 - val_loss: 0.2295 - val_auc: 0.8497\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 0s 4ms/step - loss: 0.2540 - auc: 0.7780 - val_loss: 0.2280 - val_auc: 0.8462\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7873 - val_loss: 0.2284 - val_auc: 0.8475\n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7947 - val_loss: 0.2293 - val_auc: 0.8462\n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2515 - auc: 0.7893 - val_loss: 0.2305 - val_auc: 0.8472\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2511 - auc: 0.7909 - val_loss: 0.2283 - val_auc: 0.8435\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2520 - auc: 0.7838 - val_loss: 0.2314 - val_auc: 0.8463\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7988 - val_loss: 0.2286 - val_auc: 0.8461\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - 0s 3ms/step - loss: 0.2505 - auc: 0.7951 - val_loss: 0.2351 - val_auc: 0.8483\n",
      "Model: \"sequential_265\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_795 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_796 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_797 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_798 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "75/75 [==============================] - 1s 8ms/step - loss: 0.6834 - auc: 0.6511 - val_loss: 0.2432 - val_auc: 0.8387\n",
      "Epoch 2/10\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.2601 - auc: 0.7740 - val_loss: 0.2303 - val_auc: 0.8487\n",
      "Epoch 3/10\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.2544 - auc: 0.7802 - val_loss: 0.2275 - val_auc: 0.8467\n",
      "Epoch 4/10\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.2513 - auc: 0.7886 - val_loss: 0.2276 - val_auc: 0.8480\n",
      "Epoch 5/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2505 - auc: 0.7938 - val_loss: 0.2288 - val_auc: 0.8451\n",
      "Epoch 6/10\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.2507 - auc: 0.7888 - val_loss: 0.2288 - val_auc: 0.8456\n",
      "Epoch 7/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7948 - val_loss: 0.2275 - val_auc: 0.8442\n",
      "Epoch 8/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7966 - val_loss: 0.2293 - val_auc: 0.8416\n",
      "Epoch 9/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.7890 - val_loss: 0.2280 - val_auc: 0.8432\n",
      "Epoch 10/10\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7898 - val_loss: 0.2289 - val_auc: 0.8432\n",
      "Model: \"sequential_266\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_798 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_799 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_800 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_801 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.7319 - auc: 0.6441 - val_loss: 0.2507 - val_auc: 0.8410\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2614 - auc: 0.7784 - val_loss: 0.2294 - val_auc: 0.8490\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2536 - auc: 0.7867 - val_loss: 0.2279 - val_auc: 0.8520\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2515 - auc: 0.7942 - val_loss: 0.2274 - val_auc: 0.8476\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2511 - auc: 0.7928 - val_loss: 0.2273 - val_auc: 0.8458\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.7919 - val_loss: 0.2278 - val_auc: 0.8443\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7967 - val_loss: 0.2284 - val_auc: 0.8443\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7945 - val_loss: 0.2267 - val_auc: 0.8424\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8005 - val_loss: 0.2270 - val_auc: 0.8451\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.7969 - val_loss: 0.2266 - val_auc: 0.8447\n",
      "Model: \"sequential_267\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_801 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_802 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_803 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_804 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 0.7840 - auc: 0.6227 - val_loss: 0.2620 - val_auc: 0.8347\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2640 - auc: 0.7765 - val_loss: 0.2293 - val_auc: 0.8493\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2525 - auc: 0.7955 - val_loss: 0.2270 - val_auc: 0.8522\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.8056 - val_loss: 0.2265 - val_auc: 0.8506\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2474 - auc: 0.8116 - val_loss: 0.2270 - val_auc: 0.8475\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2475 - auc: 0.8080 - val_loss: 0.2267 - val_auc: 0.8453\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2463 - auc: 0.8154 - val_loss: 0.2271 - val_auc: 0.8467\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2467 - auc: 0.8068 - val_loss: 0.2254 - val_auc: 0.8463\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2470 - auc: 0.8057 - val_loss: 0.2264 - val_auc: 0.8472\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.2470 - auc: 0.8070 - val_loss: 0.2261 - val_auc: 0.8449\n",
      "Model: \"sequential_268\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_804 (Dense)            (80, 128)                 3840      \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (80, 128)                 0         \n",
      "_________________________________________________________________\n",
      "dense_805 (Dense)            (80, 139)                 17931     \n",
      "_________________________________________________________________\n",
      "dense_806 (Dense)            (80, 1)                   140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_807 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 0.8279 - auc: 0.6271 - val_loss: 0.2730 - val_auc: 0.8327\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2699 - auc: 0.7556 - val_loss: 0.2308 - val_auc: 0.8495\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7884 - val_loss: 0.2275 - val_auc: 0.8538\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2512 - auc: 0.7897 - val_loss: 0.2267 - val_auc: 0.8533\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.7881 - val_loss: 0.2262 - val_auc: 0.8481\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7952 - val_loss: 0.2264 - val_auc: 0.8506\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.7961 - val_loss: 0.2267 - val_auc: 0.8463\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7923 - val_loss: 0.2266 - val_auc: 0.8452\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2481 - auc: 0.7947 - val_loss: 0.2262 - val_auc: 0.8445\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2489 - auc: 0.7934 - val_loss: 0.2260 - val_auc: 0.8467\n",
      "Model: \"sequential_269\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_807 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_808 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_809 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_810 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.8726 - auc: 0.6467 - val_loss: 0.2908 - val_auc: 0.8297\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2755 - auc: 0.7603 - val_loss: 0.2322 - val_auc: 0.8502\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2554 - auc: 0.7763 - val_loss: 0.2279 - val_auc: 0.8510\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2501 - auc: 0.7947 - val_loss: 0.2265 - val_auc: 0.8504\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.7973 - val_loss: 0.2271 - val_auc: 0.8488\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2487 - auc: 0.7964 - val_loss: 0.2271 - val_auc: 0.8457\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.7975 - val_loss: 0.2271 - val_auc: 0.8466\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2476 - auc: 0.7999 - val_loss: 0.2279 - val_auc: 0.8466\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2477 - auc: 0.7997 - val_loss: 0.2271 - val_auc: 0.8467\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.2484 - auc: 0.7992 - val_loss: 0.2267 - val_auc: 0.8461\n",
      "Model: \"sequential_270\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_810 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_811 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_812 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_813 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.9171 - auc: 0.6500 - val_loss: 0.3028 - val_auc: 0.8352\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2840 - auc: 0.7436 - val_loss: 0.2338 - val_auc: 0.8473\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2584 - auc: 0.7577 - val_loss: 0.2274 - val_auc: 0.8523\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2525 - auc: 0.7774 - val_loss: 0.2286 - val_auc: 0.8499\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2503 - auc: 0.7889 - val_loss: 0.2264 - val_auc: 0.8490\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 0.2500 - auc: 0.7873 - val_loss: 0.2271 - val_auc: 0.8480\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7901 - val_loss: 0.2280 - val_auc: 0.8484\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.2496 - auc: 0.7906 - val_loss: 0.2277 - val_auc: 0.8425\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7854 - val_loss: 0.2268 - val_auc: 0.8450\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.2486 - auc: 0.7911 - val_loss: 0.2272 - val_auc: 0.8444\n",
      "Model: \"sequential_271\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_813 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_814 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_815 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_816 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.9539 - auc: 0.6614 - val_loss: 0.3202 - val_auc: 0.8409\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2896 - auc: 0.7586 - val_loss: 0.2349 - val_auc: 0.8503\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2588 - auc: 0.7611 - val_loss: 0.2276 - val_auc: 0.8539\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2534 - auc: 0.7706 - val_loss: 0.2266 - val_auc: 0.8523\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2511 - auc: 0.7820 - val_loss: 0.2272 - val_auc: 0.8499\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7887 - val_loss: 0.2278 - val_auc: 0.8476\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.2494 - auc: 0.7931 - val_loss: 0.2283 - val_auc: 0.8484\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2477 - auc: 0.7984 - val_loss: 0.2270 - val_auc: 0.8459\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2495 - auc: 0.7919 - val_loss: 0.2282 - val_auc: 0.8447\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.7971 - val_loss: 0.2278 - val_auc: 0.8475\n",
      "Model: \"sequential_272\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_816 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_817 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_818 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_819 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.9944 - auc: 0.6569 - val_loss: 0.3413 - val_auc: 0.8401\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2974 - auc: 0.7629 - val_loss: 0.2394 - val_auc: 0.8463\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2596 - auc: 0.7645 - val_loss: 0.2306 - val_auc: 0.8506\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7692 - val_loss: 0.2301 - val_auc: 0.8536\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2508 - auc: 0.7817 - val_loss: 0.2290 - val_auc: 0.8517\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2505 - auc: 0.7825 - val_loss: 0.2266 - val_auc: 0.8530\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.7869 - val_loss: 0.2266 - val_auc: 0.8507\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.7903 - val_loss: 0.2282 - val_auc: 0.8478\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.7943 - val_loss: 0.2284 - val_auc: 0.8479\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.7976 - val_loss: 0.2276 - val_auc: 0.8477\n",
      "Model: \"sequential_273\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_819 (Dense)            (120, 128)                3840      \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (120, 128)                0         \n",
      "_________________________________________________________________\n",
      "dense_820 (Dense)            (120, 139)                17931     \n",
      "_________________________________________________________________\n",
      "dense_821 (Dense)            (120, 1)                  140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_822 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 1.0291 - auc: 0.6535 - val_loss: 0.3552 - val_auc: 0.8349\n",
      "Epoch 2/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.3041 - auc: 0.7595 - val_loss: 0.2447 - val_auc: 0.8447\n",
      "Epoch 3/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2593 - auc: 0.7723 - val_loss: 0.2324 - val_auc: 0.8500\n",
      "Epoch 4/10\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.2527 - auc: 0.7770 - val_loss: 0.2290 - val_auc: 0.8539\n",
      "Epoch 5/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2507 - auc: 0.7837 - val_loss: 0.2287 - val_auc: 0.8539\n",
      "Epoch 6/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2505 - auc: 0.7810 - val_loss: 0.2284 - val_auc: 0.8508\n",
      "Epoch 7/10\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.2506 - auc: 0.7838 - val_loss: 0.2283 - val_auc: 0.8500\n",
      "Epoch 8/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2497 - auc: 0.7839 - val_loss: 0.2290 - val_auc: 0.8512\n",
      "Epoch 9/10\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.2488 - auc: 0.7893 - val_loss: 0.2283 - val_auc: 0.8492\n",
      "Epoch 10/10\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.2480 - auc: 0.7973 - val_loss: 0.2277 - val_auc: 0.8473\n",
      "Model: \"sequential_274\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_822 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_823 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_824 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8419527832100159 72\n",
      "[0.8164774903731781, 0.834443862018911, 0.8268220398782283, 0.8376484345073688, 0.8402330598173425, 0.8419527832100159, 0.8413197314570271, 0.8402451563476543, 0.8411987661539081, 0.8390092941674564, 0.8393479970161891, 0.836073869478438, 0.8374367452269107]\n",
      "0.2100622838725738 96\n",
      "[0.24243237150592342, 0.23459741483781915, 0.23243358015536808, 0.22682053400415939, 0.2171456494014353, 0.21500695089617805, 0.2123730820891863, 0.21211691290764403, 0.2100622838725738, 0.21016248835468482, 0.21032348228534234, 0.2146820052972834, 0.2132968133874305]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(32, 136, 8)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(0.3, seed = 0),\n",
    "            tf.keras.layers.Dense(139, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = i, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'orange')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_825 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.6880 - auc: 0.6381 - val_loss: 0.2433 - val_auc: 0.8390\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.2595 - auc: 0.7766 - val_loss: 0.2292 - val_auc: 0.8481\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2537 - auc: 0.7840 - val_loss: 0.2280 - val_auc: 0.8498\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2517 - auc: 0.7916 - val_loss: 0.2276 - val_auc: 0.8449\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.2510 - auc: 0.7911 - val_loss: 0.2281 - val_auc: 0.8435\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2514 - auc: 0.7901 - val_loss: 0.2296 - val_auc: 0.8476\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s 4ms/step - loss: 0.2508 - auc: 0.7894 - val_loss: 0.2285 - val_auc: 0.8434\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7917 - val_loss: 0.2281 - val_auc: 0.8451\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7925 - val_loss: 0.2303 - val_auc: 0.8438\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7879 - val_loss: 0.2278 - val_auc: 0.8443\n",
      "Model: \"sequential_275\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_825 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_826 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_827 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_828 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.6927 - auc: 0.6572 - val_loss: 0.2451 - val_auc: 0.8416\n",
      "Epoch 2/10\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2605 - auc: 0.7741 - val_loss: 0.2297 - val_auc: 0.8499\n",
      "Epoch 3/10\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.2529 - auc: 0.7883 - val_loss: 0.2287 - val_auc: 0.8471\n",
      "Epoch 4/10\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.2513 - auc: 0.7901 - val_loss: 0.2276 - val_auc: 0.8467\n",
      "Epoch 5/10\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7950 - val_loss: 0.2281 - val_auc: 0.8453\n",
      "Epoch 6/10\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.7930 - val_loss: 0.2279 - val_auc: 0.8474\n",
      "Epoch 7/10\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2501 - auc: 0.7937 - val_loss: 0.2271 - val_auc: 0.8444\n",
      "Epoch 8/10\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2510 - auc: 0.7884 - val_loss: 0.2301 - val_auc: 0.8430\n",
      "Epoch 9/10\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.7995 - val_loss: 0.2290 - val_auc: 0.8450\n",
      "Epoch 10/10\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2508 - auc: 0.7946 - val_loss: 0.2289 - val_auc: 0.8469\n",
      "Model: \"sequential_276\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_828 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_829 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_830 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_831 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.6992 - auc: 0.6448 - val_loss: 0.2446 - val_auc: 0.8395\n",
      "Epoch 2/10\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.2598 - auc: 0.7782 - val_loss: 0.2302 - val_auc: 0.8496\n",
      "Epoch 3/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2532 - auc: 0.7936 - val_loss: 0.2297 - val_auc: 0.8480\n",
      "Epoch 4/10\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.2514 - auc: 0.7925 - val_loss: 0.2279 - val_auc: 0.8467\n",
      "Epoch 5/10\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8051 - val_loss: 0.2276 - val_auc: 0.8453\n",
      "Epoch 6/10\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.2491 - auc: 0.7974 - val_loss: 0.2289 - val_auc: 0.8427\n",
      "Epoch 7/10\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.2479 - auc: 0.8066 - val_loss: 0.2286 - val_auc: 0.8413\n",
      "Epoch 8/10\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.2491 - auc: 0.8030 - val_loss: 0.2291 - val_auc: 0.8450\n",
      "Epoch 9/10\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.2497 - auc: 0.7978 - val_loss: 0.2304 - val_auc: 0.8488\n",
      "Epoch 10/10\n",
      "72/72 [==============================] - 0s 5ms/step - loss: 0.2484 - auc: 0.8046 - val_loss: 0.2295 - val_auc: 0.8448\n",
      "Model: \"sequential_277\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_831 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_832 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_833 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_834 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "71/71 [==============================] - 1s 8ms/step - loss: 0.7096 - auc: 0.6411 - val_loss: 0.2463 - val_auc: 0.8404\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 0s 4ms/step - loss: 0.2592 - auc: 0.7829 - val_loss: 0.2298 - val_auc: 0.8508\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7949 - val_loss: 0.2284 - val_auc: 0.8489\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7961 - val_loss: 0.2281 - val_auc: 0.8476\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2501 - auc: 0.7958 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2493 - auc: 0.7981 - val_loss: 0.2285 - val_auc: 0.8444\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2489 - auc: 0.7998 - val_loss: 0.2285 - val_auc: 0.8454\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.7962 - val_loss: 0.2298 - val_auc: 0.8451\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7969 - val_loss: 0.2277 - val_auc: 0.8436\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7983 - val_loss: 0.2281 - val_auc: 0.8444\n",
      "Model: \"sequential_278\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_834 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_835 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_836 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_837 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "70/70 [==============================] - 1s 8ms/step - loss: 0.7207 - auc: 0.6220 - val_loss: 0.2474 - val_auc: 0.8370\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2603 - auc: 0.7773 - val_loss: 0.2301 - val_auc: 0.8497\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2528 - auc: 0.7970 - val_loss: 0.2289 - val_auc: 0.8487\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7967 - val_loss: 0.2281 - val_auc: 0.8453\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7951 - val_loss: 0.2280 - val_auc: 0.8482\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.8002 - val_loss: 0.2288 - val_auc: 0.8451\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.7962 - val_loss: 0.2273 - val_auc: 0.8444\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8014 - val_loss: 0.2278 - val_auc: 0.8426\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2489 - auc: 0.7996 - val_loss: 0.2283 - val_auc: 0.8420\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7977 - val_loss: 0.2303 - val_auc: 0.8451\n",
      "Model: \"sequential_279\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_837 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_838 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_839 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_840 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.7242 - auc: 0.6346 - val_loss: 0.2487 - val_auc: 0.8368\n",
      "Epoch 2/10\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.2612 - auc: 0.7712 - val_loss: 0.2299 - val_auc: 0.8492\n",
      "Epoch 3/10\n",
      "69/69 [==============================] - 0s 3ms/step - loss: 0.2522 - auc: 0.7938 - val_loss: 0.2285 - val_auc: 0.8473\n",
      "Epoch 4/10\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2518 - auc: 0.7908 - val_loss: 0.2284 - val_auc: 0.8461\n",
      "Epoch 5/10\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2508 - auc: 0.7913 - val_loss: 0.2278 - val_auc: 0.8443\n",
      "Epoch 6/10\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7996 - val_loss: 0.2291 - val_auc: 0.8453\n",
      "Epoch 7/10\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2500 - auc: 0.7980 - val_loss: 0.2284 - val_auc: 0.8434\n",
      "Epoch 8/10\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7983 - val_loss: 0.2294 - val_auc: 0.8429\n",
      "Epoch 9/10\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2492 - auc: 0.8021 - val_loss: 0.2294 - val_auc: 0.8445\n",
      "Epoch 10/10\n",
      "69/69 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7972 - val_loss: 0.2288 - val_auc: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_280\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_840 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_841 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_842 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_843 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 0.7289 - auc: 0.6296 - val_loss: 0.2501 - val_auc: 0.8368\n",
      "Epoch 2/10\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 0.2614 - auc: 0.7703 - val_loss: 0.2287 - val_auc: 0.8491\n",
      "Epoch 3/10\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.2534 - auc: 0.7825 - val_loss: 0.2275 - val_auc: 0.8461\n",
      "Epoch 4/10\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.2505 - auc: 0.7940 - val_loss: 0.2266 - val_auc: 0.8458\n",
      "Epoch 5/10\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7951 - val_loss: 0.2277 - val_auc: 0.8463\n",
      "Epoch 6/10\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7962 - val_loss: 0.2266 - val_auc: 0.8451\n",
      "Epoch 7/10\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.8013 - val_loss: 0.2264 - val_auc: 0.8444\n",
      "Epoch 8/10\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7924 - val_loss: 0.2269 - val_auc: 0.8455\n",
      "Epoch 9/10\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7986 - val_loss: 0.2300 - val_auc: 0.8463\n",
      "Epoch 10/10\n",
      "68/68 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7974 - val_loss: 0.2268 - val_auc: 0.8460\n",
      "Model: \"sequential_281\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_843 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_844 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_845 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_846 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "67/67 [==============================] - 1s 11ms/step - loss: 0.7319 - auc: 0.6441 - val_loss: 0.2507 - val_auc: 0.8410\n",
      "Epoch 2/10\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2614 - auc: 0.7784 - val_loss: 0.2294 - val_auc: 0.8490\n",
      "Epoch 3/10\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2536 - auc: 0.7867 - val_loss: 0.2279 - val_auc: 0.8520\n",
      "Epoch 4/10\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2515 - auc: 0.7942 - val_loss: 0.2274 - val_auc: 0.8476\n",
      "Epoch 5/10\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2511 - auc: 0.7928 - val_loss: 0.2273 - val_auc: 0.8458\n",
      "Epoch 6/10\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.7919 - val_loss: 0.2278 - val_auc: 0.8443\n",
      "Epoch 7/10\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7967 - val_loss: 0.2284 - val_auc: 0.8443\n",
      "Epoch 8/10\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7945 - val_loss: 0.2267 - val_auc: 0.8424\n",
      "Epoch 9/10\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.8005 - val_loss: 0.2270 - val_auc: 0.8451\n",
      "Epoch 10/10\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.2486 - auc: 0.7969 - val_loss: 0.2266 - val_auc: 0.8447\n",
      "Model: \"sequential_282\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_846 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_847 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_848 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_849 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Model: \"sequential_283\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_849 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_850 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_851 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_852 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.7414 - auc: 0.6340 - val_loss: 0.2529 - val_auc: 0.8384\n",
      "Epoch 2/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.2622 - auc: 0.7707 - val_loss: 0.2307 - val_auc: 0.8482\n",
      "Epoch 3/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.2519 - auc: 0.7925 - val_loss: 0.2305 - val_auc: 0.8477\n",
      "Epoch 4/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7985 - val_loss: 0.2291 - val_auc: 0.8467\n",
      "Epoch 5/10\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.2496 - auc: 0.7975 - val_loss: 0.2307 - val_auc: 0.8442\n",
      "Epoch 6/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7958 - val_loss: 0.2281 - val_auc: 0.8437\n",
      "Epoch 7/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8027 - val_loss: 0.2297 - val_auc: 0.8419\n",
      "Epoch 8/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.8035 - val_loss: 0.2307 - val_auc: 0.8434\n",
      "Epoch 9/10\n",
      "65/65 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8046 - val_loss: 0.2274 - val_auc: 0.8429\n",
      "Epoch 10/10\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.7966 - val_loss: 0.2295 - val_auc: 0.8431\n",
      "Model: \"sequential_284\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_852 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_853 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_854 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_855 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.7504 - auc: 0.6291 - val_loss: 0.2556 - val_auc: 0.8375\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2617 - auc: 0.7805 - val_loss: 0.2300 - val_auc: 0.8506\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2523 - auc: 0.7999 - val_loss: 0.2281 - val_auc: 0.8516\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.7980 - val_loss: 0.2283 - val_auc: 0.8463\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7995 - val_loss: 0.2279 - val_auc: 0.8451\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2491 - auc: 0.7998 - val_loss: 0.2280 - val_auc: 0.8460\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2478 - auc: 0.8067 - val_loss: 0.2275 - val_auc: 0.8462\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7996 - val_loss: 0.2278 - val_auc: 0.8435\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.8013 - val_loss: 0.2284 - val_auc: 0.8429\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2482 - auc: 0.8059 - val_loss: 0.2284 - val_auc: 0.8412\n",
      "Model: \"sequential_285\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_855 (Dense)            (75, 128)                 3840      \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (75, 128)                 0         \n",
      "_________________________________________________________________\n",
      "dense_856 (Dense)            (75, 139)                 17931     \n",
      "_________________________________________________________________\n",
      "dense_857 (Dense)            (75, 1)                   140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_858 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 0.7598 - auc: 0.6130 - val_loss: 0.2554 - val_auc: 0.8384\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2637 - auc: 0.7681 - val_loss: 0.2295 - val_auc: 0.8505\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 5ms/step - loss: 0.2539 - auc: 0.7820 - val_loss: 0.2272 - val_auc: 0.8509\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2522 - auc: 0.7913 - val_loss: 0.2292 - val_auc: 0.8477\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7900 - val_loss: 0.2266 - val_auc: 0.8445\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7923 - val_loss: 0.2268 - val_auc: 0.8461\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.7955 - val_loss: 0.2267 - val_auc: 0.8447\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8005 - val_loss: 0.2282 - val_auc: 0.8414\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7895 - val_loss: 0.2258 - val_auc: 0.8428\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8030 - val_loss: 0.2285 - val_auc: 0.8443\n",
      "Model: \"sequential_286\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_858 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_859 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_860 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_861 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7732 - auc: 0.6110 - val_loss: 0.2586 - val_auc: 0.8371\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2643 - auc: 0.7676 - val_loss: 0.2292 - val_auc: 0.8490\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2519 - auc: 0.7969 - val_loss: 0.2280 - val_auc: 0.8481\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2492 - auc: 0.8062 - val_loss: 0.2261 - val_auc: 0.8484\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8075 - val_loss: 0.2268 - val_auc: 0.8475\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.8021 - val_loss: 0.2262 - val_auc: 0.8480\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2478 - auc: 0.8044 - val_loss: 0.2259 - val_auc: 0.8486\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2473 - auc: 0.8023 - val_loss: 0.2265 - val_auc: 0.8457\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2469 - auc: 0.8102 - val_loss: 0.2262 - val_auc: 0.8476\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.8017 - val_loss: 0.2258 - val_auc: 0.8464\n",
      "Model: \"sequential_287\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_861 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_862 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_863 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_864 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.7708 - auc: 0.6310 - val_loss: 0.2587 - val_auc: 0.8371\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.2624 - auc: 0.7806 - val_loss: 0.2296 - val_auc: 0.8489\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.2529 - auc: 0.7928 - val_loss: 0.2286 - val_auc: 0.8481\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7916 - val_loss: 0.2271 - val_auc: 0.8478\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2493 - auc: 0.7969 - val_loss: 0.2274 - val_auc: 0.8465\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.7942 - val_loss: 0.2292 - val_auc: 0.8441\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7919 - val_loss: 0.2283 - val_auc: 0.8438\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.8014 - val_loss: 0.2268 - val_auc: 0.8458\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.7950 - val_loss: 0.2284 - val_auc: 0.8435\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.2476 - auc: 0.7977 - val_loss: 0.2261 - val_auc: 0.8429\n",
      "Model: \"sequential_288\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_864 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_865 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_866 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense_867 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 1s 8ms/step - loss: 0.7768 - auc: 0.6311 - val_loss: 0.2606 - val_auc: 0.8383\n",
      "Epoch 2/10\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2632 - auc: 0.7775 - val_loss: 0.2296 - val_auc: 0.8515\n",
      "Epoch 3/10\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2521 - auc: 0.7941 - val_loss: 0.2283 - val_auc: 0.8504\n",
      "Epoch 4/10\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2493 - auc: 0.8040 - val_loss: 0.2271 - val_auc: 0.8476\n",
      "Epoch 5/10\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7965 - val_loss: 0.2274 - val_auc: 0.8458\n",
      "Epoch 6/10\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2495 - auc: 0.7998 - val_loss: 0.2286 - val_auc: 0.8460\n",
      "Epoch 7/10\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8041 - val_loss: 0.2282 - val_auc: 0.8465\n",
      "Epoch 8/10\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.8002 - val_loss: 0.2273 - val_auc: 0.8467\n",
      "Epoch 9/10\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.8040 - val_loss: 0.2277 - val_auc: 0.8428\n",
      "Epoch 10/10\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2488 - auc: 0.7942 - val_loss: 0.2277 - val_auc: 0.8481\n",
      "Model: \"sequential_289\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_867 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_868 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_869 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8432713050140118 73\n",
      "[0.840128223221306, 0.8401524162819298, 0.8418136731114292, 0.8418479466139795, 0.8417370617527873, 0.8413237636337977, 0.841408439345981, 0.8419527832100159, 0.8432713050140118, 0.8418479466139795, 0.8428217173040866, 0.8407330497369004, 0.8411655006955506, 0.8412693292473942, 0.8412330396564587]\n",
      "0.21197534474357826 77\n",
      "[0.21638171361449876, 0.21780224590704864, 0.21826482781957682, 0.21516954897351123, 0.21957516353786358, 0.21661233283556428, 0.21486334774577118, 0.21500695089617805, 0.21284597255343485, 0.21327572939577005, 0.21271600490830328, 0.21387148936020586, 0.21197534474357826, 0.21302918130899312, 0.2124712743796071]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(65, 80)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(0.3, seed = 0),\n",
    "            tf.keras.layers.Dense(139, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = i, epochs = 10, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'orange')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_870 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Model: \"sequential_290\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_870 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_871 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_872 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/11\n",
      "WARNING:tensorflow:Layer dense_873 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/11\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/11\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/11\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/11\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/11\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/11\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/11\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/11\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/11\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/11\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Model: \"sequential_291\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_873 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_874 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_875 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/21\n",
      "WARNING:tensorflow:Layer dense_876 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/21\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/21\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_292\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_876 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_877 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_878 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/31\n",
      "WARNING:tensorflow:Layer dense_879 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/31\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/31\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/31\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/31\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/31\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Epoch 28/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.8016 - val_loss: 0.2303 - val_auc: 0.8488\n",
      "Epoch 29/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.8016 - val_loss: 0.2294 - val_auc: 0.8501\n",
      "Epoch 30/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8033 - val_loss: 0.2283 - val_auc: 0.8481\n",
      "Epoch 31/31\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7997 - val_loss: 0.2287 - val_auc: 0.8475\n",
      "Model: \"sequential_293\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_879 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_880 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_881 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/41\n",
      "WARNING:tensorflow:Layer dense_882 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/41\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/41\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/41\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/41\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Epoch 28/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.8016 - val_loss: 0.2303 - val_auc: 0.8488\n",
      "Epoch 29/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.8016 - val_loss: 0.2294 - val_auc: 0.8501\n",
      "Epoch 30/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8033 - val_loss: 0.2283 - val_auc: 0.8481\n",
      "Epoch 31/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7997 - val_loss: 0.2287 - val_auc: 0.8475\n",
      "Epoch 32/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7972 - val_loss: 0.2272 - val_auc: 0.8471\n",
      "Epoch 33/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7911 - val_loss: 0.2291 - val_auc: 0.8452\n",
      "Epoch 34/41\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2500 - auc: 0.7951 - val_loss: 0.2292 - val_auc: 0.8487\n",
      "Epoch 35/41\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2512 - auc: 0.7932 - val_loss: 0.2298 - val_auc: 0.8472\n",
      "Epoch 36/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7998 - val_loss: 0.2293 - val_auc: 0.8516\n",
      "Epoch 37/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7964 - val_loss: 0.2292 - val_auc: 0.8474\n",
      "Epoch 38/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.8012 - val_loss: 0.2297 - val_auc: 0.8494\n",
      "Epoch 39/41\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2501 - auc: 0.7962 - val_loss: 0.2307 - val_auc: 0.8516\n",
      "Epoch 40/41\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2507 - auc: 0.7942 - val_loss: 0.2302 - val_auc: 0.8461\n",
      "Epoch 41/41\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2505 - auc: 0.7962 - val_loss: 0.2288 - val_auc: 0.8490\n",
      "Model: \"sequential_294\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_882 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_883 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_884 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/51\n",
      "WARNING:tensorflow:Layer dense_885 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/51\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/51\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/51\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/51\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/51\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/51\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/51\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Epoch 28/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.8016 - val_loss: 0.2303 - val_auc: 0.8488\n",
      "Epoch 29/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.8016 - val_loss: 0.2294 - val_auc: 0.8501\n",
      "Epoch 30/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8033 - val_loss: 0.2283 - val_auc: 0.8481\n",
      "Epoch 31/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7997 - val_loss: 0.2287 - val_auc: 0.8475\n",
      "Epoch 32/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7972 - val_loss: 0.2272 - val_auc: 0.8471\n",
      "Epoch 33/51\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2504 - auc: 0.7911 - val_loss: 0.2291 - val_auc: 0.8452\n",
      "Epoch 34/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7951 - val_loss: 0.2292 - val_auc: 0.8487\n",
      "Epoch 35/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.7932 - val_loss: 0.2298 - val_auc: 0.8472\n",
      "Epoch 36/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7998 - val_loss: 0.2293 - val_auc: 0.8516\n",
      "Epoch 37/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7964 - val_loss: 0.2292 - val_auc: 0.8474\n",
      "Epoch 38/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.8012 - val_loss: 0.2297 - val_auc: 0.8494\n",
      "Epoch 39/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2501 - auc: 0.7962 - val_loss: 0.2307 - val_auc: 0.8516\n",
      "Epoch 40/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.7942 - val_loss: 0.2302 - val_auc: 0.8461\n",
      "Epoch 41/51\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2505 - auc: 0.7962 - val_loss: 0.2288 - val_auc: 0.8490\n",
      "Epoch 42/51\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2523 - auc: 0.7919 - val_loss: 0.2348 - val_auc: 0.8514\n",
      "Epoch 43/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2527 - auc: 0.7883 - val_loss: 0.2308 - val_auc: 0.8475\n",
      "Epoch 44/51\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2520 - auc: 0.7898 - val_loss: 0.2294 - val_auc: 0.8487\n",
      "Epoch 45/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.7940 - val_loss: 0.2308 - val_auc: 0.8502\n",
      "Epoch 46/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.8014 - val_loss: 0.2271 - val_auc: 0.8501\n",
      "Epoch 47/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.8014 - val_loss: 0.2281 - val_auc: 0.8475\n",
      "Epoch 48/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2519 - auc: 0.7857 - val_loss: 0.2285 - val_auc: 0.8508\n",
      "Epoch 49/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2508 - auc: 0.7960 - val_loss: 0.2344 - val_auc: 0.8459\n",
      "Epoch 50/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2545 - auc: 0.7807 - val_loss: 0.2306 - val_auc: 0.8509\n",
      "Epoch 51/51\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7993 - val_loss: 0.2277 - val_auc: 0.8509\n",
      "Model: \"sequential_295\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_885 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_886 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_887 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/61\n",
      "WARNING:tensorflow:Layer dense_888 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Epoch 28/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2507 - auc: 0.8016 - val_loss: 0.2303 - val_auc: 0.8488\n",
      "Epoch 29/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2495 - auc: 0.8016 - val_loss: 0.2294 - val_auc: 0.8501\n",
      "Epoch 30/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8033 - val_loss: 0.2283 - val_auc: 0.8481\n",
      "Epoch 31/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7997 - val_loss: 0.2287 - val_auc: 0.8475\n",
      "Epoch 32/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7972 - val_loss: 0.2272 - val_auc: 0.8471\n",
      "Epoch 33/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2504 - auc: 0.7911 - val_loss: 0.2291 - val_auc: 0.8452\n",
      "Epoch 34/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2500 - auc: 0.7951 - val_loss: 0.2292 - val_auc: 0.8487\n",
      "Epoch 35/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2512 - auc: 0.7932 - val_loss: 0.2298 - val_auc: 0.8472\n",
      "Epoch 36/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2496 - auc: 0.7998 - val_loss: 0.2293 - val_auc: 0.8516\n",
      "Epoch 37/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7964 - val_loss: 0.2292 - val_auc: 0.8474\n",
      "Epoch 38/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.8012 - val_loss: 0.2297 - val_auc: 0.8494\n",
      "Epoch 39/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2501 - auc: 0.7962 - val_loss: 0.2307 - val_auc: 0.8516\n",
      "Epoch 40/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.7942 - val_loss: 0.2302 - val_auc: 0.8461\n",
      "Epoch 41/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2505 - auc: 0.7962 - val_loss: 0.2288 - val_auc: 0.8490\n",
      "Epoch 42/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2523 - auc: 0.7919 - val_loss: 0.2348 - val_auc: 0.8514\n",
      "Epoch 43/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2527 - auc: 0.7883 - val_loss: 0.2308 - val_auc: 0.8475\n",
      "Epoch 44/61\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2520 - auc: 0.7898 - val_loss: 0.2294 - val_auc: 0.8487\n",
      "Epoch 45/61\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.2503 - auc: 0.7940 - val_loss: 0.2308 - val_auc: 0.8502\n",
      "Epoch 46/61\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.2491 - auc: 0.8014 - val_loss: 0.2271 - val_auc: 0.8501\n",
      "Epoch 47/61\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2494 - auc: 0.8014 - val_loss: 0.2281 - val_auc: 0.8475\n",
      "Epoch 48/61\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.2519 - auc: 0.7857 - val_loss: 0.2285 - val_auc: 0.8508\n",
      "Epoch 49/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2508 - auc: 0.7960 - val_loss: 0.2344 - val_auc: 0.8459\n",
      "Epoch 50/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2545 - auc: 0.7807 - val_loss: 0.2306 - val_auc: 0.8509\n",
      "Epoch 51/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7993 - val_loss: 0.2277 - val_auc: 0.8509\n",
      "Epoch 52/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.8038 - val_loss: 0.2298 - val_auc: 0.8462\n",
      "Epoch 53/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2493 - auc: 0.7991 - val_loss: 0.2278 - val_auc: 0.8435\n",
      "Epoch 54/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7995 - val_loss: 0.2316 - val_auc: 0.8451\n",
      "Epoch 55/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2512 - auc: 0.7937 - val_loss: 0.2282 - val_auc: 0.8464\n",
      "Epoch 56/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2479 - auc: 0.8080 - val_loss: 0.2281 - val_auc: 0.8462\n",
      "Epoch 57/61\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.8008 - val_loss: 0.2310 - val_auc: 0.8479\n",
      "Epoch 58/61\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2509 - auc: 0.7995 - val_loss: 0.2302 - val_auc: 0.8486\n",
      "Epoch 59/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2493 - auc: 0.8004 - val_loss: 0.2284 - val_auc: 0.8470\n",
      "Epoch 60/61\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.8060 - val_loss: 0.2292 - val_auc: 0.8475\n",
      "Epoch 61/61\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2489 - auc: 0.8003 - val_loss: 0.2269 - val_auc: 0.8489\n",
      "Model: \"sequential_296\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_888 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_889 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_890 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/71\n",
      "WARNING:tensorflow:Layer dense_891 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/71\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Epoch 28/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2507 - auc: 0.8016 - val_loss: 0.2303 - val_auc: 0.8488\n",
      "Epoch 29/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2495 - auc: 0.8016 - val_loss: 0.2294 - val_auc: 0.8501\n",
      "Epoch 30/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8033 - val_loss: 0.2283 - val_auc: 0.8481\n",
      "Epoch 31/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7997 - val_loss: 0.2287 - val_auc: 0.8475\n",
      "Epoch 32/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7972 - val_loss: 0.2272 - val_auc: 0.8471\n",
      "Epoch 33/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2504 - auc: 0.7911 - val_loss: 0.2291 - val_auc: 0.8452\n",
      "Epoch 34/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2500 - auc: 0.7951 - val_loss: 0.2292 - val_auc: 0.8487\n",
      "Epoch 35/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2512 - auc: 0.7932 - val_loss: 0.2298 - val_auc: 0.8472\n",
      "Epoch 36/71\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2496 - auc: 0.7998 - val_loss: 0.2293 - val_auc: 0.8516\n",
      "Epoch 37/71\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2509 - auc: 0.7964 - val_loss: 0.2292 - val_auc: 0.8474\n",
      "Epoch 38/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2504 - auc: 0.8012 - val_loss: 0.2297 - val_auc: 0.8494\n",
      "Epoch 39/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2501 - auc: 0.7962 - val_loss: 0.2307 - val_auc: 0.8516\n",
      "Epoch 40/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2507 - auc: 0.7942 - val_loss: 0.2302 - val_auc: 0.8461\n",
      "Epoch 41/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2505 - auc: 0.7962 - val_loss: 0.2288 - val_auc: 0.8490\n",
      "Epoch 42/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2523 - auc: 0.7919 - val_loss: 0.2348 - val_auc: 0.8514\n",
      "Epoch 43/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2527 - auc: 0.7883 - val_loss: 0.2308 - val_auc: 0.8475\n",
      "Epoch 44/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2520 - auc: 0.7898 - val_loss: 0.2294 - val_auc: 0.8487\n",
      "Epoch 45/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2503 - auc: 0.7940 - val_loss: 0.2308 - val_auc: 0.8502\n",
      "Epoch 46/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2491 - auc: 0.8014 - val_loss: 0.2271 - val_auc: 0.8501\n",
      "Epoch 47/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.8014 - val_loss: 0.2281 - val_auc: 0.8475\n",
      "Epoch 48/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2519 - auc: 0.7857 - val_loss: 0.2285 - val_auc: 0.8508\n",
      "Epoch 49/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2508 - auc: 0.7960 - val_loss: 0.2344 - val_auc: 0.8459\n",
      "Epoch 50/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2545 - auc: 0.7807 - val_loss: 0.2306 - val_auc: 0.8509\n",
      "Epoch 51/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2500 - auc: 0.7993 - val_loss: 0.2277 - val_auc: 0.8509\n",
      "Epoch 52/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.8038 - val_loss: 0.2298 - val_auc: 0.8462\n",
      "Epoch 53/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2493 - auc: 0.7991 - val_loss: 0.2278 - val_auc: 0.8435\n",
      "Epoch 54/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7995 - val_loss: 0.2316 - val_auc: 0.8451\n",
      "Epoch 55/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2512 - auc: 0.7937 - val_loss: 0.2282 - val_auc: 0.8464\n",
      "Epoch 56/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2479 - auc: 0.8080 - val_loss: 0.2281 - val_auc: 0.8462\n",
      "Epoch 57/71\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2500 - auc: 0.8008 - val_loss: 0.2310 - val_auc: 0.8479\n",
      "Epoch 58/71\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2509 - auc: 0.7995 - val_loss: 0.2302 - val_auc: 0.8486\n",
      "Epoch 59/71\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2493 - auc: 0.8004 - val_loss: 0.2284 - val_auc: 0.8470\n",
      "Epoch 60/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2492 - auc: 0.8060 - val_loss: 0.2292 - val_auc: 0.8475\n",
      "Epoch 61/71\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2489 - auc: 0.8003 - val_loss: 0.2269 - val_auc: 0.8489\n",
      "Epoch 62/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.8023 - val_loss: 0.2320 - val_auc: 0.8494\n",
      "Epoch 63/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2521 - auc: 0.7918 - val_loss: 0.2289 - val_auc: 0.8495\n",
      "Epoch 64/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2496 - auc: 0.7981 - val_loss: 0.2299 - val_auc: 0.8498\n",
      "Epoch 65/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2495 - auc: 0.7990 - val_loss: 0.2294 - val_auc: 0.8508\n",
      "Epoch 66/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7990 - val_loss: 0.2286 - val_auc: 0.8469\n",
      "Epoch 67/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2498 - auc: 0.7982 - val_loss: 0.2282 - val_auc: 0.8433\n",
      "Epoch 68/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.8050 - val_loss: 0.2299 - val_auc: 0.8470\n",
      "Epoch 69/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7998 - val_loss: 0.2262 - val_auc: 0.8465\n",
      "Epoch 70/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2489 - auc: 0.7995 - val_loss: 0.2274 - val_auc: 0.8468\n",
      "Epoch 71/71\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2507 - auc: 0.7945 - val_loss: 0.2282 - val_auc: 0.8498\n",
      "Model: \"sequential_297\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_891 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_892 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_893 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/81\n",
      "WARNING:tensorflow:Layer dense_894 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/81\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/81\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/81\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/81\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Epoch 28/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2507 - auc: 0.8016 - val_loss: 0.2303 - val_auc: 0.8488\n",
      "Epoch 29/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.8016 - val_loss: 0.2294 - val_auc: 0.8501\n",
      "Epoch 30/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8033 - val_loss: 0.2283 - val_auc: 0.8481\n",
      "Epoch 31/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7997 - val_loss: 0.2287 - val_auc: 0.8475\n",
      "Epoch 32/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2494 - auc: 0.7972 - val_loss: 0.2272 - val_auc: 0.8471\n",
      "Epoch 33/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7911 - val_loss: 0.2291 - val_auc: 0.8452\n",
      "Epoch 34/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7951 - val_loss: 0.2292 - val_auc: 0.8487\n",
      "Epoch 35/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.7932 - val_loss: 0.2298 - val_auc: 0.8472\n",
      "Epoch 36/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2496 - auc: 0.7998 - val_loss: 0.2293 - val_auc: 0.8516\n",
      "Epoch 37/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2509 - auc: 0.7964 - val_loss: 0.2292 - val_auc: 0.8474\n",
      "Epoch 38/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2504 - auc: 0.8012 - val_loss: 0.2297 - val_auc: 0.8494\n",
      "Epoch 39/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2501 - auc: 0.7962 - val_loss: 0.2307 - val_auc: 0.8516\n",
      "Epoch 40/81\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2507 - auc: 0.7942 - val_loss: 0.2302 - val_auc: 0.8461\n",
      "Epoch 41/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2505 - auc: 0.7962 - val_loss: 0.2288 - val_auc: 0.8490\n",
      "Epoch 42/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2523 - auc: 0.7919 - val_loss: 0.2348 - val_auc: 0.8514\n",
      "Epoch 43/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2527 - auc: 0.7883 - val_loss: 0.2308 - val_auc: 0.8475\n",
      "Epoch 44/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2520 - auc: 0.7898 - val_loss: 0.2294 - val_auc: 0.8487\n",
      "Epoch 45/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2503 - auc: 0.7940 - val_loss: 0.2308 - val_auc: 0.8502\n",
      "Epoch 46/81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2491 - auc: 0.8014 - val_loss: 0.2271 - val_auc: 0.8501\n",
      "Epoch 47/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.8014 - val_loss: 0.2281 - val_auc: 0.8475\n",
      "Epoch 48/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2519 - auc: 0.7857 - val_loss: 0.2285 - val_auc: 0.8508\n",
      "Epoch 49/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2508 - auc: 0.7960 - val_loss: 0.2344 - val_auc: 0.8459\n",
      "Epoch 50/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2545 - auc: 0.7807 - val_loss: 0.2306 - val_auc: 0.8509\n",
      "Epoch 51/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2500 - auc: 0.7993 - val_loss: 0.2277 - val_auc: 0.8509\n",
      "Epoch 52/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.8038 - val_loss: 0.2298 - val_auc: 0.8462\n",
      "Epoch 53/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2493 - auc: 0.7991 - val_loss: 0.2278 - val_auc: 0.8435\n",
      "Epoch 54/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7995 - val_loss: 0.2316 - val_auc: 0.8451\n",
      "Epoch 55/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.7937 - val_loss: 0.2282 - val_auc: 0.8464\n",
      "Epoch 56/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2479 - auc: 0.8080 - val_loss: 0.2281 - val_auc: 0.8462\n",
      "Epoch 57/81\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2500 - auc: 0.8008 - val_loss: 0.2310 - val_auc: 0.8479\n",
      "Epoch 58/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2509 - auc: 0.7995 - val_loss: 0.2302 - val_auc: 0.8486\n",
      "Epoch 59/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2493 - auc: 0.8004 - val_loss: 0.2284 - val_auc: 0.8470\n",
      "Epoch 60/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2492 - auc: 0.8060 - val_loss: 0.2292 - val_auc: 0.8475\n",
      "Epoch 61/81\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2489 - auc: 0.8003 - val_loss: 0.2269 - val_auc: 0.8489\n",
      "Epoch 62/81\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2485 - auc: 0.8023 - val_loss: 0.2320 - val_auc: 0.8494\n",
      "Epoch 63/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2521 - auc: 0.7918 - val_loss: 0.2289 - val_auc: 0.8495\n",
      "Epoch 64/81\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2496 - auc: 0.7981 - val_loss: 0.2299 - val_auc: 0.8498\n",
      "Epoch 65/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.7990 - val_loss: 0.2294 - val_auc: 0.8508\n",
      "Epoch 66/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7990 - val_loss: 0.2286 - val_auc: 0.8469\n",
      "Epoch 67/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2498 - auc: 0.7982 - val_loss: 0.2282 - val_auc: 0.8433\n",
      "Epoch 68/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2486 - auc: 0.8050 - val_loss: 0.2299 - val_auc: 0.8470\n",
      "Epoch 69/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2489 - auc: 0.7998 - val_loss: 0.2262 - val_auc: 0.8465\n",
      "Epoch 70/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2489 - auc: 0.7995 - val_loss: 0.2274 - val_auc: 0.8468\n",
      "Epoch 71/81\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2507 - auc: 0.7945 - val_loss: 0.2282 - val_auc: 0.8498\n",
      "Epoch 72/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7979 - val_loss: 0.2298 - val_auc: 0.8523\n",
      "Epoch 73/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2526 - auc: 0.7870 - val_loss: 0.2293 - val_auc: 0.8475\n",
      "Epoch 74/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8023 - val_loss: 0.2301 - val_auc: 0.8464\n",
      "Epoch 75/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7985 - val_loss: 0.2271 - val_auc: 0.8459\n",
      "Epoch 76/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2476 - auc: 0.8050 - val_loss: 0.2282 - val_auc: 0.8463\n",
      "Epoch 77/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8075 - val_loss: 0.2288 - val_auc: 0.8470\n",
      "Epoch 78/81\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7971 - val_loss: 0.2281 - val_auc: 0.8475\n",
      "Epoch 79/81\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2490 - auc: 0.8061 - val_loss: 0.2283 - val_auc: 0.8501\n",
      "Epoch 80/81\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.2487 - auc: 0.8017 - val_loss: 0.2298 - val_auc: 0.8479\n",
      "Epoch 81/81\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2489 - auc: 0.8037 - val_loss: 0.2280 - val_auc: 0.8470\n",
      "Model: \"sequential_298\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_894 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_895 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_896 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/91\n",
      "WARNING:tensorflow:Layer dense_897 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/91\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.2515 - auc: 0.793 - 0s 6ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/91\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/91\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Epoch 28/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2507 - auc: 0.8016 - val_loss: 0.2303 - val_auc: 0.8488\n",
      "Epoch 29/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2495 - auc: 0.8016 - val_loss: 0.2294 - val_auc: 0.8501\n",
      "Epoch 30/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2483 - auc: 0.8033 - val_loss: 0.2283 - val_auc: 0.8481\n",
      "Epoch 31/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2500 - auc: 0.7997 - val_loss: 0.2287 - val_auc: 0.8475\n",
      "Epoch 32/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7972 - val_loss: 0.2272 - val_auc: 0.8471\n",
      "Epoch 33/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7911 - val_loss: 0.2291 - val_auc: 0.8452\n",
      "Epoch 34/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.7951 - val_loss: 0.2292 - val_auc: 0.8487\n",
      "Epoch 35/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.7932 - val_loss: 0.2298 - val_auc: 0.8472\n",
      "Epoch 36/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7998 - val_loss: 0.2293 - val_auc: 0.8516\n",
      "Epoch 37/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7964 - val_loss: 0.2292 - val_auc: 0.8474\n",
      "Epoch 38/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.8012 - val_loss: 0.2297 - val_auc: 0.8494\n",
      "Epoch 39/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2501 - auc: 0.7962 - val_loss: 0.2307 - val_auc: 0.8516\n",
      "Epoch 40/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.7942 - val_loss: 0.2302 - val_auc: 0.8461\n",
      "Epoch 41/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2505 - auc: 0.7962 - val_loss: 0.2288 - val_auc: 0.8490\n",
      "Epoch 42/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2523 - auc: 0.7919 - val_loss: 0.2348 - val_auc: 0.8514\n",
      "Epoch 43/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2527 - auc: 0.7883 - val_loss: 0.2308 - val_auc: 0.8475\n",
      "Epoch 44/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2520 - auc: 0.7898 - val_loss: 0.2294 - val_auc: 0.8487\n",
      "Epoch 45/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.7940 - val_loss: 0.2308 - val_auc: 0.8502\n",
      "Epoch 46/91\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2491 - auc: 0.8014 - val_loss: 0.2271 - val_auc: 0.8501\n",
      "Epoch 47/91\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2494 - auc: 0.8014 - val_loss: 0.2281 - val_auc: 0.8475\n",
      "Epoch 48/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2519 - auc: 0.7857 - val_loss: 0.2285 - val_auc: 0.8508\n",
      "Epoch 49/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2508 - auc: 0.7960 - val_loss: 0.2344 - val_auc: 0.8459\n",
      "Epoch 50/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2545 - auc: 0.7807 - val_loss: 0.2306 - val_auc: 0.8509\n",
      "Epoch 51/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2500 - auc: 0.7993 - val_loss: 0.2277 - val_auc: 0.8509\n",
      "Epoch 52/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2480 - auc: 0.8038 - val_loss: 0.2298 - val_auc: 0.8462\n",
      "Epoch 53/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2493 - auc: 0.7991 - val_loss: 0.2278 - val_auc: 0.8435\n",
      "Epoch 54/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7995 - val_loss: 0.2316 - val_auc: 0.8451\n",
      "Epoch 55/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2512 - auc: 0.7937 - val_loss: 0.2282 - val_auc: 0.8464\n",
      "Epoch 56/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.8080 - val_loss: 0.2281 - val_auc: 0.8462\n",
      "Epoch 57/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2500 - auc: 0.8008 - val_loss: 0.2310 - val_auc: 0.8479\n",
      "Epoch 58/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2509 - auc: 0.7995 - val_loss: 0.2302 - val_auc: 0.8486\n",
      "Epoch 59/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2493 - auc: 0.8004 - val_loss: 0.2284 - val_auc: 0.8470\n",
      "Epoch 60/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.8060 - val_loss: 0.2292 - val_auc: 0.8475\n",
      "Epoch 61/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2489 - auc: 0.8003 - val_loss: 0.2269 - val_auc: 0.8489\n",
      "Epoch 62/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8023 - val_loss: 0.2320 - val_auc: 0.8494\n",
      "Epoch 63/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2521 - auc: 0.7918 - val_loss: 0.2289 - val_auc: 0.8495\n",
      "Epoch 64/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7981 - val_loss: 0.2299 - val_auc: 0.8498\n",
      "Epoch 65/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2495 - auc: 0.7990 - val_loss: 0.2294 - val_auc: 0.8508\n",
      "Epoch 66/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7990 - val_loss: 0.2286 - val_auc: 0.8469\n",
      "Epoch 67/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2498 - auc: 0.7982 - val_loss: 0.2282 - val_auc: 0.8433\n",
      "Epoch 68/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2486 - auc: 0.8050 - val_loss: 0.2299 - val_auc: 0.8470\n",
      "Epoch 69/91\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.2489 - auc: 0.7998 - val_loss: 0.2262 - val_auc: 0.8465\n",
      "Epoch 70/91\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2489 - auc: 0.7995 - val_loss: 0.2274 - val_auc: 0.8468\n",
      "Epoch 71/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2507 - auc: 0.7945 - val_loss: 0.2282 - val_auc: 0.8498\n",
      "Epoch 72/91\n",
      "66/66 [==============================] - 0s 6ms/step - loss: 0.2494 - auc: 0.7979 - val_loss: 0.2298 - val_auc: 0.8523\n",
      "Epoch 73/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2526 - auc: 0.7870 - val_loss: 0.2293 - val_auc: 0.8475\n",
      "Epoch 74/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2490 - auc: 0.8023 - val_loss: 0.2301 - val_auc: 0.8464\n",
      "Epoch 75/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2491 - auc: 0.7985 - val_loss: 0.2271 - val_auc: 0.8459\n",
      "Epoch 76/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2476 - auc: 0.8050 - val_loss: 0.2282 - val_auc: 0.8463\n",
      "Epoch 77/91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8075 - val_loss: 0.2288 - val_auc: 0.8470\n",
      "Epoch 78/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2500 - auc: 0.7971 - val_loss: 0.2281 - val_auc: 0.8475\n",
      "Epoch 79/91\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.2498 - auc: 0.807 - 0s 3ms/step - loss: 0.2490 - auc: 0.8061 - val_loss: 0.2283 - val_auc: 0.8501\n",
      "Epoch 80/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8017 - val_loss: 0.2298 - val_auc: 0.8479\n",
      "Epoch 81/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2489 - auc: 0.8037 - val_loss: 0.2280 - val_auc: 0.8470\n",
      "Epoch 82/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2480 - auc: 0.8012 - val_loss: 0.2285 - val_auc: 0.8465\n",
      "Epoch 83/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2477 - auc: 0.8041 - val_loss: 0.2269 - val_auc: 0.8435\n",
      "Epoch 84/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8066 - val_loss: 0.2280 - val_auc: 0.8523\n",
      "Epoch 85/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.8007 - val_loss: 0.2310 - val_auc: 0.8493\n",
      "Epoch 86/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2509 - auc: 0.7984 - val_loss: 0.2318 - val_auc: 0.8483\n",
      "Epoch 87/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2503 - auc: 0.8017 - val_loss: 0.2299 - val_auc: 0.8456\n",
      "Epoch 88/91\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.8014 - val_loss: 0.2352 - val_auc: 0.8471\n",
      "Epoch 89/91\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2507 - auc: 0.7955 - val_loss: 0.2275 - val_auc: 0.8459\n",
      "Epoch 90/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2496 - auc: 0.7980 - val_loss: 0.2280 - val_auc: 0.8478\n",
      "Epoch 91/91\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2486 - auc: 0.8052 - val_loss: 0.2296 - val_auc: 0.8476\n",
      "Model: \"sequential_299\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_897 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_898 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_899 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8417451261063285 21\n",
      "[0.7887925646660349, 0.8414346484949901, 0.8417451261063285, 0.8396181528598214, 0.840243140259269, 0.8381393520291931, 0.840675591217919, 0.8362210439305658, 0.8402491885244248, 0.8392109030059878]\n",
      "0.21339539281445496 61\n",
      "[0.220499219331409, 0.21405433012638408, 0.2148482731502696, 0.21597229929521566, 0.21633006152273884, 0.21724812694735235, 0.21339539281445496, 0.21791225524199234, 0.2137686079580349, 0.21677384791080714]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(1, 101, 10)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(0.3, seed = 0),\n",
    "            tf.keras.layers.Dense(139, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 73, epochs = i, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'orange')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Layer dense_900 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/20\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/20\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/20\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/20\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/20\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/20\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Model: \"sequential_300\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_900 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_901 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_902 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/21\n",
      "WARNING:tensorflow:Layer dense_903 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Model: \"sequential_301\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_903 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_904 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_905 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "WARNING:tensorflow:Layer dense_906 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/22\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/22\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/22\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/22\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/22\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Model: \"sequential_302\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_906 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_907 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_908 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/23\n",
      "WARNING:tensorflow:Layer dense_909 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/23\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/23\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Model: \"sequential_303\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_909 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_910 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_911 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "WARNING:tensorflow:Layer dense_912 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/24\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/24\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Model: \"sequential_304\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_912 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_913 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_914 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:Layer dense_915 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/25\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/25\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Model: \"sequential_305\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_915 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_916 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_917 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/26\n",
      "WARNING:tensorflow:Layer dense_918 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/26\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/26\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Model: \"sequential_306\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_918 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_919 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_920 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/27\n",
      "WARNING:tensorflow:Layer dense_921 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/27\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/27\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Model: \"sequential_307\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_921 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_922 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_923 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/28\n",
      "WARNING:tensorflow:Layer dense_924 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 0s 7ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Epoch 28/28\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.8016 - val_loss: 0.2303 - val_auc: 0.8488\n",
      "Model: \"sequential_308\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_924 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_925 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_926 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29\n",
      "WARNING:tensorflow:Layer dense_927 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 8ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/29\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Epoch 22/29\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2485 - auc: 0.8013 - val_loss: 0.2285 - val_auc: 0.8489\n",
      "Epoch 23/29\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2498 - auc: 0.8007 - val_loss: 0.2295 - val_auc: 0.8474\n",
      "Epoch 24/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2517 - auc: 0.7887 - val_loss: 0.2291 - val_auc: 0.8495\n",
      "Epoch 25/29\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2514 - auc: 0.7929 - val_loss: 0.2285 - val_auc: 0.8476\n",
      "Epoch 26/29\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2499 - auc: 0.7979 - val_loss: 0.2292 - val_auc: 0.8465\n",
      "Epoch 27/29\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2506 - auc: 0.7961 - val_loss: 0.2287 - val_auc: 0.8490\n",
      "Epoch 28/29\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2507 - auc: 0.8016 - val_loss: 0.2303 - val_auc: 0.8488\n",
      "Epoch 29/29\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2495 - auc: 0.8016 - val_loss: 0.2294 - val_auc: 0.8501\n",
      "Model: \"sequential_309\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_927 (Dense)            (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_928 (Dense)            (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_929 (Dense)            (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.8417451261063285 21\n",
      "[0.8413076349267151, 0.8417451261063285, 0.8389034495272273, 0.839171589282474, 0.8385697868994577, 0.8382875345255136, 0.8389750206649059, 0.8373107397028287, 0.837918590351001, 0.8399790326807928]\n",
      "0.2148482731502696 21\n",
      "[0.21612146210432365, 0.2148482731502696, 0.2172598968817166, 0.21954072154741539, 0.21603640355169773, 0.2155831517281575, 0.2168340668732107, 0.21636874733510933, 0.21732084571653212, 0.21749032988511982]\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = np.arange(20, 30)\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(0.3, seed = 0),\n",
    "            tf.keras.layers.Dense(139, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid', kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 73, epochs = i, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'orange')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "66/66 [==============================] - 1s 21ms/step - loss: 14.4340 - auc: 0.5000 - val_loss: 14.3478 - val_auc: 0.5000\n",
      "Epoch 2/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 14.2359 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 3/21\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 4/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 5/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 6/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 7/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 8/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 9/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 10/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 11/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 12/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 13/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 14/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 15/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 16/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 17/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 18/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 19/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 20/21\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Epoch 21/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 14.2358 - auc: 0.5000 - val_loss: 14.3470 - val_auc: 0.5000\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/21\n",
      "WARNING:tensorflow:Layer dense_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2240: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2240: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 1s 14ms/step - loss: 0.7379 - auc: 0.6349 - val_loss: 0.2524 - val_auc: 0.8404\n",
      "Epoch 2/21\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2613 - auc: 0.7795 - val_loss: 0.2296 - val_auc: 0.8498\n",
      "Epoch 3/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2533 - auc: 0.7873 - val_loss: 0.2280 - val_auc: 0.8506\n",
      "Epoch 4/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2504 - auc: 0.7971 - val_loss: 0.2286 - val_auc: 0.8477\n",
      "Epoch 5/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2490 - auc: 0.8017 - val_loss: 0.2270 - val_auc: 0.8472\n",
      "Epoch 6/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2488 - auc: 0.8021 - val_loss: 0.2280 - val_auc: 0.8415\n",
      "Epoch 7/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2494 - auc: 0.7964 - val_loss: 0.2270 - val_auc: 0.8454\n",
      "Epoch 8/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2483 - auc: 0.8020 - val_loss: 0.2272 - val_auc: 0.8435\n",
      "Epoch 9/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2497 - auc: 0.7981 - val_loss: 0.2288 - val_auc: 0.8418\n",
      "Epoch 10/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2502 - auc: 0.7897 - val_loss: 0.2291 - val_auc: 0.8429\n",
      "Epoch 11/21\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2496 - auc: 0.7927 - val_loss: 0.2286 - val_auc: 0.8405\n",
      "Epoch 12/21\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2492 - auc: 0.7973 - val_loss: 0.2274 - val_auc: 0.8452\n",
      "Epoch 13/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2482 - auc: 0.8014 - val_loss: 0.2269 - val_auc: 0.8444\n",
      "Epoch 14/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2479 - auc: 0.7989 - val_loss: 0.2280 - val_auc: 0.8447\n",
      "Epoch 15/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2484 - auc: 0.7960 - val_loss: 0.2288 - val_auc: 0.8479\n",
      "Epoch 16/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2494 - auc: 0.7986 - val_loss: 0.2272 - val_auc: 0.8460\n",
      "Epoch 17/21\n",
      "66/66 [==============================] - 0s 5ms/step - loss: 0.2486 - auc: 0.8004 - val_loss: 0.2283 - val_auc: 0.8437\n",
      "Epoch 18/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2487 - auc: 0.8007 - val_loss: 0.2277 - val_auc: 0.8452\n",
      "Epoch 19/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2471 - auc: 0.8054 - val_loss: 0.2287 - val_auc: 0.8452\n",
      "Epoch 20/21\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2502 - auc: 0.7997 - val_loss: 0.2284 - val_auc: 0.8460\n",
      "Epoch 21/21\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 0.2492 - auc: 0.7990 - val_loss: 0.2277 - val_auc: 0.8457\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 128)               3840      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 139)               17931     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 140       \n",
      "=================================================================\n",
      "Total params: 21,911\n",
      "Trainable params: 21,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/21\n",
      "WARNING:tensorflow:Layer dense_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (sequential_2/dense_8/Tanh:0) = ] [[-0.0511600487][-0.247552][0.516378701]...] [y (Cast_3/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_12247]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7b6958f53f2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m              \u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m              ,metrics=['AUC'])\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m73\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (sequential_2/dense_8/Tanh:0) = ] [[-0.0511600487][-0.247552][0.516378701]...] [y (Cast_3/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/else/_1/assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_12247]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "auc = []\n",
    "loss = []\n",
    "epoch = ['softmax', 'sigmoid', 'tanh', 'relu']\n",
    "for i in epoch:\n",
    "    model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dropout(0.3, seed = 0),\n",
    "            tf.keras.layers.Dense(139, activation = 'tanh',kernel_initializer=glorot_normal(seed=0), \n",
    "                                   kernel_regularizer = tf.keras.regularizers.l2()),\n",
    "            tf.keras.layers.Dense(1, activation = i, kernel_initializer=glorot_normal(seed=0),\n",
    "                                  kernel_regularizer = tf.keras.regularizers.l2())\n",
    "            ])\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(lr=0.00773, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "             ,loss = tf.keras.losses.binary_crossentropy\n",
    "             ,metrics=['AUC'])\n",
    "    model.fit(Xtrain, Ytrain, batch_size = 73, epochs = 21, validation_split = 0.2, shuffle = False)\n",
    "    model.summary()\n",
    "    y_predict = model.predict(Xtest)\n",
    "    auc.append(roc_auc_score(Ytest, y_predict))\n",
    "    loss.append(log_loss(Ytest, y_predict))\n",
    "print(max(auc), epoch[auc.index(max(auc))])\n",
    "print(auc)\n",
    "print(min(loss), epoch[loss.index(min(loss))])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(2, figsize = (20, 8))\n",
    "ax[0].plot(epoch, auc, color = 'red')\n",
    "ax[0].set_title('auc')\n",
    "ax[0].set_xticks(epoch)\n",
    "ax[1].plot(epoch, loss, color = 'orange')\n",
    "ax[1].set_title('loss')\n",
    "ax[1].set_xticks(epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
