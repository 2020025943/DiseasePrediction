{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_selection import mutual_info_classif as MIF\n",
    "import random\n",
    "import os\n",
    "# chain()可以把一组迭代对象串联起来，形成一个更大的迭代器\n",
    "from itertools import chain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import optimizers, layers, losses, metrics\n",
    "from tensorflow.keras.initializers import glorot_normal, he_normal\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Embedding, Lambda, multiply, Flatten, Concatenate\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from deepctr.inputs import get_dense_input, create_embedding_matrix, embedding_lookup, get_dense_input, varlen_embedding_lookup, \\\n",
    "    get_varlen_pooling_list, mergeDict\n",
    "from deepctr.layers.sequence import SequencePoolingLayer, Transformer, AttentionSequencePoolingLayer\n",
    "\n",
    "from deepctr.feature_column import  SparseFeat, DenseFeat, VarLenSparseFeat, get_feature_names, build_input_features, get_linear_logit, DEFAULT_GROUP_NAME, input_from_feature_columns\n",
    "from deepctr.layers.core import PredictionLayer, DNN\n",
    "from deepctr.layers.interaction import FM, FEFMLayer, BiInteractionPooling, AFMLayer, CIN, InteractingLayer, FwFMLayer, InnerProductLayer, OutterProductLayer, FGCNNLayer, CrossNet,  CrossNetMix\n",
    "from deepctr.layers.utils import concat_func, add_func, Hash, NoMask, combined_dnn_input, reduce_sum, softmax\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.initializers import Zeros, glorot_normal, RandomNormal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DCNNFMA(linear_feature_columns, dnn_feature_columns, fm_group=[DEFAULT_GROUP_NAME], cross_num=2, cross_parameterization='vector',\n",
    "        dnn_hidden_units=(256, 128, 64), l2_reg_linear=1e-5, l2_reg_embedding=1e-5,\n",
    "        l2_reg_cross=1e-5, attention_factor=8, l2_reg_att=1e-5, afm_dropout=0, l2_reg_dnn=0, seed=1024, dnn_dropout=0,bi_dropout=0, dnn_use_bn=False,\n",
    "        dnn_activation='relu', task='binary'):\n",
    "   \n",
    "    if len(dnn_hidden_units) == 0 and cross_num == 0:\n",
    "        raise ValueError(\"Either hidden_layer or cross layer must > 0\")\n",
    "\n",
    "    features = build_input_features(dnn_feature_columns)\n",
    "    inputs_list = list(features.values())\n",
    "\n",
    "    linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
    "                                    l2_reg=l2_reg_linear)\n",
    "\n",
    "#     sparse_embedding_list, dense_value_list = input_from_feature_columns(features, dnn_feature_columns,\n",
    "#                                                                          l2_reg_embedding, seed)\n",
    "    group_embedding_dict, dense_value_list = input_from_feature_columns(features, dnn_feature_columns, l2_reg_embedding,\n",
    "                                                                        seed = seed, support_group=True)\n",
    "            \n",
    "#   dnn_input = combined_dnn_input(list(chain.from_iterable(group_embedding_dict.values())), dense_value_list)\n",
    "    sparse_embedding_list = list(chain.from_iterable(group_embedding_dict.values()))\n",
    "    fm_logit = add_func([FM()(concat_func(v, axis=1))\n",
    "                         for k, v in group_embedding_dict.items() if k in fm_group])\n",
    "#     afm_logit = add_func([AFMLayer(attention_factor, l2_reg_att, afm_dropout,\n",
    "#                                       seed)(list(v)) for k, v in group_embedding_dict.items() if k in fm_group])\n",
    "    fm_input = concat_func(sparse_embedding_list, axis=1)\n",
    "    bi_out = BiInteractionPooling()(fm_input)\n",
    "    if bi_dropout:\n",
    "        bi_out = tf.keras.layers.Dropout(bi_dropout)(bi_out, training=None)\n",
    "    dnn_input = combined_dnn_input([bi_out], dense_value_list)\n",
    "\n",
    "#     dnn_input = combined_dnn_input(sparse_embedding_list, dense_value_list)\n",
    "\n",
    "    if len(dnn_hidden_units) > 0 and cross_num > 0:  # Deep & Cross\n",
    "        deep_out = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)\n",
    "        cross_out = CrossNet(cross_num, parameterization=cross_parameterization, l2_reg=l2_reg_cross)(dnn_input)\n",
    "        stack_out = Concatenate()([cross_out, deep_out])\n",
    "        final_logit = Dense(1, use_bias=False)(stack_out)\n",
    "    elif len(dnn_hidden_units) > 0:  # Only Deep\n",
    "        deep_out = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)\n",
    "        final_logit = Dense(1, use_bias=False)(deep_out)\n",
    "    elif cross_num > 0:  # Only Cross\n",
    "        cross_out = CrossNet(cross_num, parameterization=cross_parameterization, l2_reg=l2_reg_cross)(dnn_input)\n",
    "        final_logit = Dense(1, use_bias=False)(cross_out)\n",
    "    else:  # Error\n",
    "        raise NotImplementedError\n",
    "    linear_logit = Dense(1, use_bias=False, activation=None)(linear_logit)\n",
    "    final_logit = Dense(1, use_bias=False, activation=None)(final_logit)\n",
    "    final_logit = add_func([linear_logit, final_logit])\n",
    "    output = PredictionLayer(task)(final_logit)\n",
    "\n",
    "    model = Model(inputs=inputs_list, outputs=output)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "                          loss=losses.BinaryCrossentropy(), \n",
    "                          metrics=['AUC', 'binary_accuracy', 'Precision', 'Recall'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "lrs = [1]\n",
    "for i in lrs:\n",
    "    metric = []\n",
    "    for j in range(1):\n",
    "        model = DCNNFMA(linear_feature_columns, dnn_feature_columns, fm_group=[DEFAULT_GROUP_NAME], cross_num=2, cross_parameterization='vector',\n",
    "        dnn_hidden_units=(256, 128, 64), l2_reg_linear=1e-5, l2_reg_embedding=1e-5,\n",
    "        l2_reg_cross=1e-5, attention_factor=8, l2_reg_att=1e-5, afm_dropout=0, l2_reg_dnn=0, seed=1024, dnn_dropout=0,bi_dropout=0, dnn_use_bn=False,\n",
    "        dnn_activation='relu', task='binary')\n",
    "        input_train = deepfm_train\n",
    "        model.fit(input_train,\n",
    "                        label,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=100,\n",
    "                        batch_size=128,\n",
    "                        shuffle = False,\n",
    "                        verbose = 1, \n",
    "                        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],)\n",
    "        input_test = deepfm_test\n",
    "        ans_mtx = model.predict(input_test, batch_size=100)\n",
    "        loss, auc, acc, pre, rec = model.evaluate(input_test, label1)\n",
    "        metric.append([loss, auc, acc, pre, rec])\n",
    "    metric = np.array(metric)\n",
    "    print(metric)\n",
    "    metrics.append(metric)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics)\n",
    "print(*zip(lrs, np.mean(metrics, axis = 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
