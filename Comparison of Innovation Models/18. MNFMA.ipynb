{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_selection import mutual_info_classif as MIF\n",
    "import random\n",
    "import os\n",
    "# chain()可以把一组迭代对象串联起来，形成一个更大的迭代器\n",
    "from itertools import chain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import optimizers, layers, losses, metrics\n",
    "from tensorflow.keras.initializers import glorot_normal, he_normal\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Embedding, Lambda, multiply, Flatten, Concatenate\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from deepctr.inputs import get_dense_input, create_embedding_matrix, embedding_lookup, get_dense_input, varlen_embedding_lookup, \\\n",
    "    get_varlen_pooling_list, mergeDict\n",
    "from deepctr.layers.sequence import SequencePoolingLayer, Transformer, AttentionSequencePoolingLayer\n",
    "\n",
    "from deepctr.feature_column import  SparseFeat, DenseFeat, VarLenSparseFeat, get_feature_names, build_input_features, get_linear_logit, DEFAULT_GROUP_NAME, input_from_feature_columns\n",
    "from deepctr.layers.core import PredictionLayer, DNN\n",
    "from deepctr.layers.interaction import FM, FEFMLayer, BiInteractionPooling, AFMLayer, CIN, InteractingLayer, FwFMLayer, InnerProductLayer, OutterProductLayer, FGCNNLayer, CrossNet,  CrossNetMix\n",
    "from deepctr.layers.utils import concat_func, add_func, Hash, NoMask, combined_dnn_input, reduce_sum, softmax\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.initializers import Zeros, glorot_normal, RandomNormal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNFMA(linear_feature_columns, dnn_feature_columns, fm_group=[DEFAULT_GROUP_NAME], dnn_hidden_units=(128, 128),\n",
    "      l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, \n",
    "      seed=0, dnn_dropout=0,dropout = 0.1, bi_dropout=0, dnn_activation='relu', dnn_use_bn=False, task='binary'):\n",
    "            # deepFM处理过程\n",
    "            features = build_input_features(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "            inputs_list = list(features.values())\n",
    "\n",
    "            linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
    "                                    l2_reg=l2_reg_linear, )\n",
    "            group_embedding_dict, dense_value_list = input_from_feature_columns(features, dnn_feature_columns, l2_reg_embedding,\n",
    "                                                                        seed = seed, support_group=True)\n",
    "            \n",
    "#             dnn_input = combined_dnn_input(list(chain.from_iterable(group_embedding_dict.values())), dense_value_list)\n",
    "            sparse_embedding_list = list(chain.from_iterable(group_embedding_dict.values()))\n",
    "            fm_input = concat_func(sparse_embedding_list, axis=1)\n",
    "            bi_out = BiInteractionPooling()(fm_input)\n",
    "            if bi_dropout:\n",
    "                bi_out = tf.keras.layers.Dropout(bi_dropout)(bi_out, training=None)\n",
    "            dnn_input = combined_dnn_input([bi_out], dense_value_list)\n",
    "    \n",
    "            fm_logit = add_func([FM()(concat_func(v, axis=1))\n",
    "                         for k, v in group_embedding_dict.items() if k in fm_group])\n",
    "            dnn_output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout,\n",
    "                     dnn_use_bn, seed = seed)(dnn_input)\n",
    "            dnn_output=tf.keras.layers.Dropout(dropout, seed = seed)(dnn_output)\n",
    "\n",
    "            dnn_logit = tf.keras.layers.Dense(\n",
    "                    1, use_bias=False, activation=None, kernel_initializer=glorot_normal(seed=seed))(dnn_output)\n",
    "            fm_logit = Dense(1, use_bias=False)(fm_logit)\n",
    "            dnn_logit = Dense(1, use_bias=False)(dnn_logit)\n",
    "            final_logit = add_func([fm_logit, dnn_logit])\n",
    "            output = PredictionLayer(task)(final_logit)\n",
    "            #tensorflow模型拟合\n",
    "            model = Model(inputs=[features], outputs=[output])\n",
    "            #multi_category_focal_loss2(alpha=0.35, gamma=2)\n",
    "            model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "                          loss=losses.BinaryCrossentropy(), \n",
    "                          metrics=['AUC', 'binary_accuracy', 'Precision', 'Recall'])\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "lrs = [1]\n",
    "for i in lrs:\n",
    "    metric = []\n",
    "    for j in range(1):\n",
    "        model = MNFMA(linear_feature_columns, dnn_feature_columns, fm_group=[DEFAULT_GROUP_NAME], dnn_hidden_units=(128, 128),\n",
    "      l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, \n",
    "      seed=0, dnn_dropout=0,dropout = 0.1, bi_dropout=0, dnn_activation='relu', dnn_use_bn=False, task='binary')\n",
    "        input_train = deepfm_train\n",
    "        model.fit(input_train,\n",
    "                        label,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=100,\n",
    "                        batch_size=128,\n",
    "                        shuffle = False,\n",
    "                        verbose = 1, \n",
    "                        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],)\n",
    "        input_test = deepfm_test\n",
    "        ans_mtx = model.predict(input_test, batch_size=100)\n",
    "        loss, auc, acc, pre, rec = model.evaluate(input_test, label1)\n",
    "        metric.append([loss, auc, acc, pre, rec])\n",
    "    metric = np.array(metric)\n",
    "    print(metric)\n",
    "    metrics.append(metric)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics)\n",
    "print(*zip(lrs, np.mean(metrics, axis = 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
