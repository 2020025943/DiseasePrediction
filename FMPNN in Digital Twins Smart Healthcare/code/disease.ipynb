{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_selection import mutual_info_classif as MIF\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, ADASYN, RandomOverSampler, SVMSMOTE, KMeansSMOTE\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import random\n",
    "import os\n",
    "# chain()可以把一组迭代对象串联起来，形成一个更大的迭代器\n",
    "from itertools import chain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import optimizers, layers, losses, metrics\n",
    "from tensorflow.keras.initializers import glorot_normal, he_normal\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Embedding, Lambda, multiply\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from deepctr.inputs import get_dense_input, create_embedding_matrix, embedding_lookup, get_dense_input, varlen_embedding_lookup, \\\n",
    "    get_varlen_pooling_list, mergeDict\n",
    "from deepctr.layers.sequence import SequencePoolingLayer\n",
    "\n",
    "from deepctr.feature_column import  SparseFeat, DenseFeat, VarLenSparseFeat, get_feature_names, build_input_features, get_linear_logit, DEFAULT_GROUP_NAME, input_from_feature_columns\n",
    "from deepctr.layers.core import PredictionLayer, DNN\n",
    "from deepctr.layers.interaction import FM, FEFMLayer, BiInteractionPooling, AFMLayer, CIN, InteractingLayer, FwFMLayer, InnerProductLayer, OutterProductLayer\n",
    "from deepctr.layers.utils import concat_func, add_func, Hash, NoMask, combined_dnn_input, reduce_sum, softmax\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.initializers import Zeros, glorot_normal, RandomNormal\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "matplotlib.rcParams['font.size'] = 12\n",
    "np.random.seed(1024) # seed是一个固定的整数即可\n",
    "random.seed(1024)\n",
    "os.environ['PYTHONHASHSEED'] = str(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5105</td>\n",
       "      <td>18234</td>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>83.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5106</td>\n",
       "      <td>44873</td>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5107</td>\n",
       "      <td>19723</td>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5108</td>\n",
       "      <td>37544</td>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5109</td>\n",
       "      <td>44679</td>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0      9046    Male  67.0             0              1          Yes   \n",
       "1     51676  Female  61.0             0              0          Yes   \n",
       "2     31112    Male  80.0             0              1          Yes   \n",
       "3     60182  Female  49.0             0              0          Yes   \n",
       "4      1665  Female  79.0             1              0          Yes   \n",
       "...     ...     ...   ...           ...            ...          ...   \n",
       "5105  18234  Female  80.0             1              0          Yes   \n",
       "5106  44873  Female  81.0             0              0          Yes   \n",
       "5107  19723  Female  35.0             0              0          Yes   \n",
       "5108  37544    Male  51.0             0              0          Yes   \n",
       "5109  44679  Female  44.0             0              0          Yes   \n",
       "\n",
       "          work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0           Private          Urban             228.69  36.6  formerly smoked   \n",
       "1     Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2           Private          Rural             105.92  32.5     never smoked   \n",
       "3           Private          Urban             171.23  34.4           smokes   \n",
       "4     Self-employed          Rural             174.12  24.0     never smoked   \n",
       "...             ...            ...                ...   ...              ...   \n",
       "5105        Private          Urban              83.75   NaN     never smoked   \n",
       "5106  Self-employed          Urban             125.20  40.0     never smoked   \n",
       "5107  Self-employed          Rural              82.99  30.6     never smoked   \n",
       "5108        Private          Rural             166.29  25.6  formerly smoked   \n",
       "5109       Govt_job          Urban              85.28  26.2          Unknown   \n",
       "\n",
       "      stroke  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "5105       0  \n",
       "5106       0  \n",
       "5107       0  \n",
       "5108       0  \n",
       "5109       0  \n",
       "\n",
       "[5110 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('E:/BaiduNetdiskDownload/论文/论文/medmnist/healthcare-dataset-stroke-data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "Residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  201\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "gender                object\n",
       "age                  float64\n",
       "hypertension           int64\n",
       "heart_disease          int64\n",
       "ever_married          object\n",
       "work_type             object\n",
       "Residence_type        object\n",
       "avg_glucose_level    float64\n",
       "bmi                  float64\n",
       "smoking_status        object\n",
       "stroke                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'age', 'hypertension', 'heart_disease', 'ever_married',\n",
       "       'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
       "       'smoking_status', 'stroke'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(data[data.gender=='Other'].index,axis=0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "data.loc[:, ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']] = encoder.fit_transform(data[['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']])\n",
    "# imputer = SimpleImputer(strategy = 'mean')\n",
    "# data.loc[:, 'bmi'] = imputer.fit_transform(data.loc[:, 'bmi'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               float64\n",
       "age                  float64\n",
       "hypertension           int64\n",
       "heart_disease          int64\n",
       "ever_married         float64\n",
       "work_type            float64\n",
       "Residence_type       float64\n",
       "avg_glucose_level    float64\n",
       "bmi                  float64\n",
       "smoking_status       float64\n",
       "stroke                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4908, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke']:\n",
    "    data.loc[:, i] = data.loc[:, i].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['age', 'avg_glucose_level', 'bmi']:\n",
    "    data.loc[:, i] = data.loc[:, i].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                 int32\n",
       "age                  float32\n",
       "hypertension           int32\n",
       "heart_disease          int32\n",
       "ever_married           int32\n",
       "work_type              int32\n",
       "Residence_type         int32\n",
       "avg_glucose_level    float32\n",
       "bmi                  float32\n",
       "smoking_status         int32\n",
       "stroke                 int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop(columns=['stroke'])\n",
    "labe = data['stroke']\n",
    "dat, test, lab, label1 = train_test_split(data1, labe, test_size = 0.2, stratify=labe)\n",
    "# dat, test, lab, label1 = train_test_split(data1, labe, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.reset_index(drop = True)\n",
    "lab = lab.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>80.809998</td>\n",
       "      <td>33.200001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>82.720001</td>\n",
       "      <td>29.799999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>114.760002</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>218.100006</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100.050003</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3921</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>55.610001</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3922</td>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>72.959999</td>\n",
       "      <td>31.299999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3923</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>58.720001</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3924</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>207.789993</td>\n",
       "      <td>38.599998</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3925</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>127.320000</td>\n",
       "      <td>33.099998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3926 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease  ever_married  work_type  \\\n",
       "0          1  34.0             0              0             1          2   \n",
       "1          0  65.0             0              0             1          0   \n",
       "2          0  49.0             0              0             1          2   \n",
       "3          0  45.0             0              0             1          2   \n",
       "4          0  38.0             0              0             1          2   \n",
       "...      ...   ...           ...            ...           ...        ...   \n",
       "3921       1   6.0             0              0             0          4   \n",
       "3922       1  74.0             0              0             1          2   \n",
       "3923       0  35.0             0              0             1          2   \n",
       "3924       0  54.0             0              0             1          2   \n",
       "3925       0  58.0             0              0             1          2   \n",
       "\n",
       "      Residence_type  avg_glucose_level        bmi  smoking_status  \n",
       "0                  1          80.809998  33.200001               2  \n",
       "1                  1          82.720001  29.799999               3  \n",
       "2                  0         114.760002  24.700001               2  \n",
       "3                  0         218.100006  55.000000               3  \n",
       "4                  0         100.050003  20.799999               3  \n",
       "...              ...                ...        ...             ...  \n",
       "3921               1          55.610001  19.600000               0  \n",
       "3922               1          72.959999  31.299999               3  \n",
       "3923               0          58.720001  40.000000               3  \n",
       "3924               1         207.789993  38.599998               2  \n",
       "3925               0         127.320000  33.099998               3  \n",
       "\n",
       "[3926 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "3921    0\n",
       "3922    1\n",
       "3923    0\n",
       "3924    0\n",
       "3925    0\n",
       "Name: stroke, Length: 3926, dtype: int32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = RandomUnderSampler(random_state=42)\n",
    "# sm = SMOTEENN(random_state=42)\n",
    "# sm = KMeansSMOTE(random_state=42)\n",
    "# sm = SVMSMOTE(random_state=42)\n",
    "# sm = RandomOverSampler(random_state=42)\n",
    "# sm = ADASYN(random_state=42)\n",
    "sm = BorderlineSMOTE(random_state=42,kind=\"borderline-2\")\n",
    "# sm =  SMOTETomek(random_state=42) #实例化\n",
    "# sm = SMOTE(random_state=42)\n",
    "dat, lab = sm.fit_sample(dat,lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat((dat, lab), axis = 1)\n",
    "train = shuffle(train)\n",
    "train = train.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4082"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = OneClassSVM(kernel=\"rbf\")\n",
    "# clf = clf.fit(train)\n",
    "# y_pred = clf.predict(train)\n",
    "# y_pred=np.array([1 if x == 1 else 0 for x in y_pred])\n",
    "# y_pred[y_pred == 1].sum()\n",
    "clf = IsolationForest(n_estimators=100)\n",
    "clf = clf.fit(train)\n",
    "y_pred = clf.predict(train)\n",
    "y_pred=np.array([1 if x == 1 else 0 for x in y_pred])\n",
    "y_pred[y_pred == 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3705"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_pred == lab).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train = train[y_pred == lab]\n",
    "# train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ever_married'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = train.drop(columns=['stroke'])\n",
    "lab = train['stroke']\n",
    "result = MIF(dat, lab)\n",
    "dat.columns[result <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "RFC_ = RFC(n_estimators =10,random_state=0)\n",
    "score = []\n",
    "for i in range(1,11,1):\n",
    "    X_wrapper = RFE(RFC_,n_features_to_select=i, step=1).fit_transform(dat,lab)\n",
    "    once = cross_val_score(RFC_,X_wrapper,lab,cv=5).mean()\n",
    "    score.append(once)\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.plot(range(1,11,1),score)\n",
    "plt.xticks(range(1,11,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = train.copy()\n",
    "# data_test = test.copy()\n",
    "train = data_train.drop(columns=['stroke'])\n",
    "label = data_train['stroke']\n",
    "# test = data_test.drop(columns=['stroke'])\n",
    "# label1 = data_test['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(label1 == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7517, 982)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0],test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train.append(test)\n",
    "dense_features=['age', 'avg_glucose_level', 'bmi']\n",
    "sparse_features = list(set(data.columns.tolist()).difference(set(dense_features)))\n",
    "\n",
    "# 离散型数据进行标签化处理\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "# 连续型数据进行归一化处理，使其范围在（0，1）\n",
    "mms = StandardScaler()\n",
    "# mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4)\n",
    "                        for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
    "                        for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 3.generate input deepfm_data for model\n",
    "# train, test = train_test_split(deepfm_data, test_size=0.2)\n",
    "\n",
    "deepfm_train = data.head(train.shape[0])\n",
    "deepfm_test = data.tail(test.shape[0])\n",
    "\n",
    "deepfm_train = {name:deepfm_train[name] for name in feature_names}\n",
    "deepfm_test = {name:deepfm_test[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PNN2(dnn_feature_columns, dnn_hidden_units=(256, 128, 64), l2_reg_embedding=0.00001, l2_reg_dnn=0,\n",
    "#         seed=1024, dnn_dropout=0, dnn_activation='relu', use_inner=True, use_outter=False, kernel_type='mat',\n",
    "#         task='binary'):\n",
    "#     if kernel_type not in ['mat', 'vec', 'num']:\n",
    "#         raise ValueError(\"kernel_type must be mat,vec or num\")\n",
    "\n",
    "#     features = build_input_features(dnn_feature_columns)\n",
    "\n",
    "#     inputs_list = list(features.values())\n",
    "\n",
    "#     sparse_embedding_list, dense_value_list = input_from_feature_columns(features, dnn_feature_columns,\n",
    "#                                                                          l2_reg_embedding, seed)\n",
    "#     inner_product = tf.keras.layers.Flatten()(\n",
    "#         InnerProductLayer()(sparse_embedding_list))\n",
    "#     outter_product = OutterProductLayer(kernel_type)(sparse_embedding_list)\n",
    "\n",
    "#     # ipnn deep input\n",
    "#     linear_signal = tf.keras.layers.Reshape(\n",
    "#         [sum(map(lambda x: int(x.shape[-1]), sparse_embedding_list))])(concat_func(sparse_embedding_list))\n",
    "\n",
    "#     if use_inner and use_outter:\n",
    "#         deep_input = tf.keras.layers.Concatenate()(\n",
    "#             [linear_signal, inner_product, outter_product])\n",
    "#     elif use_inner:\n",
    "#         deep_input = tf.keras.layers.Concatenate()(\n",
    "#             [linear_signal, inner_product])\n",
    "#     elif use_outter:\n",
    "#         deep_input = tf.keras.layers.Concatenate()(\n",
    "#             [linear_signal, outter_product])\n",
    "#     else:\n",
    "#         deep_input = linear_signal\n",
    "\n",
    "#     dnn_input = combined_dnn_input([deep_input], dense_value_list)\n",
    "#     dnn_out = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, False, seed=seed)(dnn_input)\n",
    "#     dnn_logit = tf.keras.layers.Dense(\n",
    "#         1, use_bias=False, kernel_initializer=tf.keras.initializers.glorot_normal(seed))(dnn_out)\n",
    "\n",
    "#     output = PredictionLayer(task)(dnn_logit)\n",
    "\n",
    "#     model = tf.keras.models.Model(inputs=inputs_list, outputs=output)\n",
    "#     model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "#             loss=losses.BinaryCrossentropy(), \n",
    "#             metrics=['AUC', 'binary_accuracy', 'Precision', 'Recall', 'FalseNegatives', 'TruePositives', 'TrueNegatives', 'FalsePositives'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_from_feature_columns(features, feature_columns, l2_reg, seed, prefix='', seq_mask_zero=True,\n",
    "                               support_dense=True, support_group=False):\n",
    "    sparse_feature_columns = list(\n",
    "        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if feature_columns else []\n",
    "    varlen_sparse_feature_columns = list(\n",
    "        filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n",
    "\n",
    "    embedding_matrix_dict = create_embedding_matrix(feature_columns, l2_reg, seed, prefix=prefix,\n",
    "                                                    seq_mask_zero=seq_mask_zero)\n",
    "    group_sparse_embedding_dict = embedding_lookup(embedding_matrix_dict, features, sparse_feature_columns)\n",
    "    dense_value_list = get_dense_input(features, feature_columns)\n",
    "    if not support_dense and len(dense_value_list) > 0:\n",
    "        raise ValueError(\"DenseFeat is not supported in dnn_feature_columns\")\n",
    "\n",
    "    sequence_embed_dict = varlen_embedding_lookup(embedding_matrix_dict, features, varlen_sparse_feature_columns)\n",
    "    group_varlen_sparse_embedding_dict = get_varlen_pooling_list(sequence_embed_dict, features,\n",
    "                                                                 varlen_sparse_feature_columns)\n",
    "    group_embedding_dict = mergeDict(group_sparse_embedding_dict, group_varlen_sparse_embedding_dict)\n",
    "#     if not support_group:\n",
    "#         group_embedding_dict = list(chain.from_iterable(group_embedding_dict.values()))\n",
    "    return group_embedding_dict, dense_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DIFM(linear_feature_columns, dnn_feature_columns,\n",
    "#          att_embedding_size=8, att_head_num=8, att_res=True, dnn_hidden_units=(256, 128, 64),\n",
    "#          l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, seed=1024, dnn_dropout=0,\n",
    "#          dnn_activation='relu', dnn_use_bn=False, task='binary'):\n",
    "#     if not len(dnn_hidden_units) > 0:\n",
    "#         raise ValueError(\"dnn_hidden_units is null!\")\n",
    "\n",
    "#     features = build_input_features(\n",
    "#         linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "#     sparse_feat_num = len(list(filter(lambda x: isinstance(x, SparseFeat) or isinstance(x, VarLenSparseFeat),\n",
    "#                                       dnn_feature_columns)))\n",
    "#     inputs_list = list(features.values())\n",
    "\n",
    "#     sparse_embedding_list, _ = input_from_feature_columns(features, dnn_feature_columns,\n",
    "#                                                           l2_reg_embedding, seed)\n",
    "\n",
    "#     if not len(sparse_embedding_list) > 0:\n",
    "#         raise ValueError(\"there are no sparse features\")\n",
    "\n",
    "#     att_input = concat_func(sparse_embedding_list, axis=1)\n",
    "#     att_out = InteractingLayer(att_embedding_size, att_head_num, att_res, scaling=True)(att_input)\n",
    "#     att_out = tf.keras.layers.Flatten()(att_out)\n",
    "#     m_vec = tf.keras.layers.Dense(\n",
    "#         sparse_feat_num, use_bias=False, kernel_initializer=tf.keras.initializers.glorot_normal(seed=seed))(att_out)\n",
    "\n",
    "#     dnn_input = combined_dnn_input(sparse_embedding_list, [])\n",
    "#     dnn_output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)\n",
    "#     m_bit = tf.keras.layers.Dense(\n",
    "#         sparse_feat_num, use_bias=False, kernel_initializer=tf.keras.initializers.glorot_normal(seed=seed))(dnn_output)\n",
    "\n",
    "#     input_aware_factor = add_func([m_vec, m_bit])  # the complete input-aware factor m_x\n",
    "\n",
    "#     linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
    "#                                     l2_reg=l2_reg_linear, sparse_feat_refine_weight=input_aware_factor)\n",
    "\n",
    "#     fm_input = concat_func(sparse_embedding_list, axis=1)\n",
    "#     refined_fm_input = tf.keras.layers.Lambda(lambda x: x[0] * tf.expand_dims(x[1], axis=-1))(\n",
    "#         [fm_input, input_aware_factor])\n",
    "#     fm_logit = FM()(refined_fm_input)\n",
    "\n",
    "#     final_logit = add_func([linear_logit, fm_logit])\n",
    "\n",
    "#     output = PredictionLayer(task)(final_logit)\n",
    "#     model = tf.keras.models.Model(inputs=inputs_list, outputs=output)\n",
    "#     model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "#             loss=losses.BinaryCrossentropy(), \n",
    "#             metrics=['AUC', 'binary_accuracy', 'Precision', 'Recall', 'FalseNegatives', 'TruePositives', 'TrueNegatives', 'FalsePositives'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DeepFEFM(linear_feature_columns, dnn_feature_columns, use_fefm=True,\n",
    "#              dnn_hidden_units=(256, 128, 64), l2_reg_linear=0.00001, l2_reg_embedding_feat=0.00001,\n",
    "#              l2_reg_embedding_field=0.00001, l2_reg_dnn=0, seed=1024, dnn_dropout=0.0,\n",
    "#              exclude_feature_embed_in_dnn=False,\n",
    "#              use_linear=True, use_fefm_embed_in_dnn=True, dnn_activation='relu', dnn_use_bn=False, task='binary'):\n",
    "#     features = build_input_features(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "#     inputs_list = list(features.values())\n",
    "\n",
    "#     linear_logit = get_linear_logit(features, linear_feature_columns, l2_reg=l2_reg_linear, seed=seed, prefix='linear')\n",
    "\n",
    "#     group_embedding_dict, dense_value_list = input_from_feature_columns(features, dnn_feature_columns,\n",
    "#                                                                         l2_reg_embedding_feat,\n",
    "#                                                                         seed, support_group=True)\n",
    "\n",
    "#     fefm_interaction_embedding = concat_func([FEFMLayer(\n",
    "#         regularizer=l2_reg_embedding_field)(concat_func(v, axis=1))\n",
    "#                                               for k, v in group_embedding_dict.items() if k in [DEFAULT_GROUP_NAME]],\n",
    "#                                              axis=1)\n",
    "\n",
    "#     dnn_input = combined_dnn_input(list(chain.from_iterable(group_embedding_dict.values())), dense_value_list)\n",
    "\n",
    "#     # if use_fefm_embed_in_dnn is set to False it is Ablation4 (Use false only for Ablation)\n",
    "#     if use_fefm_embed_in_dnn:\n",
    "#         if exclude_feature_embed_in_dnn:\n",
    "#             # Ablation3: remove feature vector embeddings from the DNN input\n",
    "#             dnn_input = fefm_interaction_embedding\n",
    "#         else:\n",
    "#             # No ablation\n",
    "#             dnn_input = concat_func([dnn_input, fefm_interaction_embedding], axis=1)\n",
    "\n",
    "#     dnn_out = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, dnn_use_bn, seed=seed)(dnn_input)\n",
    "\n",
    "#     dnn_logit = tf.keras.layers.Dense(\n",
    "#         1, use_bias=False, kernel_initializer=tf.keras.initializers.glorot_normal(seed))(dnn_out)\n",
    "\n",
    "#     fefm_logit = tf.keras.layers.Lambda(lambda x: reduce_sum(x, axis=1, keep_dims=True))(fefm_interaction_embedding)\n",
    "\n",
    "#     if len(dnn_hidden_units) == 0 and use_fefm is False and use_linear is True:  # only linear\n",
    "#         final_logit = linear_logit\n",
    "#     elif len(dnn_hidden_units) == 0 and use_fefm is True and use_linear is True:  # linear + FEFM\n",
    "#         final_logit = tf.keras.layers.add([linear_logit, fefm_logit])\n",
    "#     elif len(dnn_hidden_units) > 0 and use_fefm is False and use_linear is True:  # linear +　Deep # Ablation1\n",
    "#         final_logit = tf.keras.layers.add([linear_logit, dnn_logit])\n",
    "#     elif len(dnn_hidden_units) > 0 and use_fefm is True and use_linear is True:  # linear + FEFM + Deep\n",
    "#         final_logit = tf.keras.layers.add([linear_logit, fefm_logit, dnn_logit])\n",
    "#     elif len(dnn_hidden_units) == 0 and use_fefm is True and use_linear is False:  # only FEFM (shallow)\n",
    "#         final_logit = fefm_logit\n",
    "#     elif len(dnn_hidden_units) > 0 and use_fefm is False and use_linear is False:  # only Deep\n",
    "#         final_logit = dnn_logit\n",
    "#     elif len(dnn_hidden_units) > 0 and use_fefm is True and use_linear is False:  # FEFM + Deep # Ablation2\n",
    "#         final_logit = tf.keras.layers.add([fefm_logit, dnn_logit])\n",
    "#     else:\n",
    "#         raise NotImplementedError\n",
    "\n",
    "#     output = PredictionLayer(task)(final_logit)\n",
    "#     model = tf.keras.models.Model(inputs=inputs_list, outputs=output)\n",
    "#     model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "#                loss=losses.BinaryCrossentropy(), \n",
    "#                metrics=['AUC', 'binary_accuracy', 'Precision', 'Recall', 'FalseNegatives', 'TruePositives', 'TrueNegatives', 'FalsePositives'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def NFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(256, 128, 64),\n",
    "#         l2_reg_embedding=1e-5, l2_reg_linear=1e-5, l2_reg_dnn=0, seed=1024, bi_dropout=0,\n",
    "#         dnn_dropout=0, dnn_activation='relu', task='binary'):\n",
    "#     features = build_input_features(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "#     inputs_list = list(features.values())\n",
    "\n",
    "#     linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
    "#                                     l2_reg=l2_reg_linear)\n",
    "\n",
    "#     sparse_embedding_list, dense_value_list = input_from_feature_columns(features, dnn_feature_columns,\n",
    "#                                                                          l2_reg_embedding, seed)\n",
    "\n",
    "#     fm_input = concat_func(sparse_embedding_list, axis=1)\n",
    "#     bi_out = BiInteractionPooling()(fm_input)\n",
    "#     if bi_dropout:\n",
    "#         bi_out = tf.keras.layers.Dropout(bi_dropout)(bi_out, training=None)\n",
    "#     dnn_input = combined_dnn_input([bi_out], dense_value_list)\n",
    "#     dnn_output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, False, seed=seed)(dnn_input)\n",
    "#     dnn_logit = tf.keras.layers.Dense(\n",
    "#         1, use_bias=False, kernel_initializer=tf.keras.initializers.glorot_normal(seed))(dnn_output)\n",
    "\n",
    "#     final_logit = add_func([linear_logit, dnn_logit])\n",
    "\n",
    "#     output = PredictionLayer(task)(final_logit)\n",
    "\n",
    "#     model = tf.keras.models.Model(inputs=inputs_list, outputs=output)\n",
    "#     model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "#             loss=losses.BinaryCrossentropy(), \n",
    "#             metrics=['AUC', 'binary_accuracy', 'Precision', 'Recall', 'FalseNegatives', 'TruePositives', 'TrueNegatives', 'FalsePositives'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def AFM(linear_feature_columns, dnn_feature_columns, fm_group=DEFAULT_GROUP_NAME, use_attention=True,\n",
    "#         attention_factor=8,l2_reg_linear=1e-5, l2_reg_embedding=1e-5, l2_reg_att=1e-5, afm_dropout=0, seed=1024,\n",
    "#         task='binary'):\n",
    "#     features = build_input_features(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "#     inputs_list = list(features.values())\n",
    "\n",
    "#     group_embedding_dict, _ = input_from_feature_columns(features, dnn_feature_columns, l2_reg_embedding,\n",
    "#                                                          seed, support_dense=True, support_group=True)\n",
    "\n",
    "#     linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
    "#                                     l2_reg=l2_reg_linear)\n",
    "\n",
    "#     if use_attention:\n",
    "#         fm_logit = add_func([AFMLayer(attention_factor, l2_reg_att, afm_dropout,\n",
    "#                                       seed)(list(v)) for k, v in group_embedding_dict.items() if k in fm_group])\n",
    "#     else:\n",
    "#         fm_logit = add_func([FM()(concat_func(v, axis=1))\n",
    "#                              for k, v in group_embedding_dict.items() if k in fm_group])\n",
    "\n",
    "#     final_logit = add_func([linear_logit, fm_logit])\n",
    "#     output = PredictionLayer(task)(final_logit)\n",
    "\n",
    "#     model = tf.keras.models.Model(inputs=inputs_list, outputs=output)\n",
    "#     model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "#                loss=losses.BinaryCrossentropy(), \n",
    "#                metrics=['AUC', 'binary_accuracy', 'Precision', 'Recall', 'FalseNegatives', 'TruePositives', 'TrueNegatives', 'FalsePositives'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_balanced_sigmoid_cross_entropy(label, logits):\n",
    "    y = tf.cast(label, tf.float32)\n",
    "    logits = tf.cast(logits, tf.float32)\n",
    "    count_neg = tf.reduce_sum(1. - y) # the number of 0 in y\n",
    "    count_pos = tf.reduce_sum(y) # the number of 1 in y (less than count_neg)\n",
    "    beta = count_neg / (count_neg + count_pos)\n",
    "\n",
    "    pos_weight = beta / (1 - beta)\n",
    "    cost = tf.nn.weighted_cross_entropy_with_logits(y, logits, pos_weight)\n",
    "    cost = tf.reduce_mean(cost * (1 - beta))\n",
    "    return cost\n",
    "def PNN(linear_feature_columns, dnn_feature_columns, fm_group=[DEFAULT_GROUP_NAME], dnn_hidden_units=(256, 128, 64), \n",
    "        l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, l2_reg_att=2.1, attention_factor=4, \n",
    "        afm_dropout=0.8, seed=1024, dnn_dropout=0, dnn_activation='relu', use_inner=True, use_outter=False, \n",
    "        kernel_type='mat',task='binary'):\n",
    "    if kernel_type not in ['mat', 'vec', 'num']:\n",
    "        raise ValueError(\"kernel_type must be mat,vec or num\")\n",
    "\n",
    "    features = build_input_features(dnn_feature_columns)\n",
    "\n",
    "    inputs_list = list(features.values())\n",
    "\n",
    "    linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
    "                                    l2_reg=l2_reg_linear)\n",
    "    group_embedding_dict, dense_value_list = input_from_feature_columns(features, dnn_feature_columns,\n",
    "                                                                         l2_reg_embedding, seed)\n",
    "    sparse_embedding_list = list(chain.from_iterable(group_embedding_dict.values()))\n",
    "    fm_logit = add_func([FM()(concat_func(v, axis=1)) \n",
    "                         for k, v in group_embedding_dict.items() if k in fm_group])\n",
    "    afm_logit = add_func([AFMLayer(attention_factor, l2_reg_att, afm_dropout,\n",
    "                                    seed)(list(v)) for k, v in group_embedding_dict.items() if k in fm_group])\n",
    "    inner_product = tf.keras.layers.Flatten()(\n",
    "        InnerProductLayer()(sparse_embedding_list))\n",
    "    outter_product = OutterProductLayer(kernel_type)(sparse_embedding_list)\n",
    "\n",
    "    # ipnn deep input\n",
    "    linear_signal = tf.keras.layers.Reshape(\n",
    "        [sum(map(lambda x: int(x.shape[-1]), sparse_embedding_list))])(concat_func(sparse_embedding_list))\n",
    "\n",
    "    if use_inner and use_outter:\n",
    "        deep_input = tf.keras.layers.Concatenate()(\n",
    "            [linear_signal, inner_product, outter_product])\n",
    "    elif use_inner:\n",
    "        deep_input = tf.keras.layers.Concatenate()(\n",
    "            [linear_signal, inner_product])\n",
    "    elif use_outter:\n",
    "        deep_input = tf.keras.layers.Concatenate()(\n",
    "            [linear_signal, outter_product])\n",
    "    else:\n",
    "        deep_input = linear_signal\n",
    "\n",
    "    dnn_input = combined_dnn_input([deep_input], dense_value_list)\n",
    "    dnn_out = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout, False, seed=seed)(dnn_input)\n",
    "    dnn_out = tf.keras.layers.BatchNormalization()(dnn_out)\n",
    "    dnn_out = tf.keras.layers.Dense(\n",
    "        64, activation = 'relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed))(dnn_out)\n",
    "    dnn_out = tf.keras.layers.BatchNormalization()(dnn_out)\n",
    "    dnn_logit = tf.keras.layers.Dense(\n",
    "        1, use_bias=False, kernel_initializer=tf.keras.initializers.glorot_normal(seed))(dnn_out)\n",
    "    final_logit = add_func([fm_logit, dnn_logit])\n",
    "    output = PredictionLayer(task)(final_logit)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs_list, outputs=output)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "            loss=losses.BinaryCrossentropy(),\n",
    "            metrics=['AUC', 'binary_accuracy', 'Precision', 'Recall', 'FalseNegatives', 'TruePositives', 'TrueNegatives', 'FalsePositives'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def focal_loss(gamma=2., alpha=0.25):\n",
    " \n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#         loss = -tf.reduce_sum(alpha * tf.pow(1. - pt_1, gamma) * tf.math.log(1e-07+pt_1)) \\\n",
    "#            -tf.reduce_sum((1-alpha) * tf.pow( pt_0, gamma) * tf.math.log(1. - pt_0 + 1e-07))\n",
    "#         return loss\n",
    "#     return focal_loss_fixed\n",
    "# def M(linear_feature_columns, dnn_feature_columns, fm_group=[DEFAULT_GROUP_NAME], dnn_hidden_units=(128, 128),\n",
    "#       l2_reg_linear=0.00001, lr = 0.001, l2_reg_embedding=0.00001, l2_reg_dnn=0, \n",
    "#       seed=0, dnn_dropout=0,dropout = 0.1, dnn_activation='relu', dnn_use_bn=False, task='binary'):\n",
    "#             # deepFM处理过程\n",
    "#             features = build_input_features(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "#             inputs_list = list(features.values())\n",
    "\n",
    "#             linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
    "#                                     l2_reg=l2_reg_linear, )\n",
    "#             group_embedding_dict, dense_value_list = input_from_feature_columns(features, dnn_feature_columns, l2_reg_embedding,\n",
    "#                                                                         seed = seed, support_group=True)\n",
    "#             fm_logit = add_func([FM()(concat_func(v, axis=1))\n",
    "#                          for k, v in group_embedding_dict.items() if k in fm_group])\n",
    "\n",
    "#             dnn_input = combined_dnn_input(list(chain.from_iterable(\n",
    "#                     group_embedding_dict.values())), dense_value_list)\n",
    "\n",
    "#             dnn_output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout,\n",
    "#                      dnn_use_bn, seed = seed)(dnn_input)\n",
    "#             dnn_output=tf.keras.layers.Dropout(dropout, seed = seed)(dnn_output)\n",
    "# #             dnn_output = tf.keras.layers.Dense(128, activation = 'relu', kernel_initializer=glorot_normal(seed=0), \n",
    "# #                                    kernel_regularizer = tf.keras.regularizers.l2(reg))(dnn_output)\n",
    "# #             dnn_output = tf.keras.layers.Dense(\n",
    "# #                     128, activation ='relu', kernel_initializer=he_normal(seed=seed))(dnn_output)\n",
    "# #             dnn_output = tf.keras.layers.Dense(\n",
    "# #                     128, activation ='relu', kernel_initializer=he_normal(seed=seed))(dnn_output)\n",
    "# #             dnn_output = tf.keras.layers.Dense(\n",
    "# #                     128, activation='relu', kernel_initializer=he_normal(seed=seed))(dnn_output)\n",
    "            \n",
    "# #             linear_logit = tf.keras.layers.Dense(\n",
    "# #                     1, activation ='relu', kernel_initializer=he_normal(seed=seed))(linear_logit)\n",
    "# #             fm_logit = tf.keras.layers.Dense(\n",
    "# #                     1, activation ='relu', kernel_initializer=he_normal(seed=seed))(fm_logit)\n",
    "#             dnn_logit = tf.keras.layers.Dense(\n",
    "#                     1, use_bias=False, activation=None, kernel_initializer=glorot_normal(seed=seed))(dnn_output)\n",
    "#             final_logit = add_func([linear_logit, fm_logit, dnn_logit])\n",
    "#             output = PredictionLayer(task)(final_logit)\n",
    "#             #tensorflow模型拟合\n",
    "#             model = Model(inputs=[features], outputs=[output])\n",
    "#             #multi_category_focal_loss2(alpha=0.35, gamma=2)\n",
    "#             model.compile(optimizer=optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "#                loss=losses.BinaryCrossentropy(), \n",
    "#                metrics=['AUC', 'binary_accuracy', 'Precision', 'Recall', 'FalseNegatives', 'TruePositives', 'TrueNegatives', 'FalsePositives'])\n",
    "#             return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_30), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer_30/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 2s 39ms/step - loss: 0.5594 - auc: 0.7806 - binary_accuracy: 0.7078 - precision: 0.6994 - recall: 0.7424 - false_negatives: 785.0000 - true_positives: 2262.0000 - true_negatives: 1994.0000 - false_positives: 972.0000 - val_loss: 0.5101 - val_auc: 0.8682 - val_binary_accuracy: 0.8092 - val_precision: 0.7585 - val_recall: 0.8748 - val_false_negatives: 89.0000 - val_true_positives: 622.0000 - val_true_negatives: 595.0000 - val_false_positives: 198.0000\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.4861 - auc: 0.8350 - binary_accuracy: 0.7811 - precision: 0.7460 - recall: 0.8615 - false_negatives: 422.0000 - true_positives: 2625.0000 - true_negatives: 2072.0000 - false_positives: 894.0000 - val_loss: 0.4876 - val_auc: 0.8715 - val_binary_accuracy: 0.8092 - val_precision: 0.7506 - val_recall: 0.8931 - val_false_negatives: 76.0000 - val_true_positives: 635.0000 - val_true_negatives: 582.0000 - val_false_positives: 211.0000\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.4655 - auc: 0.8469 - binary_accuracy: 0.7866 - precision: 0.7457 - recall: 0.8786 - false_negatives: 370.0000 - true_positives: 2677.0000 - true_negatives: 2053.0000 - false_positives: 913.0000 - val_loss: 0.4641 - val_auc: 0.8748 - val_binary_accuracy: 0.8132 - val_precision: 0.7560 - val_recall: 0.8931 - val_false_negatives: 76.0000 - val_true_positives: 635.0000 - val_true_negatives: 588.0000 - val_false_positives: 205.0000\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.4548 - auc: 0.8575 - binary_accuracy: 0.7971 - precision: 0.7558 - recall: 0.8858 - false_negatives: 348.0000 - true_positives: 2699.0000 - true_negatives: 2094.0000 - false_positives: 872.0000 - val_loss: 0.4426 - val_auc: 0.8830 - val_binary_accuracy: 0.8191 - val_precision: 0.7598 - val_recall: 0.9030 - val_false_negatives: 69.0000 - val_true_positives: 642.0000 - val_true_negatives: 590.0000 - val_false_positives: 203.0000\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.4438 - auc: 0.8659 - binary_accuracy: 0.8063 - precision: 0.7663 - recall: 0.8887 - false_negatives: 339.0000 - true_positives: 2708.0000 - true_negatives: 2140.0000 - false_positives: 826.0000 - val_loss: 0.4248 - val_auc: 0.8872 - val_binary_accuracy: 0.8231 - val_precision: 0.7665 - val_recall: 0.9001 - val_false_negatives: 71.0000 - val_true_positives: 640.0000 - val_true_negatives: 598.0000 - val_false_positives: 195.0000\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.4345 - auc: 0.8760 - binary_accuracy: 0.8204 - precision: 0.7784 - recall: 0.9025 - false_negatives: 297.0000 - true_positives: 2750.0000 - true_negatives: 2183.0000 - false_positives: 783.0000 - val_loss: 0.4119 - val_auc: 0.8974 - val_binary_accuracy: 0.8338 - val_precision: 0.7774 - val_recall: 0.9086 - val_false_negatives: 65.0000 - val_true_positives: 646.0000 - val_true_negatives: 608.0000 - val_false_positives: 185.0000\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.4229 - auc: 0.8863 - binary_accuracy: 0.8244 - precision: 0.7845 - recall: 0.9009 - false_negatives: 302.0000 - true_positives: 2745.0000 - true_negatives: 2212.0000 - false_positives: 754.0000 - val_loss: 0.3933 - val_auc: 0.9133 - val_binary_accuracy: 0.8451 - val_precision: 0.7987 - val_recall: 0.8987 - val_false_negatives: 72.0000 - val_true_positives: 639.0000 - val_true_negatives: 632.0000 - val_false_positives: 161.0000\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.4136 - auc: 0.8962 - binary_accuracy: 0.8294 - precision: 0.7973 - recall: 0.8894 - false_negatives: 337.0000 - true_positives: 2710.0000 - true_negatives: 2277.0000 - false_positives: 689.00 - 1s 12ms/step - loss: 0.4136 - auc: 0.8962 - binary_accuracy: 0.8294 - precision: 0.7973 - recall: 0.8894 - false_negatives: 337.0000 - true_positives: 2710.0000 - true_negatives: 2277.0000 - false_positives: 689.0000 - val_loss: 0.3809 - val_auc: 0.9213 - val_binary_accuracy: 0.8484 - val_precision: 0.8045 - val_recall: 0.8973 - val_false_negatives: 73.0000 - val_true_positives: 638.0000 - val_true_negatives: 638.0000 - val_false_positives: 155.0000\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.3963 - auc: 0.9040 - binary_accuracy: 0.8405 - precision: 0.8056 - recall: 0.9032 - false_negatives: 295.0000 - true_positives: 2752.0000 - true_negatives: 2302.0000 - false_positives: 664.0000 - val_loss: 0.3650 - val_auc: 0.9283 - val_binary_accuracy: 0.8544 - val_precision: 0.8146 - val_recall: 0.8959 - val_false_negatives: 74.0000 - val_true_positives: 637.0000 - val_true_negatives: 648.0000 - val_false_positives: 145.0000\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3904 - auc: 0.9089 - binary_accuracy: 0.8440 - precision: 0.8143 - recall: 0.8966 - false_negatives: 315.0000 - true_positives: 2732.0000 - true_negatives: 2343.0000 - false_positives: 623.0000 - val_loss: 0.3669 - val_auc: 0.9291 - val_binary_accuracy: 0.8531 - val_precision: 0.8393 - val_recall: 0.8523 - val_false_negatives: 105.0000 - val_true_positives: 606.0000 - val_true_negatives: 677.0000 - val_false_positives: 116.0000\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3782 - auc: 0.9160 - binary_accuracy: 0.8458 - precision: 0.8220 - recall: 0.8881 - false_negatives: 341.0000 - true_positives: 2706.0000 - true_negatives: 2380.0000 - false_positives: 586.0000 - val_loss: 0.3486 - val_auc: 0.9332 - val_binary_accuracy: 0.8564 - val_precision: 0.8218 - val_recall: 0.8889 - val_false_negatives: 79.0000 - val_true_positives: 632.0000 - val_true_negatives: 656.0000 - val_false_positives: 137.0000\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3744 - auc: 0.9177 - binary_accuracy: 0.8483 - precision: 0.8203 - recall: 0.8973 - false_negatives: 313.0000 - true_positives: 2734.0000 - true_negatives: 2367.0000 - false_positives: 599.0000 - val_loss: 0.3580 - val_auc: 0.9310 - val_binary_accuracy: 0.8531 - val_precision: 0.8451 - val_recall: 0.8439 - val_false_negatives: 111.0000 - val_true_positives: 600.0000 - val_true_negatives: 683.0000 - val_false_positives: 110.0000\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3636 - auc: 0.9229 - binary_accuracy: 0.8540 - precision: 0.8307 - recall: 0.8940 - false_negatives: 323.0000 - true_positives: 2724.0000 - true_negatives: 2411.0000 - false_positives: 555.0000 - val_loss: 0.3447 - val_auc: 0.9344 - val_binary_accuracy: 0.8624 - val_precision: 0.8351 - val_recall: 0.8833 - val_false_negatives: 83.0000 - val_true_positives: 628.0000 - val_true_negatives: 669.0000 - val_false_positives: 124.0000\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - ETA: 0s - loss: 0.3668 - auc: 0.9216 - binary_accuracy: 0.8481 - precision: 0.8213 - recall: 0.8949 - false_negatives: 293.0000 - true_positives: 2496.0000 - true_negatives: 2172.0000 - false_positives: 543.00 - 1s 15ms/step - loss: 0.3667 - auc: 0.9216 - binary_accuracy: 0.8475 - precision: 0.8239 - recall: 0.8891 - false_negatives: 338.0000 - true_positives: 2709.0000 - true_negatives: 2387.0000 - false_positives: 579.0000 - val_loss: 0.3488 - val_auc: 0.9329 - val_binary_accuracy: 0.8557 - val_precision: 0.8412 - val_recall: 0.8565 - val_false_negatives: 102.0000 - val_true_positives: 609.0000 - val_true_negatives: 678.0000 - val_false_positives: 115.0000\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 14ms/step - loss: 0.3649 - auc: 0.9212 - binary_accuracy: 0.8498 - precision: 0.8268 - recall: 0.8901 - false_negatives: 335.0000 - true_positives: 2712.0000 - true_negatives: 2398.0000 - false_positives: 568.0000 - val_loss: 0.3426 - val_auc: 0.9350 - val_binary_accuracy: 0.8557 - val_precision: 0.8356 - val_recall: 0.8650 - val_false_negatives: 96.0000 - val_true_positives: 615.0000 - val_true_negatives: 672.0000 - val_false_positives: 121.0000\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3577 - auc: 0.9241 - binary_accuracy: 0.8508 - precision: 0.8279 - recall: 0.8907 - false_negatives: 333.0000 - true_positives: 2714.0000 - true_negatives: 2402.0000 - false_positives: 564.0000 - val_loss: 0.3548 - val_auc: 0.9327 - val_binary_accuracy: 0.8451 - val_precision: 0.8515 - val_recall: 0.8143 - val_false_negatives: 132.0000 - val_true_positives: 579.0000 - val_true_negatives: 692.0000 - val_false_positives: 101.0000\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3529 - auc: 0.9271 - binary_accuracy: 0.8563 - precision: 0.8366 - recall: 0.8904 - false_negatives: 334.0000 - true_positives: 2713.0000 - true_negatives: 2436.0000 - false_positives: 530.0000 - val_loss: 0.3430 - val_auc: 0.9336 - val_binary_accuracy: 0.8624 - val_precision: 0.8452 - val_recall: 0.8678 - val_false_negatives: 94.0000 - val_true_positives: 617.0000 - val_true_negatives: 680.0000 - val_false_positives: 113.0000\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3551 - auc: 0.9260 - binary_accuracy: 0.8568 - precision: 0.8355 - recall: 0.8933 - false_negatives: 325.0000 - true_positives: 2722.0000 - true_negatives: 2430.0000 - false_positives: 536.0000 - val_loss: 0.3481 - val_auc: 0.9328 - val_binary_accuracy: 0.8531 - val_precision: 0.8470 - val_recall: 0.8411 - val_false_negatives: 113.0000 - val_true_positives: 598.0000 - val_true_negatives: 685.0000 - val_false_positives: 108.0000\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3559 - auc: 0.9253 - binary_accuracy: 0.8533 - precision: 0.8301 - recall: 0.8933 - false_negatives: 325.0000 - true_positives: 2722.0000 - true_negatives: 2409.0000 - false_positives: 557.0000 - val_loss: 0.3380 - val_auc: 0.9362 - val_binary_accuracy: 0.8590 - val_precision: 0.8404 - val_recall: 0.8664 - val_false_negatives: 95.0000 - val_true_positives: 616.0000 - val_true_negatives: 676.0000 - val_false_positives: 117.0000\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3464 - auc: 0.9292 - binary_accuracy: 0.8568 - precision: 0.8328 - recall: 0.8976 - false_negatives: 312.0000 - true_positives: 2735.0000 - true_negatives: 2417.0000 - false_positives: 549.0000 - val_loss: 0.3337 - val_auc: 0.9374 - val_binary_accuracy: 0.8590 - val_precision: 0.8270 - val_recall: 0.8875 - val_false_negatives: 80.0000 - val_true_positives: 631.0000 - val_true_negatives: 661.0000 - val_false_positives: 132.0000\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3474 - auc: 0.9297 - binary_accuracy: 0.8575 - precision: 0.8353 - recall: 0.8953 - false_negatives: 319.0000 - true_positives: 2728.0000 - true_negatives: 2428.0000 - false_positives: 538.0000 - val_loss: 0.3387 - val_auc: 0.9367 - val_binary_accuracy: 0.8624 - val_precision: 0.8529 - val_recall: 0.8565 - val_false_negatives: 102.0000 - val_true_positives: 609.0000 - val_true_negatives: 688.0000 - val_false_positives: 105.0000\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3483 - auc: 0.9290 - binary_accuracy: 0.8571 - precision: 0.8352 - recall: 0.8947 - false_negatives: 321.0000 - true_positives: 2726.0000 - true_negatives: 2428.0000 - false_positives: 538.0000 - val_loss: 0.3333 - val_auc: 0.9380 - val_binary_accuracy: 0.8590 - val_precision: 0.8178 - val_recall: 0.9030 - val_false_negatives: 69.0000 - val_true_positives: 642.0000 - val_true_negatives: 650.0000 - val_false_positives: 143.0000\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.3453 - auc: 0.9308 - binary_accuracy: 0.8595 - precision: 0.8407 - recall: 0.8917 - false_negatives: 330.0000 - true_positives: 2717.0000 - true_negatives: 2451.0000 - false_positives: 515.0000 - val_loss: 0.3456 - val_auc: 0.9354 - val_binary_accuracy: 0.8471 - val_precision: 0.8552 - val_recall: 0.8143 - val_false_negatives: 132.0000 - val_true_positives: 579.0000 - val_true_negatives: 695.0000 - val_false_positives: 98.0000\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3482 - auc: 0.9295 - binary_accuracy: 0.8560 - precision: 0.8367 - recall: 0.8894 - false_negatives: 337.0000 - true_positives: 2710.0000 - true_negatives: 2437.0000 - false_positives: 529.0000 - val_loss: 0.3330 - val_auc: 0.9373 - val_binary_accuracy: 0.8584 - val_precision: 0.8420 - val_recall: 0.8622 - val_false_negatives: 98.0000 - val_true_positives: 613.0000 - val_true_negatives: 678.0000 - val_false_positives: 115.0000\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3387 - auc: 0.9326 - binary_accuracy: 0.8611 - precision: 0.8426 - recall: 0.8927 - false_negatives: 327.0000 - true_positives: 2720.0000 - true_negatives: 2458.0000 - false_positives: 508.0000 - val_loss: 0.3281 - val_auc: 0.9378 - val_binary_accuracy: 0.8630 - val_precision: 0.8389 - val_recall: 0.8790 - val_false_negatives: 86.0000 - val_true_positives: 625.0000 - val_true_negatives: 673.0000 - val_false_positives: 120.0000\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.3374 - auc: 0.9334 - binary_accuracy: 0.8618 - precision: 0.8439 - recall: 0.8924 - false_negatives: 328.0000 - true_positives: 2719.0000 - true_negatives: 2463.0000 - false_positives: 503.0000 - val_loss: 0.3265 - val_auc: 0.9391 - val_binary_accuracy: 0.8650 - val_precision: 0.8470 - val_recall: 0.8720 - val_false_negatives: 91.0000 - val_true_positives: 620.0000 - val_true_negatives: 681.0000 - val_false_positives: 112.0000\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3334 - auc: 0.9349 - binary_accuracy: 0.8616 - precision: 0.8428 - recall: 0.8937 - false_negatives: 324.0000 - true_positives: 2723.0000 - true_negatives: 2458.0000 - false_positives: 508.0000 - val_loss: 0.3362 - val_auc: 0.9379 - val_binary_accuracy: 0.8604 - val_precision: 0.8573 - val_recall: 0.8453 - val_false_negatives: 110.0000 - val_true_positives: 601.0000 - val_true_negatives: 693.0000 - val_false_positives: 100.0000\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3394 - auc: 0.9330 - binary_accuracy: 0.8560 - precision: 0.8365 - recall: 0.8897 - false_negatives: 336.0000 - true_positives: 2711.0000 - true_negatives: 2436.0000 - false_positives: 530.0000 - val_loss: 0.3263 - val_auc: 0.9395 - val_binary_accuracy: 0.8630 - val_precision: 0.8426 - val_recall: 0.8734 - val_false_negatives: 90.0000 - val_true_positives: 621.0000 - val_true_negatives: 677.0000 - val_false_positives: 116.0000\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3355 - auc: 0.9342 - binary_accuracy: 0.8658 - precision: 0.8485 - recall: 0.8950 - false_negatives: 320.0000 - true_positives: 2727.0000 - true_negatives: 2479.0000 - false_positives: 487.0000 - val_loss: 0.3355 - val_auc: 0.9390 - val_binary_accuracy: 0.8557 - val_precision: 0.8569 - val_recall: 0.8340 - val_false_negatives: 118.0000 - val_true_positives: 593.0000 - val_true_negatives: 694.0000 - val_false_positives: 99.0000\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3390 - auc: 0.9332 - binary_accuracy: 0.8605 - precision: 0.8395 - recall: 0.8960 - false_negatives: 317.0000 - true_positives: 2730.0000 - true_negatives: 2444.0000 - false_positives: 522.0000 - val_loss: 0.3274 - val_auc: 0.9388 - val_binary_accuracy: 0.8657 - val_precision: 0.8371 - val_recall: 0.8889 - val_false_negatives: 79.0000 - val_true_positives: 632.0000 - val_true_negatives: 670.0000 - val_false_positives: 123.0000\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3362 - auc: 0.9350 - binary_accuracy: 0.8640 - precision: 0.8471 - recall: 0.8927 - false_negatives: 327.0000 - true_positives: 2720.0000 - true_negatives: 2475.0000 - false_positives: 491.0000 - val_loss: 0.3386 - val_auc: 0.9399 - val_binary_accuracy: 0.8497 - val_precision: 0.8636 - val_recall: 0.8101 - val_false_negatives: 135.0000 - val_true_positives: 576.0000 - val_true_negatives: 702.0000 - val_false_positives: 91.0000\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3400 - auc: 0.9324 - binary_accuracy: 0.8590 - precision: 0.8395 - recall: 0.8924 - false_negatives: 328.0000 - true_positives: 2719.0000 - true_negatives: 2446.0000 - false_positives: 520.0000 - val_loss: 0.3318 - val_auc: 0.9394 - val_binary_accuracy: 0.8590 - val_precision: 0.8490 - val_recall: 0.8537 - val_false_negatives: 104.0000 - val_true_positives: 607.0000 - val_true_negatives: 685.0000 - val_false_positives: 108.0000\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3360 - auc: 0.9339 - binary_accuracy: 0.8615 - precision: 0.8410 - recall: 0.8960 - false_negatives: 317.0000 - true_positives: 2730.0000 - true_negatives: 2450.0000 - false_positives: 516.0000 - val_loss: 0.3218 - val_auc: 0.9408 - val_binary_accuracy: 0.8664 - val_precision: 0.8427 - val_recall: 0.8819 - val_false_negatives: 84.0000 - val_true_positives: 627.0000 - val_true_negatives: 676.0000 - val_false_positives: 117.0000\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3381 - auc: 0.9329 - binary_accuracy: 0.8585 - precision: 0.8410 - recall: 0.8887 - false_negatives: 339.0000 - true_positives: 2708.0000 - true_negatives: 2454.0000 - false_positives: 512.0000 - val_loss: 0.3205 - val_auc: 0.9406 - val_binary_accuracy: 0.8577 - val_precision: 0.8372 - val_recall: 0.8678 - val_false_negatives: 94.0000 - val_true_positives: 617.0000 - val_true_negatives: 673.0000 - val_false_positives: 120.0000\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 1s 15ms/step - loss: 0.3291 - auc: 0.9376 - binary_accuracy: 0.8643 - precision: 0.8461 - recall: 0.8950 - false_negatives: 320.0000 - true_positives: 2727.0000 - true_negatives: 2470.0000 - false_positives: 496.0000 - val_loss: 0.3231 - val_auc: 0.9403 - val_binary_accuracy: 0.8637 - val_precision: 0.8514 - val_recall: 0.8622 - val_false_negatives: 98.0000 - val_true_positives: 613.0000 - val_true_negatives: 686.0000 - val_false_positives: 107.0000\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3316 - auc: 0.9357 - binary_accuracy: 0.8605 - precision: 0.8426 - recall: 0.8910 - false_negatives: 332.0000 - true_positives: 2715.0000 - true_negatives: 2459.0000 - false_positives: 507.0000 - val_loss: 0.3448 - val_auc: 0.9389 - val_binary_accuracy: 0.8438 - val_precision: 0.8719 - val_recall: 0.7848 - val_false_negatives: 153.0000 - val_true_positives: 558.0000 - val_true_negatives: 711.0000 - val_false_positives: 82.0000\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3352 - auc: 0.9348 - binary_accuracy: 0.8621 - precision: 0.8470 - recall: 0.8884 - false_negatives: 340.0000 - true_positives: 2707.0000 - true_negatives: 2477.0000 - false_positives: 489.0000 - val_loss: 0.3211 - val_auc: 0.9410 - val_binary_accuracy: 0.8657 - val_precision: 0.8380 - val_recall: 0.8875 - val_false_negatives: 80.0000 - val_true_positives: 631.0000 - val_true_negatives: 671.0000 - val_false_positives: 122.0000\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 1s 16ms/step - loss: 0.3314 - auc: 0.9364 - binary_accuracy: 0.8623 - precision: 0.8417 - recall: 0.8969 - false_negatives: 314.0000 - true_positives: 2733.0000 - true_negatives: 2452.0000 - false_positives: 514.0000 - val_loss: 0.3279 - val_auc: 0.9397 - val_binary_accuracy: 0.8610 - val_precision: 0.8545 - val_recall: 0.8509 - val_false_negatives: 106.0000 - val_true_positives: 605.0000 - val_true_negatives: 690.0000 - val_false_positives: 103.0000\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3297 - auc: 0.9372 - binary_accuracy: 0.8618 - precision: 0.8426 - recall: 0.8943 - false_negatives: 322.0000 - true_positives: 2725.0000 - true_negatives: 2457.0000 - false_positives: 509.0000 - val_loss: 0.3200 - val_auc: 0.9417 - val_binary_accuracy: 0.8684 - val_precision: 0.8406 - val_recall: 0.8903 - val_false_negatives: 78.0000 - val_true_positives: 633.0000 - val_true_negatives: 673.0000 - val_false_positives: 120.0000\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3295 - auc: 0.9370 - binary_accuracy: 0.8641 - precision: 0.8443 - recall: 0.8973 - false_negatives: 313.0000 - true_positives: 2734.0000 - true_negatives: 2462.0000 - false_positives: 504.0000 - val_loss: 0.3200 - val_auc: 0.9421 - val_binary_accuracy: 0.8677 - val_precision: 0.8516 - val_recall: 0.8720 - val_false_negatives: 91.0000 - val_true_positives: 620.0000 - val_true_negatives: 685.0000 - val_false_positives: 108.0000\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.3287 - auc: 0.9367 - binary_accuracy: 0.8606 - precision: 0.8393 - recall: 0.8966 - false_negatives: 315.0000 - true_positives: 2732.0000 - true_negatives: 2443.0000 - false_positives: 523.0000 - val_loss: 0.3240 - val_auc: 0.9417 - val_binary_accuracy: 0.8697 - val_precision: 0.8503 - val_recall: 0.8790 - val_false_negatives: 86.0000 - val_true_positives: 625.0000 - val_true_negatives: 683.0000 - val_false_positives: 110.0000\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3226 - auc: 0.9398 - binary_accuracy: 0.8698 - precision: 0.8502 - recall: 0.9019 - false_negatives: 299.0000 - true_positives: 2748.0000 - true_negatives: 2482.0000 - false_positives: 484.0000 - val_loss: 0.3180 - val_auc: 0.9422 - val_binary_accuracy: 0.8690 - val_precision: 0.8346 - val_recall: 0.9015 - val_false_negatives: 70.0000 - val_true_positives: 641.0000 - val_true_negatives: 666.0000 - val_false_positives: 127.0000\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.3236 - auc: 0.9388 - binary_accuracy: 0.8651 - precision: 0.8496 - recall: 0.8917 - false_negatives: 330.0000 - true_positives: 2717.0000 - true_negatives: 2485.0000 - false_positives: 481.0000 - val_loss: 0.3246 - val_auc: 0.9421 - val_binary_accuracy: 0.8657 - val_precision: 0.8631 - val_recall: 0.8509 - val_false_negatives: 106.0000 - val_true_positives: 605.0000 - val_true_negatives: 697.0000 - val_false_positives: 96.0000\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.3269 - auc: 0.9380 - binary_accuracy: 0.8655 - precision: 0.8443 - recall: 0.9006 - false_negatives: 303.0000 - true_positives: 2744.0000 - true_negatives: 2460.0000 - false_positives: 506.0000 - val_loss: 0.3147 - val_auc: 0.9422 - val_binary_accuracy: 0.8743 - val_precision: 0.8407 - val_recall: 0.9058 - val_false_negatives: 67.0000 - val_true_positives: 644.0000 - val_true_negatives: 671.0000 - val_false_positives: 122.0000\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3261 - auc: 0.9385 - binary_accuracy: 0.8658 - precision: 0.8463 - recall: 0.8983 - false_negatives: 310.0000 - true_positives: 2737.0000 - true_negatives: 2469.0000 - false_positives: 497.0000 - val_loss: 0.3351 - val_auc: 0.9413 - val_binary_accuracy: 0.8524 - val_precision: 0.8633 - val_recall: 0.8172 - val_false_negatives: 130.0000 - val_true_positives: 581.0000 - val_true_negatives: 701.0000 - val_false_positives: 92.0000\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3303 - auc: 0.9367 - binary_accuracy: 0.8641 - precision: 0.8439 - recall: 0.8979 - false_negatives: 311.0000 - true_positives: 2736.0000 - true_negatives: 2460.0000 - false_positives: 506.0000 - val_loss: 0.3252 - val_auc: 0.9428 - val_binary_accuracy: 0.8684 - val_precision: 0.8659 - val_recall: 0.8537 - val_false_negatives: 104.0000 - val_true_positives: 607.0000 - val_true_negatives: 699.0000 - val_false_positives: 94.0000\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3254 - auc: 0.9376 - binary_accuracy: 0.8630 - precision: 0.8425 - recall: 0.8973 - false_negatives: 313.0000 - true_positives: 2734.0000 - true_negatives: 2455.0000 - false_positives: 511.0000 - val_loss: 0.3226 - val_auc: 0.9417 - val_binary_accuracy: 0.8677 - val_precision: 0.8536 - val_recall: 0.8692 - val_false_negatives: 93.0000 - val_true_positives: 618.0000 - val_true_negatives: 687.0000 - val_false_positives: 106.0000\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3252 - auc: 0.9392 - binary_accuracy: 0.8665 - precision: 0.8484 - recall: 0.8966 - false_negatives: 315.0000 - true_positives: 2732.0000 - true_negatives: 2478.0000 - false_positives: 488.0000 - val_loss: 0.3217 - val_auc: 0.9423 - val_binary_accuracy: 0.8624 - val_precision: 0.8549 - val_recall: 0.8537 - val_false_negatives: 104.0000 - val_true_positives: 607.0000 - val_true_negatives: 690.0000 - val_false_positives: 103.0000\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3199 - auc: 0.9400 - binary_accuracy: 0.8643 - precision: 0.8442 - recall: 0.8979 - false_negatives: 311.0000 - true_positives: 2736.0000 - true_negatives: 2461.0000 - false_positives: 505.0000 - val_loss: 0.3181 - val_auc: 0.9426 - val_binary_accuracy: 0.8697 - val_precision: 0.8494 - val_recall: 0.8805 - val_false_negatives: 85.0000 - val_true_positives: 626.0000 - val_true_negatives: 682.0000 - val_false_positives: 111.0000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.3805 - auc: 0.0000e+00 - binary_accuracy: 0.8438 - precision: 0.0000e+00 - recall: 0.0000e+00 - false_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 27.0000 - false_positives: 5.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0123s). Check your callbacks.\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.3499 - auc: 0.8334 - binary_accuracy: 0.8360 - precision: 0.1479 - recall: 0.5952 - false_negatives: 17.0000 - true_positives: 25.0000 - true_negatives: 796.0000 - false_positives: 144.0000       \n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_31), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer_31/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 2s 43ms/step - loss: 0.5531 - auc: 0.7839 - binary_accuracy: 0.7194 - precision: 0.7012 - recall: 0.7778 - false_negatives: 677.0000 - true_positives: 2370.0000 - true_negatives: 1956.0000 - false_positives: 1010.0000 - val_loss: 0.5092 - val_auc: 0.8691 - val_binary_accuracy: 0.8105 - val_precision: 0.7610 - val_recall: 0.8734 - val_false_negatives: 90.0000 - val_true_positives: 621.0000 - val_true_negatives: 598.0000 - val_false_positives: 195.0000\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4849 - auc: 0.8342 - binary_accuracy: 0.7805 - precision: 0.7414 - recall: 0.8704 - false_negatives: 395.0000 - true_positives: 2652.0000 - true_negatives: 2041.0000 - false_positives: 925.0000 - val_loss: 0.4866 - val_auc: 0.8751 - val_binary_accuracy: 0.8125 - val_precision: 0.7569 - val_recall: 0.8889 - val_false_negatives: 79.0000 - val_true_positives: 632.0000 - val_true_negatives: 590.0000 - val_false_positives: 203.0000\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4668 - auc: 0.8486 - binary_accuracy: 0.7855 - precision: 0.7459 - recall: 0.8746 - false_negatives: 382.0000 - true_positives: 2665.0000 - true_negatives: 2058.0000 - false_positives: 908.0000 - val_loss: 0.4609 - val_auc: 0.8785 - val_binary_accuracy: 0.8172 - val_precision: 0.7639 - val_recall: 0.8875 - val_false_negatives: 80.0000 - val_true_positives: 631.0000 - val_true_negatives: 598.0000 - val_false_positives: 195.0000\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.4533 - auc: 0.8592 - binary_accuracy: 0.8016 - precision: 0.7600 - recall: 0.8894 - false_negatives: 337.0000 - true_positives: 2710.0000 - true_negatives: 2110.0000 - false_positives: 856.0000 - val_loss: 0.4358 - val_auc: 0.8856 - val_binary_accuracy: 0.8211 - val_precision: 0.7669 - val_recall: 0.8931 - val_false_negatives: 76.0000 - val_true_positives: 635.0000 - val_true_negatives: 600.0000 - val_false_positives: 193.0000\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.4433 - auc: 0.8692 - binary_accuracy: 0.8119 - precision: 0.7719 - recall: 0.8927 - false_negatives: 327.0000 - true_positives: 2720.0000 - true_negatives: 2162.0000 - false_positives: 804.0000 - val_loss: 0.4210 - val_auc: 0.8913 - val_binary_accuracy: 0.8285 - val_precision: 0.7807 - val_recall: 0.8861 - val_false_negatives: 81.0000 - val_true_positives: 630.0000 - val_true_negatives: 616.0000 - val_false_positives: 177.0000\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.4334 - auc: 0.8762 - binary_accuracy: 0.8192 - precision: 0.7808 - recall: 0.8943 - false_negatives: 322.0000 - true_positives: 2725.0000 - true_negatives: 2201.0000 - false_positives: 765.0000 - val_loss: 0.4116 - val_auc: 0.8978 - val_binary_accuracy: 0.8318 - val_precision: 0.7800 - val_recall: 0.8973 - val_false_negatives: 73.0000 - val_true_positives: 638.0000 - val_true_negatives: 613.0000 - val_false_positives: 180.0000\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.4154 - auc: 0.8923 - binary_accuracy: 0.8307 - precision: 0.7919 - recall: 0.9032 - false_negatives: 295.0000 - true_positives: 2752.0000 - true_negatives: 2243.0000 - false_positives: 723.0000 - val_loss: 0.3929 - val_auc: 0.9124 - val_binary_accuracy: 0.8438 - val_precision: 0.8043 - val_recall: 0.8847 - val_false_negatives: 82.0000 - val_true_positives: 629.0000 - val_true_negatives: 640.0000 - val_false_positives: 153.0000\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.4049 - auc: 0.8995 - binary_accuracy: 0.8327 - precision: 0.7995 - recall: 0.8940 - false_negatives: 323.0000 - true_positives: 2724.0000 - true_negatives: 2283.0000 - false_positives: 683.0000 - val_loss: 0.3809 - val_auc: 0.9193 - val_binary_accuracy: 0.8457 - val_precision: 0.8139 - val_recall: 0.8734 - val_false_negatives: 90.0000 - val_true_positives: 621.0000 - val_true_negatives: 651.0000 - val_false_positives: 142.0000\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 1s 16ms/step - loss: 0.4005 - auc: 0.9049 - binary_accuracy: 0.8362 - precision: 0.8043 - recall: 0.8943 - false_negatives: 322.0000 - true_positives: 2725.0000 - true_negatives: 2303.0000 - false_positives: 663.0000 - val_loss: 0.3766 - val_auc: 0.9264 - val_binary_accuracy: 0.8471 - val_precision: 0.8373 - val_recall: 0.8397 - val_false_negatives: 114.0000 - val_true_positives: 597.0000 - val_true_negatives: 677.0000 - val_false_positives: 116.0000\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.3838 - auc: 0.9114 - binary_accuracy: 0.8478 - precision: 0.8176 - recall: 0.9006 - false_negatives: 303.0000 - true_positives: 2744.0000 - true_negatives: 2354.0000 - false_positives: 612.0000 - val_loss: 0.3606 - val_auc: 0.9292 - val_binary_accuracy: 0.8551 - val_precision: 0.8148 - val_recall: 0.8973 - val_false_negatives: 73.0000 - val_true_positives: 638.0000 - val_true_negatives: 648.0000 - val_false_positives: 145.0000\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3795 - auc: 0.9129 - binary_accuracy: 0.8493 - precision: 0.8212 - recall: 0.8983 - false_negatives: 310.0000 - true_positives: 2737.0000 - true_negatives: 2370.0000 - false_positives: 596.0000 - val_loss: 0.3617 - val_auc: 0.9274 - val_binary_accuracy: 0.8531 - val_precision: 0.8338 - val_recall: 0.8608 - val_false_negatives: 99.0000 - val_true_positives: 612.0000 - val_true_negatives: 671.0000 - val_false_positives: 122.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3755 - auc: 0.9171 - binary_accuracy: 0.8480 - precision: 0.8213 - recall: 0.8947 - false_negatives: 321.0000 - true_positives: 2726.0000 - true_negatives: 2373.0000 - false_positives: 593.0000 - val_loss: 0.3542 - val_auc: 0.9308 - val_binary_accuracy: 0.8564 - val_precision: 0.8414 - val_recall: 0.8579 - val_false_negatives: 101.0000 - val_true_positives: 610.0000 - val_true_negatives: 678.0000 - val_false_positives: 115.0000\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3704 - auc: 0.9196 - binary_accuracy: 0.8490 - precision: 0.8272 - recall: 0.8874 - false_negatives: 343.0000 - true_positives: 2704.0000 - true_negatives: 2401.0000 - false_positives: 565.0000 - val_loss: 0.3615 - val_auc: 0.9296 - val_binary_accuracy: 0.8477 - val_precision: 0.8473 - val_recall: 0.8270 - val_false_negatives: 123.0000 - val_true_positives: 588.0000 - val_true_negatives: 687.0000 - val_false_positives: 106.0000\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3638 - auc: 0.9223 - binary_accuracy: 0.8507 - precision: 0.8283 - recall: 0.8897 - false_negatives: 336.0000 - true_positives: 2711.0000 - true_negatives: 2404.0000 - false_positives: 562.0000 - val_loss: 0.3485 - val_auc: 0.9316 - val_binary_accuracy: 0.8544 - val_precision: 0.8237 - val_recall: 0.8805 - val_false_negatives: 85.0000 - val_true_positives: 626.0000 - val_true_negatives: 659.0000 - val_false_positives: 134.0000\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3664 - auc: 0.9205 - binary_accuracy: 0.8517 - precision: 0.8266 - recall: 0.8950 - false_negatives: 320.0000 - true_positives: 2727.0000 - true_negatives: 2394.0000 - false_positives: 572.0000 - val_loss: 0.3490 - val_auc: 0.9324 - val_binary_accuracy: 0.8504 - val_precision: 0.8423 - val_recall: 0.8411 - val_false_negatives: 113.0000 - val_true_positives: 598.0000 - val_true_negatives: 681.0000 - val_false_positives: 112.0000\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3627 - auc: 0.9214 - binary_accuracy: 0.8513 - precision: 0.8263 - recall: 0.8947 - false_negatives: 321.0000 - true_positives: 2726.0000 - true_negatives: 2393.0000 - false_positives: 573.0000 - val_loss: 0.3395 - val_auc: 0.9354 - val_binary_accuracy: 0.8604 - val_precision: 0.8353 - val_recall: 0.8776 - val_false_negatives: 87.0000 - val_true_positives: 624.0000 - val_true_negatives: 670.0000 - val_false_positives: 123.0000\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3568 - auc: 0.9250 - binary_accuracy: 0.8553 - precision: 0.8330 - recall: 0.8937 - false_negatives: 324.0000 - true_positives: 2723.0000 - true_negatives: 2420.0000 - false_positives: 546.0000 - val_loss: 0.3450 - val_auc: 0.9330 - val_binary_accuracy: 0.8537 - val_precision: 0.8424 - val_recall: 0.8495 - val_false_negatives: 107.0000 - val_true_positives: 604.0000 - val_true_negatives: 680.0000 - val_false_positives: 113.0000\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3526 - auc: 0.9271 - binary_accuracy: 0.8608 - precision: 0.8390 - recall: 0.8976 - false_negatives: 312.0000 - true_positives: 2735.0000 - true_negatives: 2441.0000 - false_positives: 525.0000 - val_loss: 0.3393 - val_auc: 0.9351 - val_binary_accuracy: 0.8577 - val_precision: 0.8381 - val_recall: 0.8664 - val_false_negatives: 95.0000 - val_true_positives: 616.0000 - val_true_negatives: 674.0000 - val_false_positives: 119.0000\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3532 - auc: 0.9264 - binary_accuracy: 0.8535 - precision: 0.8334 - recall: 0.8884 - false_negatives: 340.0000 - true_positives: 2707.0000 - true_negatives: 2425.0000 - false_positives: 541.0000 - val_loss: 0.3513 - val_auc: 0.9335 - val_binary_accuracy: 0.8477 - val_precision: 0.8503 - val_recall: 0.8228 - val_false_negatives: 126.0000 - val_true_positives: 585.0000 - val_true_negatives: 690.0000 - val_false_positives: 103.0000\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3510 - auc: 0.9282 - binary_accuracy: 0.8543 - precision: 0.8325 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2419.0000 - false_positives: 547.0000 - val_loss: 0.3431 - val_auc: 0.9344 - val_binary_accuracy: 0.8590 - val_precision: 0.8460 - val_recall: 0.8579 - val_false_negatives: 101.0000 - val_true_positives: 610.0000 - val_true_negatives: 682.0000 - val_false_positives: 111.0000\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3541 - auc: 0.9261 - binary_accuracy: 0.8525 - precision: 0.8311 - recall: 0.8897 - false_negatives: 336.0000 - true_positives: 2711.0000 - true_negatives: 2415.0000 - false_positives: 551.0000 - val_loss: 0.3369 - val_auc: 0.9361 - val_binary_accuracy: 0.8590 - val_precision: 0.8279 - val_recall: 0.8861 - val_false_negatives: 81.0000 - val_true_positives: 630.0000 - val_true_negatives: 662.0000 - val_false_positives: 131.0000\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3479 - auc: 0.9298 - binary_accuracy: 0.8581 - precision: 0.8371 - recall: 0.8940 - false_negatives: 323.0000 - true_positives: 2724.0000 - true_negatives: 2436.0000 - false_positives: 530.0000 - val_loss: 0.3528 - val_auc: 0.9349 - val_binary_accuracy: 0.8438 - val_precision: 0.8606 - val_recall: 0.7989 - val_false_negatives: 143.0000 - val_true_positives: 568.0000 - val_true_negatives: 701.0000 - val_false_positives: 92.0000\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3442 - auc: 0.9320 - binary_accuracy: 0.8590 - precision: 0.8397 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2447.0000 - false_positives: 519.0000 - val_loss: 0.3375 - val_auc: 0.9367 - val_binary_accuracy: 0.8597 - val_precision: 0.8482 - val_recall: 0.8565 - val_false_negatives: 102.0000 - val_true_positives: 609.0000 - val_true_negatives: 684.0000 - val_false_positives: 109.0000\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3442 - auc: 0.9304 - binary_accuracy: 0.8586 - precision: 0.8377 - recall: 0.8943 - false_negatives: 322.0000 - true_positives: 2725.0000 - true_negatives: 2438.0000 - false_positives: 528.0000 - val_loss: 0.3321 - val_auc: 0.9373 - val_binary_accuracy: 0.8617 - val_precision: 0.8412 - val_recall: 0.8720 - val_false_negatives: 91.0000 - val_true_positives: 620.0000 - val_true_negatives: 676.0000 - val_false_positives: 117.0000\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3431 - auc: 0.9308 - binary_accuracy: 0.8563 - precision: 0.8349 - recall: 0.8930 - false_negatives: 326.0000 - true_positives: 2721.0000 - true_negatives: 2428.0000 - false_positives: 538.0000 - val_loss: 0.3323 - val_auc: 0.9372 - val_binary_accuracy: 0.8630 - val_precision: 0.8398 - val_recall: 0.8776 - val_false_negatives: 87.0000 - val_true_positives: 624.0000 - val_true_negatives: 674.0000 - val_false_positives: 119.0000\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3494 - auc: 0.9281 - binary_accuracy: 0.8537 - precision: 0.8333 - recall: 0.8891 - false_negatives: 338.0000 - true_positives: 2709.0000 - true_negatives: 2424.0000 - false_positives: 542.0000 - val_loss: 0.3490 - val_auc: 0.9360 - val_binary_accuracy: 0.8511 - val_precision: 0.8662 - val_recall: 0.8101 - val_false_negatives: 135.0000 - val_true_positives: 576.0000 - val_true_negatives: 704.0000 - val_false_positives: 89.0000\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3405 - auc: 0.9327 - binary_accuracy: 0.8563 - precision: 0.8349 - recall: 0.8930 - false_negatives: 326.0000 - true_positives: 2721.0000 - true_negatives: 2428.0000 - false_positives: 538.0000 - val_loss: 0.3284 - val_auc: 0.9395 - val_binary_accuracy: 0.8657 - val_precision: 0.8453 - val_recall: 0.8762 - val_false_negatives: 88.0000 - val_true_positives: 623.0000 - val_true_negatives: 679.0000 - val_false_positives: 114.0000\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3427 - auc: 0.9320 - binary_accuracy: 0.8606 - precision: 0.8400 - recall: 0.8956 - false_negatives: 318.0000 - true_positives: 2729.0000 - true_negatives: 2446.0000 - false_positives: 520.0000 - val_loss: 0.3539 - val_auc: 0.9376 - val_binary_accuracy: 0.8358 - val_precision: 0.8718 - val_recall: 0.7651 - val_false_negatives: 167.0000 - val_true_positives: 544.0000 - val_true_negatives: 713.0000 - val_false_positives: 80.0000\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3366 - auc: 0.9335 - binary_accuracy: 0.8571 - precision: 0.8391 - recall: 0.8884 - false_negatives: 340.0000 - true_positives: 2707.0000 - true_negatives: 2447.0000 - false_positives: 519.0000 - val_loss: 0.3351 - val_auc: 0.9377 - val_binary_accuracy: 0.8617 - val_precision: 0.8557 - val_recall: 0.8509 - val_false_negatives: 106.0000 - val_true_positives: 605.0000 - val_true_negatives: 691.0000 - val_false_positives: 102.0000\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3374 - auc: 0.9337 - binary_accuracy: 0.8606 - precision: 0.8423 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2457.0000 - false_positives: 509.0000 - val_loss: 0.3287 - val_auc: 0.9386 - val_binary_accuracy: 0.8650 - val_precision: 0.8405 - val_recall: 0.8819 - val_false_negatives: 84.0000 - val_true_positives: 627.0000 - val_true_negatives: 674.0000 - val_false_positives: 119.0000\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3406 - auc: 0.9330 - binary_accuracy: 0.8598 - precision: 0.8418 - recall: 0.8907 - false_negatives: 333.0000 - true_positives: 2714.0000 - true_negatives: 2456.0000 - false_positives: 510.0000 - val_loss: 0.3440 - val_auc: 0.9384 - val_binary_accuracy: 0.8511 - val_precision: 0.8597 - val_recall: 0.8186 - val_false_negatives: 129.0000 - val_true_positives: 582.0000 - val_true_negatives: 698.0000 - val_false_positives: 95.0000\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3391 - auc: 0.9333 - binary_accuracy: 0.8580 - precision: 0.8381 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2441.0000 - false_positives: 525.0000 - val_loss: 0.3276 - val_auc: 0.9390 - val_binary_accuracy: 0.8664 - val_precision: 0.8418 - val_recall: 0.8833 - val_false_negatives: 83.0000 - val_true_positives: 628.0000 - val_true_negatives: 675.0000 - val_false_positives: 118.0000\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3333 - auc: 0.9353 - binary_accuracy: 0.8590 - precision: 0.8424 - recall: 0.8878 - false_negatives: 342.0000 - true_positives: 2705.0000 - true_negatives: 2460.0000 - false_positives: 506.0000 - val_loss: 0.3305 - val_auc: 0.9387 - val_binary_accuracy: 0.8617 - val_precision: 0.8488 - val_recall: 0.8608 - val_false_negatives: 99.0000 - val_true_positives: 612.0000 - val_true_negatives: 684.0000 - val_false_positives: 109.0000\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3352 - auc: 0.9342 - binary_accuracy: 0.8600 - precision: 0.8368 - recall: 0.8989 - false_negatives: 308.0000 - true_positives: 2739.0000 - true_negatives: 2432.0000 - false_positives: 534.0000 - val_loss: 0.3229 - val_auc: 0.9398 - val_binary_accuracy: 0.8664 - val_precision: 0.8409 - val_recall: 0.8847 - val_false_negatives: 82.0000 - val_true_positives: 629.0000 - val_true_negatives: 674.0000 - val_false_positives: 119.0000\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3304 - auc: 0.9364 - binary_accuracy: 0.8611 - precision: 0.8418 - recall: 0.8940 - false_negatives: 323.0000 - true_positives: 2724.0000 - true_negatives: 2454.0000 - false_positives: 512.0000 - val_loss: 0.3240 - val_auc: 0.9395 - val_binary_accuracy: 0.8664 - val_precision: 0.8437 - val_recall: 0.8805 - val_false_negatives: 85.0000 - val_true_positives: 626.0000 - val_true_negatives: 677.0000 - val_false_positives: 116.0000\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3336 - auc: 0.9355 - binary_accuracy: 0.8631 - precision: 0.8441 - recall: 0.8953 - false_negatives: 319.0000 - true_positives: 2728.0000 - true_negatives: 2462.0000 - false_positives: 504.0000 - val_loss: 0.3413 - val_auc: 0.9390 - val_binary_accuracy: 0.8557 - val_precision: 0.8698 - val_recall: 0.8172 - val_false_negatives: 130.0000 - val_true_positives: 581.0000 - val_true_negatives: 706.0000 - val_false_positives: 87.0000\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.3288 - auc: 0.9367 - binary_accuracy: 0.8651 - precision: 0.8463 - recall: 0.8966 - false_negatives: 315.0000 - true_positives: 2732.0000 - true_negatives: 2470.0000 - false_positives: 496.0000 - val_loss: 0.3221 - val_auc: 0.9410 - val_binary_accuracy: 0.8637 - val_precision: 0.8456 - val_recall: 0.8706 - val_false_negatives: 92.0000 - val_true_positives: 619.0000 - val_true_negatives: 680.0000 - val_false_positives: 113.0000\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.3291 - auc: 0.9377 - binary_accuracy: 0.8616 - precision: 0.8430 - recall: 0.8933 - false_negatives: 325.0000 - true_positives: 2722.0000 - true_negatives: 2459.0000 - false_positives: 507.0000 - val_loss: 0.3297 - val_auc: 0.9389 - val_binary_accuracy: 0.8637 - val_precision: 0.8584 - val_recall: 0.8523 - val_false_negatives: 105.0000 - val_true_positives: 606.0000 - val_true_negatives: 693.0000 - val_false_positives: 100.00000.9349 - binary_accuracy: 0.8634 - precision: 0.8487 - recall: 0.8944 - false_negatives: 202.0000 - true_positives: 1711.0000 - true_negatives: 1494.0000 - false_positives\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3366 - auc: 0.9331 - binary_accuracy: 0.8628 - precision: 0.8423 - recall: 0.8973 - false_negatives: 313.0000 - true_positives: 2734.0000 - true_negatives: 2454.0000 - false_positives: 512.0000 - val_loss: 0.3246 - val_auc: 0.9396 - val_binary_accuracy: 0.8670 - val_precision: 0.8457 - val_recall: 0.8790 - val_false_negatives: 86.0000 - val_true_positives: 625.0000 - val_true_negatives: 679.0000 - val_false_positives: 114.0000\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3308 - auc: 0.9365 - binary_accuracy: 0.8616 - precision: 0.8421 - recall: 0.8947 - false_negatives: 321.0000 - true_positives: 2726.0000 - true_negatives: 2455.0000 - false_positives: 511.0000 - val_loss: 0.3330 - val_auc: 0.9401 - val_binary_accuracy: 0.8630 - val_precision: 0.8623 - val_recall: 0.8453 - val_false_negatives: 110.0000 - val_true_positives: 601.0000 - val_true_negatives: 697.0000 - val_false_positives: 96.0000\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3241 - auc: 0.9390 - binary_accuracy: 0.8641 - precision: 0.8465 - recall: 0.8940 - false_negatives: 323.0000 - true_positives: 2724.0000 - true_negatives: 2472.0000 - false_positives: 494.0000 - val_loss: 0.3191 - val_auc: 0.9408 - val_binary_accuracy: 0.8697 - val_precision: 0.8357 - val_recall: 0.9015 - val_false_negatives: 70.0000 - val_true_positives: 641.0000 - val_true_negatives: 667.0000 - val_false_positives: 126.0000\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3280 - auc: 0.9366 - binary_accuracy: 0.8610 - precision: 0.8396 - recall: 0.8969 - false_negatives: 314.0000 - true_positives: 2733.0000 - true_negatives: 2444.0000 - false_positives: 522.0000 - val_loss: 0.3192 - val_auc: 0.9409 - val_binary_accuracy: 0.8637 - val_precision: 0.8303 - val_recall: 0.8945 - val_false_negatives: 75.0000 - val_true_positives: 636.0000 - val_true_negatives: 663.0000 - val_false_positives: 130.0000\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3246 - auc: 0.9384 - binary_accuracy: 0.8636 - precision: 0.8466 - recall: 0.8927 - false_negatives: 327.0000 - true_positives: 2720.0000 - true_negatives: 2473.0000 - false_positives: 493.0000 - val_loss: 0.3345 - val_auc: 0.9397 - val_binary_accuracy: 0.8544 - val_precision: 0.8514 - val_recall: 0.8383 - val_false_negatives: 115.0000 - val_true_positives: 596.0000 - val_true_negatives: 689.0000 - val_false_positives: 104.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3333 - auc: 0.9349 - binary_accuracy: 0.8663 - precision: 0.8458 - recall: 0.9002 - false_negatives: 304.0000 - true_positives: 2743.0000 - true_negatives: 2466.0000 - false_positives: 500.0000 - val_loss: 0.3288 - val_auc: 0.9408 - val_binary_accuracy: 0.8584 - val_precision: 0.8537 - val_recall: 0.8453 - val_false_negatives: 110.0000 - val_true_positives: 601.0000 - val_true_negatives: 690.0000 - val_false_positives: 103.0000\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.3233 - auc: 0.9397 - binary_accuracy: 0.8660 - precision: 0.8474 - recall: 0.8969 - false_negatives: 314.0000 - true_positives: 2733.0000 - true_negatives: 2474.0000 - false_positives: 492.0000 - val_loss: 0.3235 - val_auc: 0.9401 - val_binary_accuracy: 0.8637 - val_precision: 0.8504 - val_recall: 0.8636 - val_false_negatives: 97.0000 - val_true_positives: 614.0000 - val_true_negatives: 685.0000 - val_false_positives: 108.0000\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3261 - auc: 0.9383 - binary_accuracy: 0.8596 - precision: 0.8407 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2451.0000 - false_positives: 515.0000 - val_loss: 0.3251 - val_auc: 0.9404 - val_binary_accuracy: 0.8644 - val_precision: 0.8497 - val_recall: 0.8664 - val_false_negatives: 95.0000 - val_true_positives: 616.0000 - val_true_negatives: 684.0000 - val_false_positives: 109.0000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.3526 - auc: 0.8319 - binary_accuracy: 0.8340 - precision: 0.1503 - recall: 0.6190 - false_negatives: 16.0000 - true_positives: 26.0000 - true_negatives: 793.0000 - false_positives: 147.0000         \n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_32), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer_32/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 2s 38ms/step - loss: 0.5557 - auc: 0.7793 - binary_accuracy: 0.7051 - precision: 0.6890 - recall: 0.7621 - false_negatives: 725.0000 - true_positives: 2322.0000 - true_negatives: 1918.0000 - false_positives: 1048.0000 - val_loss: 0.5087 - val_auc: 0.8699 - val_binary_accuracy: 0.8092 - val_precision: 0.7542 - val_recall: 0.8847 - val_false_negatives: 82.0000 - val_true_positives: 629.0000 - val_true_negatives: 588.0000 - val_false_positives: 205.0000\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4773 - auc: 0.8382 - binary_accuracy: 0.7803 - precision: 0.7438 - recall: 0.8641 - false_negatives: 414.0000 - true_positives: 2633.0000 - true_negatives: 2059.0000 - false_positives: 907.0000 - val_loss: 0.4843 - val_auc: 0.8710 - val_binary_accuracy: 0.8078 - val_precision: 0.7482 - val_recall: 0.8945 - val_false_negatives: 75.0000 - val_true_positives: 636.0000 - val_true_negatives: 579.0000 - val_false_positives: 214.0000\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.4613 - auc: 0.8504 - binary_accuracy: 0.7858 - precision: 0.7462 - recall: 0.8750 - false_negatives: 381.0000 - true_positives: 2666.0000 - true_negatives: 2059.0000 - false_positives: 907.0000 - val_loss: 0.4661 - val_auc: 0.8739 - val_binary_accuracy: 0.8172 - val_precision: 0.7608 - val_recall: 0.8945 - val_false_negatives: 75.0000 - val_true_positives: 636.0000 - val_true_negatives: 593.0000 - val_false_positives: 200.0000\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4532 - auc: 0.8595 - binary_accuracy: 0.8036 - precision: 0.7645 - recall: 0.8851 - false_negatives: 350.0000 - true_positives: 2697.0000 - true_negatives: 2135.0000 - false_positives: 831.0000 - val_loss: 0.4455 - val_auc: 0.8820 - val_binary_accuracy: 0.8198 - val_precision: 0.7657 - val_recall: 0.8917 - val_false_negatives: 77.0000 - val_true_positives: 634.0000 - val_true_negatives: 599.0000 - val_false_positives: 194.0000\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4385 - auc: 0.8728 - binary_accuracy: 0.8084 - precision: 0.7714 - recall: 0.8838 - false_negatives: 354.0000 - true_positives: 2693.0000 - true_negatives: 2168.0000 - false_positives: 798.0000 - val_loss: 0.4218 - val_auc: 0.8945 - val_binary_accuracy: 0.8311 - val_precision: 0.7831 - val_recall: 0.8889 - val_false_negatives: 79.0000 - val_true_positives: 632.0000 - val_true_negatives: 618.0000 - val_false_positives: 175.0000\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4304 - auc: 0.8824 - binary_accuracy: 0.8166 - precision: 0.7779 - recall: 0.8930 - false_negatives: 326.0000 - true_positives: 2721.0000 - true_negatives: 2189.0000 - false_positives: 777.0000 - val_loss: 0.4079 - val_auc: 0.9050 - val_binary_accuracy: 0.8371 - val_precision: 0.7855 - val_recall: 0.9015 - val_false_negatives: 70.0000 - val_true_positives: 641.0000 - val_true_negatives: 618.0000 - val_false_positives: 175.0000\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4227 - auc: 0.8916 - binary_accuracy: 0.8274 - precision: 0.7938 - recall: 0.8907 - false_negatives: 333.0000 - true_positives: 2714.0000 - true_negatives: 2261.0000 - false_positives: 705.0000 - val_loss: 0.3937 - val_auc: 0.9170 - val_binary_accuracy: 0.8404 - val_precision: 0.7947 - val_recall: 0.8931 - val_false_negatives: 76.0000 - val_true_positives: 635.0000 - val_true_negatives: 629.0000 - val_false_positives: 164.0000\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3921 - auc: 0.9087 - binary_accuracy: 0.8379 - precision: 0.8063 - recall: 0.8950 - false_negatives: 320.0000 - true_positives: 2727.0000 - true_negatives: 2311.0000 - false_positives: 655.0000 - val_loss: 0.3725 - val_auc: 0.9260 - val_binary_accuracy: 0.8511 - val_precision: 0.8134 - val_recall: 0.8889 - val_false_negatives: 79.0000 - val_true_positives: 632.0000 - val_true_negatives: 648.0000 - val_false_positives: 145.0000\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3939 - auc: 0.9099 - binary_accuracy: 0.8422 - precision: 0.8107 - recall: 0.8983 - false_negatives: 310.0000 - true_positives: 2737.0000 - true_negatives: 2327.0000 - false_positives: 639.0000 - val_loss: 0.3661 - val_auc: 0.9292 - val_binary_accuracy: 0.8537 - val_precision: 0.8269 - val_recall: 0.8734 - val_false_negatives: 90.0000 - val_true_positives: 621.0000 - val_true_negatives: 663.0000 - val_false_positives: 130.0000\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3828 - auc: 0.9139 - binary_accuracy: 0.8472 - precision: 0.8199 - recall: 0.8950 - false_negatives: 320.0000 - true_positives: 2727.0000 - true_negatives: 2367.0000 - false_positives: 599.0000 - val_loss: 0.3624 - val_auc: 0.9288 - val_binary_accuracy: 0.8537 - val_precision: 0.8168 - val_recall: 0.8903 - val_false_negatives: 78.0000 - val_true_positives: 633.0000 - val_true_negatives: 651.0000 - val_false_positives: 142.0000\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3722 - auc: 0.9195 - binary_accuracy: 0.8510 - precision: 0.8274 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2399.0000 - false_positives: 567.0000 - val_loss: 0.3518 - val_auc: 0.9317 - val_binary_accuracy: 0.8570 - val_precision: 0.8298 - val_recall: 0.8776 - val_false_negatives: 87.0000 - val_true_positives: 624.0000 - val_true_negatives: 665.0000 - val_false_positives: 128.0000\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3713 - auc: 0.9189 - binary_accuracy: 0.8517 - precision: 0.8300 - recall: 0.8894 - false_negatives: 337.0000 - true_positives: 2710.0000 - true_negatives: 2411.0000 - false_positives: 555.0000 - val_loss: 0.3555 - val_auc: 0.9325 - val_binary_accuracy: 0.8570 - val_precision: 0.8342 - val_recall: 0.8706 - val_false_negatives: 92.0000 - val_true_positives: 619.0000 - val_true_negatives: 670.0000 - val_false_positives: 123.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3662 - auc: 0.9213 - binary_accuracy: 0.8550 - precision: 0.8296 - recall: 0.8983 - false_negatives: 310.0000 - true_positives: 2737.0000 - true_negatives: 2404.0000 - false_positives: 562.0000 - val_loss: 0.3447 - val_auc: 0.9358 - val_binary_accuracy: 0.8597 - val_precision: 0.8298 - val_recall: 0.8847 - val_false_negatives: 82.0000 - val_true_positives: 629.0000 - val_true_negatives: 664.0000 - val_false_positives: 129.0000\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3610 - auc: 0.9248 - binary_accuracy: 0.8525 - precision: 0.8307 - recall: 0.8904 - false_negatives: 334.0000 - true_positives: 2713.0000 - true_negatives: 2413.0000 - false_positives: 553.0000 - val_loss: 0.3481 - val_auc: 0.9332 - val_binary_accuracy: 0.8597 - val_precision: 0.8425 - val_recall: 0.8650 - val_false_negatives: 96.0000 - val_true_positives: 615.0000 - val_true_negatives: 678.0000 - val_false_positives: 115.0000\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3623 - auc: 0.9238 - binary_accuracy: 0.8533 - precision: 0.8277 - recall: 0.8973 - false_negatives: 313.0000 - true_positives: 2734.0000 - true_negatives: 2397.0000 - false_positives: 569.0000 - val_loss: 0.3480 - val_auc: 0.9335 - val_binary_accuracy: 0.8557 - val_precision: 0.8440 - val_recall: 0.8523 - val_false_negatives: 105.0000 - val_true_positives: 606.0000 - val_true_negatives: 681.0000 - val_false_positives: 112.0000\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3608 - auc: 0.9241 - binary_accuracy: 0.8571 - precision: 0.8368 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2436.0000 - false_positives: 530.0000 - val_loss: 0.3468 - val_auc: 0.9338 - val_binary_accuracy: 0.8584 - val_precision: 0.8392 - val_recall: 0.8664 - val_false_negatives: 95.0000 - val_true_positives: 616.0000 - val_true_negatives: 675.0000 - val_false_positives: 118.0000\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3562 - auc: 0.9267 - binary_accuracy: 0.8517 - precision: 0.8312 - recall: 0.8874 - false_negatives: 343.0000 - true_positives: 2704.0000 - true_negatives: 2417.0000 - false_positives: 549.0000 - val_loss: 0.3439 - val_auc: 0.9341 - val_binary_accuracy: 0.8590 - val_precision: 0.8441 - val_recall: 0.8608 - val_false_negatives: 99.0000 - val_true_positives: 612.0000 - val_true_negatives: 680.0000 - val_false_positives: 113.0000\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3542 - auc: 0.9284 - binary_accuracy: 0.8555 - precision: 0.8363 - recall: 0.8887 - false_negatives: 339.0000 - true_positives: 2708.0000 - true_negatives: 2436.0000 - false_positives: 530.0000 - val_loss: 0.3376 - val_auc: 0.9369 - val_binary_accuracy: 0.8570 - val_precision: 0.8272 - val_recall: 0.8819 - val_false_negatives: 84.0000 - val_true_positives: 627.0000 - val_true_negatives: 662.0000 - val_false_positives: 131.0000\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3492 - auc: 0.9286 - binary_accuracy: 0.8495 - precision: 0.8320 - recall: 0.8809 - false_negatives: 363.0000 - true_positives: 2684.0000 - true_negatives: 2424.0000 - false_positives: 542.0000 - val_loss: 0.3466 - val_auc: 0.9345 - val_binary_accuracy: 0.8551 - val_precision: 0.8567 - val_recall: 0.8326 - val_false_negatives: 119.0000 - val_true_positives: 592.0000 - val_true_negatives: 694.0000 - val_false_positives: 99.0000\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3500 - auc: 0.9289 - binary_accuracy: 0.8548 - precision: 0.8357 - recall: 0.8881 - false_negatives: 341.0000 - true_positives: 2706.0000 - true_negatives: 2434.0000 - false_positives: 532.0000 - val_loss: 0.3404 - val_auc: 0.9350 - val_binary_accuracy: 0.8564 - val_precision: 0.8433 - val_recall: 0.8551 - val_false_negatives: 103.0000 - val_true_positives: 608.0000 - val_true_negatives: 680.0000 - val_false_positives: 113.0000\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3480 - auc: 0.9296 - binary_accuracy: 0.8563 - precision: 0.8325 - recall: 0.8969 - false_negatives: 314.0000 - true_positives: 2733.0000 - true_negatives: 2416.0000 - false_positives: 550.0000 - val_loss: 0.3354 - val_auc: 0.9367 - val_binary_accuracy: 0.8604 - val_precision: 0.8465 - val_recall: 0.8608 - val_false_negatives: 99.0000 - val_true_positives: 612.0000 - val_true_negatives: 682.0000 - val_false_positives: 111.0000\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3481 - auc: 0.9287 - binary_accuracy: 0.8546 - precision: 0.8346 - recall: 0.8894 - false_negatives: 337.0000 - true_positives: 2710.0000 - true_negatives: 2429.0000 - false_positives: 537.0000 - val_loss: 0.3352 - val_auc: 0.9379 - val_binary_accuracy: 0.8644 - val_precision: 0.8555 - val_recall: 0.8579 - val_false_negatives: 101.0000 - val_true_positives: 610.0000 - val_true_negatives: 690.0000 - val_false_positives: 103.0000\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3401 - auc: 0.9325 - binary_accuracy: 0.8628 - precision: 0.8421 - recall: 0.8976 - false_negatives: 312.0000 - true_positives: 2735.0000 - true_negatives: 2453.0000 - false_positives: 513.0000 - val_loss: 0.3360 - val_auc: 0.9367 - val_binary_accuracy: 0.8604 - val_precision: 0.8465 - val_recall: 0.8608 - val_false_negatives: 99.0000 - val_true_positives: 612.0000 - val_true_negatives: 682.0000 - val_false_positives: 111.0000\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3458 - auc: 0.9287 - binary_accuracy: 0.8616 - precision: 0.8392 - recall: 0.8992 - false_negatives: 307.0000 - true_positives: 2740.0000 - true_negatives: 2441.0000 - false_positives: 525.0000 - val_loss: 0.3364 - val_auc: 0.9366 - val_binary_accuracy: 0.8670 - val_precision: 0.8554 - val_recall: 0.8650 - val_false_negatives: 96.0000 - val_true_positives: 615.0000 - val_true_negatives: 689.0000 - val_false_positives: 104.0000\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3378 - auc: 0.9335 - binary_accuracy: 0.8591 - precision: 0.8380 - recall: 0.8950 - false_negatives: 320.0000 - true_positives: 2727.0000 - true_negatives: 2439.0000 - false_positives: 527.0000 - val_loss: 0.3268 - val_auc: 0.9388 - val_binary_accuracy: 0.8597 - val_precision: 0.8238 - val_recall: 0.8945 - val_false_negatives: 75.0000 - val_true_positives: 636.0000 - val_true_negatives: 657.0000 - val_false_positives: 136.0000\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 9ms/step - loss: 0.3393 - auc: 0.9332 - binary_accuracy: 0.8616 - precision: 0.8407 - recall: 0.8969 - false_negatives: 314.0000 - true_positives: 2733.0000 - true_negatives: 2448.0000 - false_positives: 518.0000 - val_loss: 0.3353 - val_auc: 0.9387 - val_binary_accuracy: 0.8624 - val_precision: 0.8539 - val_recall: 0.8551 - val_false_negatives: 103.0000 - val_true_positives: 608.0000 - val_true_negatives: 689.0000 - val_false_positives: 104.0000\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3414 - auc: 0.9315 - binary_accuracy: 0.8611 - precision: 0.8384 - recall: 0.8992 - false_negatives: 307.0000 - true_positives: 2740.0000 - true_negatives: 2438.0000 - false_positives: 528.0000 - val_loss: 0.3279 - val_auc: 0.9386 - val_binary_accuracy: 0.8664 - val_precision: 0.8446 - val_recall: 0.8790 - val_false_negatives: 86.0000 - val_true_positives: 625.0000 - val_true_negatives: 678.0000 - val_false_positives: 115.0000\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3372 - auc: 0.9335 - binary_accuracy: 0.8663 - precision: 0.8437 - recall: 0.9035 - false_negatives: 294.0000 - true_positives: 2753.0000 - true_negatives: 2456.0000 - false_positives: 510.0000 - val_loss: 0.3712 - val_auc: 0.9351 - val_binary_accuracy: 0.8331 - val_precision: 0.8770 - val_recall: 0.7525 - val_false_negatives: 176.0000 - val_true_positives: 535.0000 - val_true_negatives: 718.0000 - val_false_positives: 75.0000\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3385 - auc: 0.9328 - binary_accuracy: 0.8610 - precision: 0.8415 - recall: 0.8940 - false_negatives: 323.0000 - true_positives: 2724.0000 - true_negatives: 2453.0000 - false_positives: 513.0000 - val_loss: 0.3347 - val_auc: 0.9380 - val_binary_accuracy: 0.8577 - val_precision: 0.8535 - val_recall: 0.8439 - val_false_negatives: 111.0000 - val_true_positives: 600.0000 - val_true_negatives: 690.0000 - val_false_positives: 103.0000\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3322 - auc: 0.9357 - binary_accuracy: 0.8630 - precision: 0.8432 - recall: 0.8963 - false_negatives: 316.0000 - true_positives: 2731.0000 - true_negatives: 2458.0000 - false_positives: 508.0000 - val_loss: 0.3284 - val_auc: 0.9384 - val_binary_accuracy: 0.8637 - val_precision: 0.8456 - val_recall: 0.8706 - val_false_negatives: 92.0000 - val_true_positives: 619.0000 - val_true_negatives: 680.0000 - val_false_positives: 113.0000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.4180 - auc: 0.0000e+00 - binary_accuracy: 0.8438 - precision: 0.0000e+00 - recall: 0.0000e+00 - false_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 27.0000 - false_positives: 5.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0051s). Check your callbacks.\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.3725 - auc: 0.8350 - binary_accuracy: 0.8330 - precision: 0.1573 - recall: 0.6667 - false_negatives: 14.0000 - true_positives: 28.0000 - true_negatives: 790.0000 - false_positives: 150.0000       \n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_33), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer_33/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 2s 36ms/step - loss: 0.5560 - auc: 0.7778 - binary_accuracy: 0.7058 - precision: 0.6897 - recall: 0.7624 - false_negatives: 724.0000 - true_positives: 2323.0000 - true_negatives: 1921.0000 - false_positives: 1045.0000 - val_loss: 0.5112 - val_auc: 0.8757 - val_binary_accuracy: 0.8105 - val_precision: 0.7623 - val_recall: 0.8706 - val_false_negatives: 92.0000 - val_true_positives: 619.0000 - val_true_negatives: 600.0000 - val_false_positives: 193.0000\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4809 - auc: 0.8393 - binary_accuracy: 0.7831 - precision: 0.7475 - recall: 0.8638 - false_negatives: 415.0000 - true_positives: 2632.0000 - true_negatives: 2077.0000 - false_positives: 889.0000 - val_loss: 0.4855 - val_auc: 0.8811 - val_binary_accuracy: 0.8105 - val_precision: 0.7530 - val_recall: 0.8917 - val_false_negatives: 77.0000 - val_true_positives: 634.0000 - val_true_negatives: 585.0000 - val_false_positives: 208.0000\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4660 - auc: 0.8453 - binary_accuracy: 0.7888 - precision: 0.7494 - recall: 0.8763 - false_negatives: 377.0000 - true_positives: 2670.0000 - true_negatives: 2073.0000 - false_positives: 893.0000 - val_loss: 0.4621 - val_auc: 0.8789 - val_binary_accuracy: 0.8132 - val_precision: 0.7547 - val_recall: 0.8959 - val_false_negatives: 74.0000 - val_true_positives: 637.0000 - val_true_negatives: 586.0000 - val_false_positives: 207.0000\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4560 - auc: 0.8575 - binary_accuracy: 0.7998 - precision: 0.7579 - recall: 0.8887 - false_negatives: 339.0000 - true_positives: 2708.0000 - true_negatives: 2101.0000 - false_positives: 865.0000 - val_loss: 0.4384 - val_auc: 0.8864 - val_binary_accuracy: 0.8205 - val_precision: 0.7634 - val_recall: 0.8987 - val_false_negatives: 72.0000 - val_true_positives: 639.0000 - val_true_negatives: 595.0000 - val_false_positives: 198.0000\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.4458 - auc: 0.8678 - binary_accuracy: 0.8092 - precision: 0.7699 - recall: 0.8894 - false_negatives: 337.0000 - true_positives: 2710.0000 - true_negatives: 2156.0000 - false_positives: 810.0000 - val_loss: 0.4251 - val_auc: 0.8937 - val_binary_accuracy: 0.8278 - val_precision: 0.7756 - val_recall: 0.8945 - val_false_negatives: 75.0000 - val_true_positives: 636.0000 - val_true_negatives: 609.0000 - val_false_positives: 184.0000\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.4338 - auc: 0.8777 - binary_accuracy: 0.8212 - precision: 0.7840 - recall: 0.8933 - false_negatives: 325.0000 - true_positives: 2722.0000 - true_negatives: 2216.0000 - false_positives: 750.0000 - val_loss: 0.4120 - val_auc: 0.9036 - val_binary_accuracy: 0.8324 - val_precision: 0.7749 - val_recall: 0.9100 - val_false_negatives: 64.0000 - val_true_positives: 647.0000 - val_true_negatives: 605.0000 - val_false_positives: 188.0000\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.4214 - auc: 0.8899 - binary_accuracy: 0.8264 - precision: 0.7887 - recall: 0.8979 - false_negatives: 311.0000 - true_positives: 2736.0000 - true_negatives: 2233.0000 - false_positives: 733.0000 - val_loss: 0.3914 - val_auc: 0.9149 - val_binary_accuracy: 0.8438 - val_precision: 0.7968 - val_recall: 0.8987 - val_false_negatives: 72.0000 - val_true_positives: 639.0000 - val_true_negatives: 630.0000 - val_false_positives: 163.0000\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4079 - auc: 0.8986 - binary_accuracy: 0.8335 - precision: 0.7998 - recall: 0.8956 - false_negatives: 318.0000 - true_positives: 2729.0000 - true_negatives: 2283.0000 - false_positives: 683.0000 - val_loss: 0.3795 - val_auc: 0.9244 - val_binary_accuracy: 0.8444 - val_precision: 0.7941 - val_recall: 0.9058 - val_false_negatives: 67.0000 - val_true_positives: 644.0000 - val_true_negatives: 626.0000 - val_false_positives: 167.0000\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3943 - auc: 0.9076 - binary_accuracy: 0.8418 - precision: 0.8097 - recall: 0.8992 - false_negatives: 307.0000 - true_positives: 2740.0000 - true_negatives: 2322.0000 - false_positives: 644.0000 - val_loss: 0.3649 - val_auc: 0.9272 - val_binary_accuracy: 0.8517 - val_precision: 0.8161 - val_recall: 0.8861 - val_false_negatives: 81.0000 - val_true_positives: 630.0000 - val_true_negatives: 651.0000 - val_false_positives: 142.0000\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3811 - auc: 0.9141 - binary_accuracy: 0.8487 - precision: 0.8210 - recall: 0.8969 - false_negatives: 314.0000 - true_positives: 2733.0000 - true_negatives: 2370.0000 - false_positives: 596.0000 - val_loss: 0.3578 - val_auc: 0.9303 - val_binary_accuracy: 0.8577 - val_precision: 0.8223 - val_recall: 0.8917 - val_false_negatives: 77.0000 - val_true_positives: 634.0000 - val_true_negatives: 656.0000 - val_false_positives: 137.0000\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3860 - auc: 0.9125 - binary_accuracy: 0.8472 - precision: 0.8207 - recall: 0.8937 - false_negatives: 324.0000 - true_positives: 2723.0000 - true_negatives: 2371.0000 - false_positives: 595.0000 - val_loss: 0.3559 - val_auc: 0.9325 - val_binary_accuracy: 0.8570 - val_precision: 0.8255 - val_recall: 0.8847 - val_false_negatives: 82.0000 - val_true_positives: 629.0000 - val_true_negatives: 660.0000 - val_false_positives: 133.0000\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3775 - auc: 0.9150 - binary_accuracy: 0.8478 - precision: 0.8226 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2380.0000 - false_positives: 586.0000 - val_loss: 0.3601 - val_auc: 0.9299 - val_binary_accuracy: 0.8517 - val_precision: 0.8389 - val_recall: 0.8495 - val_false_negatives: 107.0000 - val_true_positives: 604.0000 - val_true_negatives: 677.0000 - val_false_positives: 116.0000\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3662 - auc: 0.9224 - binary_accuracy: 0.8478 - precision: 0.8240 - recall: 0.8897 - false_negatives: 336.0000 - true_positives: 2711.0000 - true_negatives: 2387.0000 - false_positives: 579.0000 - val_loss: 0.3499 - val_auc: 0.9337 - val_binary_accuracy: 0.8551 - val_precision: 0.8400 - val_recall: 0.8565 - val_false_negatives: 102.0000 - val_true_positives: 609.0000 - val_true_negatives: 677.0000 - val_false_positives: 116.0000\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3625 - auc: 0.9231 - binary_accuracy: 0.8525 - precision: 0.8327 - recall: 0.8871 - false_negatives: 344.0000 - true_positives: 2703.0000 - true_negatives: 2423.0000 - false_positives: 543.0000 - val_loss: 0.3502 - val_auc: 0.9333 - val_binary_accuracy: 0.8544 - val_precision: 0.8245 - val_recall: 0.8790 - val_false_negatives: 86.0000 - val_true_positives: 625.0000 - val_true_negatives: 660.0000 - val_false_positives: 133.0000\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3662 - auc: 0.9219 - binary_accuracy: 0.8487 - precision: 0.8263 - recall: 0.8881 - false_negatives: 341.0000 - true_positives: 2706.0000 - true_negatives: 2397.0000 - false_positives: 569.0000 - val_loss: 0.3539 - val_auc: 0.9323 - val_binary_accuracy: 0.8477 - val_precision: 0.8433 - val_recall: 0.8326 - val_false_negatives: 119.0000 - val_true_positives: 592.0000 - val_true_negatives: 683.0000 - val_false_positives: 110.0000\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3603 - auc: 0.9231 - binary_accuracy: 0.8565 - precision: 0.8358 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2432.0000 - false_positives: 534.0000 - val_loss: 0.3410 - val_auc: 0.9364 - val_binary_accuracy: 0.8570 - val_precision: 0.8238 - val_recall: 0.8875 - val_false_negatives: 80.0000 - val_true_positives: 631.0000 - val_true_negatives: 658.0000 - val_false_positives: 135.0000\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3580 - auc: 0.9262 - binary_accuracy: 0.8556 - precision: 0.8366 - recall: 0.8887 - false_negatives: 339.0000 - true_positives: 2708.0000 - true_negatives: 2437.0000 - false_positives: 529.0000 - val_loss: 0.3453 - val_auc: 0.9350 - val_binary_accuracy: 0.8604 - val_precision: 0.8474 - val_recall: 0.8594 - val_false_negatives: 100.0000 - val_true_positives: 611.0000 - val_true_negatives: 683.0000 - val_false_positives: 110.0000\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3536 - auc: 0.9276 - binary_accuracy: 0.8563 - precision: 0.8368 - recall: 0.8901 - false_negatives: 335.0000 - true_positives: 2712.0000 - true_negatives: 2437.0000 - false_positives: 529.0000 - val_loss: 0.3415 - val_auc: 0.9362 - val_binary_accuracy: 0.8610 - val_precision: 0.8303 - val_recall: 0.8875 - val_false_negatives: 80.0000 - val_true_positives: 631.0000 - val_true_negatives: 664.0000 - val_false_positives: 129.0000\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.3485 - auc: 0.9291 - binary_accuracy: 0.8556 - precision: 0.8382 - recall: 0.8861 - false_negatives: 347.0000 - true_positives: 2700.0000 - true_negatives: 2445.0000 - false_positives: 521.0000 - val_loss: 0.3380 - val_auc: 0.9373 - val_binary_accuracy: 0.8590 - val_precision: 0.8322 - val_recall: 0.8790 - val_false_negatives: 86.0000 - val_true_positives: 625.0000 - val_true_negatives: 667.0000 - val_false_positives: 126.0000\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3497 - auc: 0.9283 - binary_accuracy: 0.8561 - precision: 0.8369 - recall: 0.8894 - false_negatives: 337.0000 - true_positives: 2710.0000 - true_negatives: 2438.0000 - false_positives: 528.0000 - val_loss: 0.3390 - val_auc: 0.9368 - val_binary_accuracy: 0.8597 - val_precision: 0.8342 - val_recall: 0.8776 - val_false_negatives: 87.0000 - val_true_positives: 624.0000 - val_true_negatives: 669.0000 - val_false_positives: 124.0000\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.3458 - auc: 0.9301 - binary_accuracy: 0.8593 - precision: 0.8400 - recall: 0.8924 - false_negatives: 328.0000 - true_positives: 2719.0000 - true_negatives: 2448.0000 - false_positives: 518.0000 - val_loss: 0.3363 - val_auc: 0.9372 - val_binary_accuracy: 0.8604 - val_precision: 0.8344 - val_recall: 0.8790 - val_false_negatives: 86.0000 - val_true_positives: 625.0000 - val_true_negatives: 669.0000 - val_false_positives: 124.0000\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.3433 - auc: 0.9316 - binary_accuracy: 0.8571 - precision: 0.8368 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2436.0000 - false_positives: 530.0000 - val_loss: 0.3353 - val_auc: 0.9384 - val_binary_accuracy: 0.8617 - val_precision: 0.8488 - val_recall: 0.8608 - val_false_negatives: 99.0000 - val_true_positives: 612.0000 - val_true_negatives: 684.0000 - val_false_positives: 109.0000\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3492 - auc: 0.9285 - binary_accuracy: 0.8595 - precision: 0.8404 - recall: 0.8920 - false_negatives: 329.0000 - true_positives: 2718.0000 - true_negatives: 2450.0000 - false_positives: 516.0000 - val_loss: 0.3365 - val_auc: 0.9368 - val_binary_accuracy: 0.8617 - val_precision: 0.8376 - val_recall: 0.8776 - val_false_negatives: 87.0000 - val_true_positives: 624.0000 - val_true_negatives: 672.0000 - val_false_positives: 121.0000\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3433 - auc: 0.9309 - binary_accuracy: 0.8601 - precision: 0.8398 - recall: 0.8947 - false_negatives: 321.0000 - true_positives: 2726.0000 - true_negatives: 2446.0000 - false_positives: 520.0000 - val_loss: 0.3363 - val_auc: 0.9360 - val_binary_accuracy: 0.8664 - val_precision: 0.8493 - val_recall: 0.8720 - val_false_negatives: 91.0000 - val_true_positives: 620.0000 - val_true_negatives: 683.0000 - val_false_positives: 110.0000\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.3443 - auc: 0.9311 - binary_accuracy: 0.8576 - precision: 0.8382 - recall: 0.8910 - false_negatives: 332.0000 - true_positives: 2715.0000 - true_negatives: 2442.0000 - false_positives: 524.0000 - val_loss: 0.3327 - val_auc: 0.9384 - val_binary_accuracy: 0.8657 - val_precision: 0.8520 - val_recall: 0.8664 - val_false_negatives: 95.0000 - val_true_positives: 616.0000 - val_true_negatives: 686.0000 - val_false_positives: 107.0000\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3377 - auc: 0.9331 - binary_accuracy: 0.8605 - precision: 0.8407 - recall: 0.8940 - false_negatives: 323.0000 - true_positives: 2724.0000 - true_negatives: 2450.0000 - false_positives: 516.0000 - val_loss: 0.3324 - val_auc: 0.9396 - val_binary_accuracy: 0.8584 - val_precision: 0.8567 - val_recall: 0.8411 - val_false_negatives: 113.0000 - val_true_positives: 598.0000 - val_true_negatives: 693.0000 - val_false_positives: 100.0000\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3409 - auc: 0.9324 - binary_accuracy: 0.8643 - precision: 0.8427 - recall: 0.9002 - false_negatives: 304.0000 - true_positives: 2743.0000 - true_negatives: 2454.0000 - false_positives: 512.0000 - val_loss: 0.3437 - val_auc: 0.9379 - val_binary_accuracy: 0.8557 - val_precision: 0.8800 - val_recall: 0.8045 - val_false_negatives: 139.0000 - val_true_positives: 572.0000 - val_true_negatives: 715.0000 - val_false_positives: 78.0000\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.3411 - auc: 0.9325 - binary_accuracy: 0.8606 - precision: 0.8425 - recall: 0.8917 - false_negatives: 330.0000 - true_positives: 2717.0000 - true_negatives: 2458.0000 - false_positives: 508.0000 - val_loss: 0.3353 - val_auc: 0.9376 - val_binary_accuracy: 0.8597 - val_precision: 0.8561 - val_recall: 0.8453 - val_false_negatives: 110.0000 - val_true_positives: 601.0000 - val_true_negatives: 692.0000 - val_false_positives: 101.0000\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 11ms/step - loss: 0.3325 - auc: 0.9356 - binary_accuracy: 0.8626 - precision: 0.8450 - recall: 0.8927 - false_negatives: 327.0000 - true_positives: 2720.0000 - true_negatives: 2467.0000 - false_positives: 499.0000 - val_loss: 0.3355 - val_auc: 0.9384 - val_binary_accuracy: 0.8617 - val_precision: 0.8629 - val_recall: 0.8411 - val_false_negatives: 113.0000 - val_true_positives: 598.0000 - val_true_negatives: 698.0000 - val_false_positives: 95.0000\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3370 - auc: 0.9342 - binary_accuracy: 0.8596 - precision: 0.8441 - recall: 0.8868 - false_negatives: 345.0000 - true_positives: 2702.0000 - true_negatives: 2467.0000 - false_positives: 499.0000 - val_loss: 0.3356 - val_auc: 0.9376 - val_binary_accuracy: 0.8610 - val_precision: 0.8565 - val_recall: 0.8481 - val_false_negatives: 108.0000 - val_true_positives: 603.0000 - val_true_negatives: 692.0000 - val_false_positives: 101.0000\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3340 - auc: 0.9347 - binary_accuracy: 0.8611 - precision: 0.8422 - recall: 0.8933 - false_negatives: 325.0000 - true_positives: 2722.0000 - true_negatives: 2456.0000 - false_positives: 510.0000 - val_loss: 0.3375 - val_auc: 0.9389 - val_binary_accuracy: 0.8570 - val_precision: 0.8605 - val_recall: 0.8326 - val_false_negatives: 119.0000 - val_true_positives: 592.0000 - val_true_negatives: 697.0000 - val_false_positives: 96.0000\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.3129 - auc: 0.8378 - binary_accuracy: 0.8554 - precision: 0.1479 - recall: 0.5000 - false_negatives: 21.0000 - true_positives: 21.0000 - true_negatives: 819.0000 - false_positives: 121.0000         \n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_34), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'afm_layer_34/projection_p:0' shape=(4, 1) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "Epoch 1/100\n",
      "47/47 [==============================] - 2s 45ms/step - loss: 0.5616 - auc: 0.7780 - binary_accuracy: 0.7076 - precision: 0.7021 - recall: 0.7348 - false_negatives: 808.0000 - true_positives: 2239.0000 - true_negatives: 2016.0000 - false_positives: 950.0000 - val_loss: 0.5138 - val_auc: 0.8670 - val_binary_accuracy: 0.8118 - val_precision: 0.7572 - val_recall: 0.8861 - val_false_negatives: 81.0000 - val_true_positives: 630.0000 - val_true_negatives: 591.0000 - val_false_positives: 202.0000\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.4920 - auc: 0.8304 - binary_accuracy: 0.7781 - precision: 0.7472 - recall: 0.8497 - false_negatives: 458.0000 - true_positives: 2589.0000 - true_negatives: 2090.0000 - false_positives: 876.0000 - val_loss: 0.4908 - val_auc: 0.8698 - val_binary_accuracy: 0.8072 - val_precision: 0.7485 - val_recall: 0.8917 - val_false_negatives: 77.0000 - val_true_positives: 634.0000 - val_true_negatives: 580.0000 - val_false_positives: 213.0000\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.4666 - auc: 0.8462 - binary_accuracy: 0.7901 - precision: 0.7538 - recall: 0.8700 - false_negatives: 396.0000 - true_positives: 2651.0000 - true_negatives: 2100.0000 - false_positives: 866.0000 - val_loss: 0.4660 - val_auc: 0.8744 - val_binary_accuracy: 0.8178 - val_precision: 0.7629 - val_recall: 0.8917 - val_false_negatives: 77.0000 - val_true_positives: 634.0000 - val_true_negatives: 596.0000 - val_false_positives: 197.0000\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 1s 17ms/step - loss: 0.4531 - auc: 0.8589 - binary_accuracy: 0.7961 - precision: 0.7584 - recall: 0.8769 - false_negatives: 375.0000 - true_positives: 2672.0000 - true_negatives: 2115.0000 - false_positives: 851.0000 - val_loss: 0.4443 - val_auc: 0.8837 - val_binary_accuracy: 0.8238 - val_precision: 0.7667 - val_recall: 0.9015 - val_false_negatives: 70.0000 - val_true_positives: 641.0000 - val_true_negatives: 598.0000 - val_false_positives: 195.0000\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.4418 - auc: 0.8690 - binary_accuracy: 0.8066 - precision: 0.7678 - recall: 0.8864 - false_negatives: 346.0000 - true_positives: 2701.0000 - true_negatives: 2149.0000 - false_positives: 817.0000 - val_loss: 0.4260 - val_auc: 0.8934 - val_binary_accuracy: 0.8271 - val_precision: 0.7760 - val_recall: 0.8917 - val_false_negatives: 77.0000 - val_true_positives: 634.0000 - val_true_negatives: 610.0000 - val_false_positives: 183.0000\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.4343 - auc: 0.8781 - binary_accuracy: 0.8176 - precision: 0.7794 - recall: 0.8927 - false_negatives: 327.0000 - true_positives: 2720.0000 - true_negatives: 2196.0000 - false_positives: 770.0000 - val_loss: 0.4101 - val_auc: 0.8996 - val_binary_accuracy: 0.8351 - val_precision: 0.7840 - val_recall: 0.8987 - val_false_negatives: 72.0000 - val_true_positives: 639.0000 - val_true_negatives: 617.0000 - val_false_positives: 176.0000\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 1s 13ms/step - loss: 0.4207 - auc: 0.8899 - binary_accuracy: 0.8259 - precision: 0.7904 - recall: 0.8933 - false_negatives: 325.0000 - true_positives: 2722.0000 - true_negatives: 2244.0000 - false_positives: 722.0000 - val_loss: 0.3953 - val_auc: 0.9131 - val_binary_accuracy: 0.8398 - val_precision: 0.7937 - val_recall: 0.8931 - val_false_negatives: 76.0000 - val_true_positives: 635.0000 - val_true_negatives: 628.0000 - val_false_positives: 165.0000\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.4064 - auc: 0.8988 - binary_accuracy: 0.8324 - precision: 0.8003 - recall: 0.8917 - false_negatives: 330.0000 - true_positives: 2717.0000 - true_negatives: 2288.0000 - false_positives: 678.0000 - val_loss: 0.3851 - val_auc: 0.9222 - val_binary_accuracy: 0.8444 - val_precision: 0.7898 - val_recall: 0.9142 - val_false_negatives: 61.0000 - val_true_positives: 650.0000 - val_true_negatives: 620.0000 - val_false_positives: 173.0000\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 1s 16ms/step - loss: 0.3951 - auc: 0.9054 - binary_accuracy: 0.8398 - precision: 0.8070 - recall: 0.8989 - false_negatives: 308.0000 - true_positives: 2739.0000 - true_negatives: 2311.0000 - false_positives: 655.0000 - val_loss: 0.3664 - val_auc: 0.9306 - val_binary_accuracy: 0.8544 - val_precision: 0.8178 - val_recall: 0.8903 - val_false_negatives: 78.0000 - val_true_positives: 633.0000 - val_true_negatives: 652.0000 - val_false_positives: 141.0000\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 1s 16ms/step - loss: 0.3820 - auc: 0.9139 - binary_accuracy: 0.8445 - precision: 0.8162 - recall: 0.8947 - false_negatives: 321.0000 - true_positives: 2726.0000 - true_negatives: 2352.0000 - false_positives: 614.0000 - val_loss: 0.3669 - val_auc: 0.9300 - val_binary_accuracy: 0.8511 - val_precision: 0.8464 - val_recall: 0.8368 - val_false_negatives: 116.0000 - val_true_positives: 595.0000 - val_true_negatives: 685.0000 - val_false_positives: 108.0000\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.3892 - auc: 0.9111 - binary_accuracy: 0.8433 - precision: 0.8164 - recall: 0.8914 - false_negatives: 331.0000 - true_positives: 2716.0000 - true_negatives: 2355.0000 - false_positives: 611.0000 - val_loss: 0.3655 - val_auc: 0.9305 - val_binary_accuracy: 0.8517 - val_precision: 0.8370 - val_recall: 0.8523 - val_false_negatives: 105.0000 - val_true_positives: 606.0000 - val_true_negatives: 675.0000 - val_false_positives: 118.0000\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 1s 14ms/step - loss: 0.3760 - auc: 0.9172 - binary_accuracy: 0.8512 - precision: 0.8284 - recall: 0.8907 - false_negatives: 333.0000 - true_positives: 2714.0000 - true_negatives: 2404.0000 - false_positives: 562.0000 - val_loss: 0.3561 - val_auc: 0.9317 - val_binary_accuracy: 0.8564 - val_precision: 0.8358 - val_recall: 0.8664 - val_false_negatives: 95.0000 - val_true_positives: 616.0000 - val_true_negatives: 672.0000 - val_false_positives: 121.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3698 - auc: 0.9190 - binary_accuracy: 0.8490 - precision: 0.8215 - recall: 0.8969 - false_negatives: 314.0000 - true_positives: 2733.0000 - true_negatives: 2372.0000 - false_positives: 594.0000 - val_loss: 0.3515 - val_auc: 0.9346 - val_binary_accuracy: 0.8497 - val_precision: 0.8420 - val_recall: 0.8397 - val_false_negatives: 114.0000 - val_true_positives: 597.0000 - val_true_negatives: 681.0000 - val_false_positives: 112.0000\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3666 - auc: 0.9195 - binary_accuracy: 0.8555 - precision: 0.8314 - recall: 0.8966 - false_negatives: 315.0000 - true_positives: 2732.0000 - true_negatives: 2412.0000 - false_positives: 554.0000 - val_loss: 0.3474 - val_auc: 0.9349 - val_binary_accuracy: 0.8524 - val_precision: 0.8336 - val_recall: 0.8594 - val_false_negatives: 100.0000 - val_true_positives: 611.0000 - val_true_negatives: 671.0000 - val_false_positives: 122.0000\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3616 - auc: 0.9242 - binary_accuracy: 0.8518 - precision: 0.8311 - recall: 0.8881 - false_negatives: 341.0000 - true_positives: 2706.0000 - true_negatives: 2416.0000 - false_positives: 550.0000 - val_loss: 0.3663 - val_auc: 0.9325 - val_binary_accuracy: 0.8418 - val_precision: 0.8589 - val_recall: 0.7961 - val_false_negatives: 145.0000 - val_true_positives: 566.0000 - val_true_negatives: 700.0000 - val_false_positives: 93.0000\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3618 - auc: 0.9238 - binary_accuracy: 0.8517 - precision: 0.8356 - recall: 0.8805 - false_negatives: 364.0000 - true_positives: 2683.0000 - true_negatives: 2438.0000 - false_positives: 528.0000 - val_loss: 0.3636 - val_auc: 0.9335 - val_binary_accuracy: 0.8424 - val_precision: 0.8635 - val_recall: 0.7918 - val_false_negatives: 148.0000 - val_true_positives: 563.0000 - val_true_negatives: 704.0000 - val_false_positives: 89.0000\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3602 - auc: 0.9245 - binary_accuracy: 0.8561 - precision: 0.8349 - recall: 0.8927 - false_negatives: 327.0000 - true_positives: 2720.0000 - true_negatives: 2428.0000 - false_positives: 538.0000 - val_loss: 0.3353 - val_auc: 0.9369 - val_binary_accuracy: 0.8590 - val_precision: 0.8287 - val_recall: 0.8847 - val_false_negatives: 82.0000 - val_true_positives: 629.0000 - val_true_negatives: 663.0000 - val_false_positives: 130.0000\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 11ms/step - loss: 0.3570 - auc: 0.9255 - binary_accuracy: 0.8548 - precision: 0.8347 - recall: 0.8897 - false_negatives: 336.0000 - true_positives: 2711.0000 - true_negatives: 2429.0000 - false_positives: 537.0000 - val_loss: 0.3430 - val_auc: 0.9374 - val_binary_accuracy: 0.8604 - val_precision: 0.8594 - val_recall: 0.8425 - val_false_negatives: 112.0000 - val_true_positives: 599.0000 - val_true_negatives: 695.0000 - val_false_positives: 98.0000\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3507 - auc: 0.9273 - binary_accuracy: 0.8581 - precision: 0.8377 - recall: 0.8930 - false_negatives: 326.0000 - true_positives: 2721.0000 - true_negatives: 2439.0000 - false_positives: 527.0000 - val_loss: 0.3414 - val_auc: 0.9368 - val_binary_accuracy: 0.8584 - val_precision: 0.8527 - val_recall: 0.8467 - val_false_negatives: 109.0000 - val_true_positives: 602.0000 - val_true_negatives: 689.0000 - val_false_positives: 104.0000\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3491 - auc: 0.9280 - binary_accuracy: 0.8581 - precision: 0.8324 - recall: 0.9015 - false_negatives: 300.0000 - true_positives: 2747.0000 - true_negatives: 2413.0000 - false_positives: 553.0000 - val_loss: 0.3343 - val_auc: 0.9380 - val_binary_accuracy: 0.8630 - val_precision: 0.8417 - val_recall: 0.8748 - val_false_negatives: 89.0000 - val_true_positives: 622.0000 - val_true_negatives: 676.0000 - val_false_positives: 117.0000\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3539 - auc: 0.9263 - binary_accuracy: 0.8528 - precision: 0.8292 - recall: 0.8937 - false_negatives: 324.0000 - true_positives: 2723.0000 - true_negatives: 2405.0000 - false_positives: 561.0000 - val_loss: 0.3434 - val_auc: 0.9370 - val_binary_accuracy: 0.8590 - val_precision: 0.8549 - val_recall: 0.8453 - val_false_negatives: 110.0000 - val_true_positives: 601.0000 - val_true_negatives: 691.0000 - val_false_positives: 102.0000\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3457 - auc: 0.9300 - binary_accuracy: 0.8591 - precision: 0.8370 - recall: 0.8966 - false_negatives: 315.0000 - true_positives: 2732.0000 - true_negatives: 2434.0000 - false_positives: 532.0000 - val_loss: 0.3508 - val_auc: 0.9360 - val_binary_accuracy: 0.8457 - val_precision: 0.8623 - val_recall: 0.8017 - val_false_negatives: 141.0000 - val_true_positives: 570.0000 - val_true_negatives: 702.0000 - val_false_positives: 91.0000\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3428 - auc: 0.9323 - binary_accuracy: 0.8600 - precision: 0.8427 - recall: 0.8897 - false_negatives: 336.0000 - true_positives: 2711.0000 - true_negatives: 2460.0000 - false_positives: 506.0000 - val_loss: 0.3296 - val_auc: 0.9394 - val_binary_accuracy: 0.8630 - val_precision: 0.8398 - val_recall: 0.8776 - val_false_negatives: 87.0000 - val_true_positives: 624.0000 - val_true_negatives: 674.0000 - val_false_positives: 119.0000\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3409 - auc: 0.9322 - binary_accuracy: 0.8618 - precision: 0.8409 - recall: 0.8969 - false_negatives: 314.0000 - true_positives: 2733.0000 - true_negatives: 2449.0000 - false_positives: 517.0000 - val_loss: 0.3535 - val_auc: 0.9372 - val_binary_accuracy: 0.8431 - val_precision: 0.8717 - val_recall: 0.7834 - val_false_negatives: 154.0000 - val_true_positives: 557.0000 - val_true_negatives: 711.0000 - val_false_positives: 82.0000\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3452 - auc: 0.9304 - binary_accuracy: 0.8591 - precision: 0.8385 - recall: 0.8943 - false_negatives: 322.0000 - true_positives: 2725.0000 - true_negatives: 2441.0000 - false_positives: 525.0000 - val_loss: 0.3282 - val_auc: 0.9390 - val_binary_accuracy: 0.8637 - val_precision: 0.8252 - val_recall: 0.9030 - val_false_negatives: 69.0000 - val_true_positives: 642.0000 - val_true_negatives: 657.0000 - val_false_positives: 136.0000\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3455 - auc: 0.9305 - binary_accuracy: 0.8570 - precision: 0.8376 - recall: 0.8904 - false_negatives: 334.0000 - true_positives: 2713.0000 - true_negatives: 2440.0000 - false_positives: 526.0000 - val_loss: 0.3307 - val_auc: 0.9385 - val_binary_accuracy: 0.8637 - val_precision: 0.8485 - val_recall: 0.8664 - val_false_negatives: 95.0000 - val_true_positives: 616.0000 - val_true_negatives: 683.0000 - val_false_positives: 110.0000\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3402 - auc: 0.9325 - binary_accuracy: 0.8608 - precision: 0.8402 - recall: 0.8956 - false_negatives: 318.0000 - true_positives: 2729.0000 - true_negatives: 2447.0000 - false_positives: 519.0000 - val_loss: 0.3312 - val_auc: 0.9388 - val_binary_accuracy: 0.8644 - val_precision: 0.8555 - val_recall: 0.8579 - val_false_negatives: 101.0000 - val_true_positives: 610.0000 - val_true_negatives: 690.0000 - val_false_positives: 103.0000\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 0.3393 - auc: 0.9322 - binary_accuracy: 0.8640 - precision: 0.8432 - recall: 0.8986 - false_negatives: 309.0000 - true_positives: 2738.0000 - true_negatives: 2457.0000 - false_positives: 509.0000 - val_loss: 0.3352 - val_auc: 0.9380 - val_binary_accuracy: 0.8637 - val_precision: 0.8543 - val_recall: 0.8579 - val_false_negatives: 101.0000 - val_true_positives: 610.0000 - val_true_negatives: 689.0000 - val_false_positives: 104.0000\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3356 - auc: 0.9343 - binary_accuracy: 0.8623 - precision: 0.8479 - recall: 0.8874 - false_negatives: 343.0000 - true_positives: 2704.0000 - true_negatives: 2481.0000 - false_positives: 485.0000 - val_loss: 0.3490 - val_auc: 0.9362 - val_binary_accuracy: 0.8438 - val_precision: 0.8617 - val_recall: 0.7975 - val_false_negatives: 144.0000 - val_true_positives: 567.0000 - val_true_negatives: 702.0000 - val_false_positives: 91.0000\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 10ms/step - loss: 0.3347 - auc: 0.9343 - binary_accuracy: 0.8623 - precision: 0.8428 - recall: 0.8953 - false_negatives: 319.0000 - true_positives: 2728.0000 - true_negatives: 2457.0000 - false_positives: 509.0000 - val_loss: 0.3311 - val_auc: 0.9391 - val_binary_accuracy: 0.8610 - val_precision: 0.8525 - val_recall: 0.8537 - val_false_negatives: 104.0000 - val_true_positives: 607.0000 - val_true_negatives: 688.0000 - val_false_positives: 105.0000\n",
      " 1/31 [..............................] - ETA: 0s - loss: 0.3940 - auc: 0.0000e+00 - binary_accuracy: 0.8438 - precision: 0.0000e+00 - recall: 0.0000e+00 - false_negatives: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 27.0000 - false_positives: 5.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0154s). Check your callbacks.\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.3749 - auc: 0.8385 - binary_accuracy: 0.8299 - precision: 0.1508 - recall: 0.6429 - false_negatives: 15.0000 - true_positives: 27.0000 - true_negatives: 788.0000 - false_positives: 152.0000       \n",
      "[0.34986109 0.35257128 0.37245876 0.31292385 0.37493032] [[8.33409309e-01 8.36048901e-01 1.47928998e-01 5.95238090e-01\n",
      "  1.70000000e+01 2.50000000e+01 7.96000000e+02 1.44000000e+02]\n",
      " [8.31876874e-01 8.34012210e-01 1.50289014e-01 6.19047642e-01\n",
      "  1.60000000e+01 2.60000000e+01 7.93000000e+02 1.47000000e+02]\n",
      " [8.35005045e-01 8.32993865e-01 1.57303378e-01 6.66666687e-01\n",
      "  1.40000000e+01 2.80000000e+01 7.90000000e+02 1.50000000e+02]\n",
      " [8.37791264e-01 8.55397165e-01 1.47887319e-01 5.00000000e-01\n",
      "  2.10000000e+01 2.10000000e+01 8.19000000e+02 1.21000000e+02]\n",
      " [8.38525832e-01 8.29938889e-01 1.50837988e-01 6.42857134e-01\n",
      "  1.50000000e+01 2.70000000e+01 7.88000000e+02 1.52000000e+02]] [[0.83340931 0.8360489 ]\n",
      " [0.83187687 0.83401221]\n",
      " [0.83500504 0.83299387]\n",
      " [0.83779126 0.85539716]\n",
      " [0.83852583 0.82993889]]\n",
      "[array([0.34986109, 0.35257128, 0.37245876, 0.31292385, 0.37493032])] [array([[0.83340931, 0.8360489 ],\n",
      "       [0.83187687, 0.83401221],\n",
      "       [0.83500504, 0.83299387],\n",
      "       [0.83779126, 0.85539716],\n",
      "       [0.83852583, 0.82993889]])]\n"
     ]
    }
   ],
   "source": [
    "loslist = []\n",
    "acclist = []\n",
    "lrs = [1]\n",
    "for i in lrs:\n",
    "    accs = []\n",
    "    los = []\n",
    "    acces = []\n",
    "    for j in range(5):\n",
    "#         model = M(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns, \n",
    "#                         dnn_hidden_units=(64, 64), l2_reg_linear=0.7, lr = 0.001 ,l2_reg_embedding=2.1, \n",
    "#                   l2_reg_dnn=0, seed=1024, dnn_dropout=0.8, \n",
    "#                   dropout = 0, dnn_activation='relu')\n",
    "#         model = PNN(linear_feature_columns, dnn_feature_columns, fm_group=[DEFAULT_GROUP_NAME], \n",
    "#                     dnn_hidden_units=(128, 128, 128), l2_reg_linear=0.1, l2_reg_embedding=1.7, l2_reg_dnn=0, \n",
    "#                     l2_reg_att=0.1, attention_factor=8, afm_dropout=0, seed=1024, dnn_dropout=0.8, \n",
    "#                     dnn_activation='relu', use_inner=True, use_outter=False, kernel_type='mat', task='binary')\n",
    "        model = PNN(linear_feature_columns, dnn_feature_columns, fm_group=[DEFAULT_GROUP_NAME], \n",
    "                    dnn_hidden_units=(256, 128), l2_reg_linear=0.1, l2_reg_embedding=2.7, l2_reg_dnn=0, \n",
    "                    l2_reg_att=0.00001, attention_factor=4, afm_dropout=0.8, seed=1024, dnn_dropout=0.7, \n",
    "                    dnn_activation='relu', use_inner=False, use_outter=True, kernel_type='mat',task='binary')\n",
    "#         model = PNN2(dnn_feature_columns, dnn_hidden_units=(96, 96, 96), l2_reg_embedding=1.3, l2_reg_dnn=0,\n",
    "#             seed=1024, dnn_dropout=0.8, dnn_activation='relu', use_inner=True, use_outter=False, \n",
    "#             kernel_type='mat')\n",
    "#         model = AFM(linear_feature_columns, dnn_feature_columns, fm_group=DEFAULT_GROUP_NAME, use_attention=True,\n",
    "#             attention_factor=8,l2_reg_linear=0.0001, l2_reg_embedding=0.1, l2_reg_att=0.00001, afm_dropout=0.1, seed=1024)\n",
    "#         model = NFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(128, 128, 128),\n",
    "#         l2_reg_embedding=0.9, l2_reg_linear=0.001, l2_reg_dnn=0, seed=1024, bi_dropout=0.4,\n",
    "#         dnn_dropout=0, dnn_activation='sigmoid')\n",
    "#         model =  DeepFEFM(linear_feature_columns, dnn_feature_columns, use_fefm=True,\n",
    "#              dnn_hidden_units=(224, 224, 224), l2_reg_linear=0.00001, l2_reg_embedding_feat=2.1,\n",
    "#              l2_reg_embedding_field=0.5, l2_reg_dnn=0, seed=1024, dnn_dropout=0.6,\n",
    "#              exclude_feature_embed_in_dnn=False, use_linear=True, use_fefm_embed_in_dnn=True, \n",
    "#             dnn_activation='relu')\n",
    "#         model = DIFM(linear_feature_columns, dnn_feature_columns,\n",
    "#          att_embedding_size=8, att_head_num=8, att_res=True, dnn_hidden_units=(64, 64, 64),\n",
    "#          l2_reg_linear=0.0001, l2_reg_embedding=2.1, l2_reg_dnn=0, seed=1024, dnn_dropout=0.9,\n",
    "#          dnn_activation='tanh', dnn_use_bn=False, task='binary')\n",
    "    \n",
    "        input_train = deepfm_train\n",
    "        model.fit(input_train,\n",
    "                        label,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=100,\n",
    "                        batch_size=128,\n",
    "                        shuffle = False,\n",
    "                        verbose = 1, \n",
    "                        callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)],)\n",
    "        input_test = deepfm_test\n",
    "        ans_mtx = model.predict(input_test, batch_size=100)\n",
    "        loss, auc, acc, pre, rec, fn, tp, tn, fp = model.evaluate(input_test, label1)\n",
    "        accs.append([auc, acc, pre, rec, fn, tp, tn, fp])\n",
    "        los.append(loss)\n",
    "        acces.append([auc, acc])\n",
    "        # auc.append(roc_auc_score(label1, ans_mtx))\n",
    "        # loss.append(log_loss(label1, ans_mtx))\n",
    "        # print(max(auc))\n",
    "        # print(auc)\n",
    "        # print(min(loss))\n",
    "        # print(loss)\n",
    "    los = np.array(los)\n",
    "    accs = np.array(accs)\n",
    "    acces = np.array(acces)\n",
    "    print(los, accs, acces)\n",
    "    loslist.append(los)\n",
    "    acclist.append(acces)\n",
    "print(loslist, acclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0.34986109, 0.35257128, 0.37245876, 0.31292385, 0.37493032])],\n",
       " [array([[0.83340931, 0.8360489 ],\n",
       "         [0.83187687, 0.83401221],\n",
       "         [0.83500504, 0.83299387],\n",
       "         [0.83779126, 0.85539716],\n",
       "         [0.83852583, 0.82993889]])])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loslist, acclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, array([0.34986109, 0.35257128, 0.37245876, 0.31292385, 0.37493032]), array([[0.83340931, 0.8360489 ],\n",
      "       [0.83187687, 0.83401221]]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(lrs, np.array(loslist), np.array(acclist)[:, :2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3498610854148865, array([0.83339667, 0.84114051])),\n",
       " (0.3525712788105011, array([0.83519506, 0.84114051])),\n",
       " (0.3724587559700012, array([0.84219855, 0.84215885])),\n",
       " (0.3129238486289978, array([0.83999497, 0.84623218])),\n",
       " (0.37493032217025757, array([0.84229994, 0.84826887]))]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loslist = np.array(loslist)[0]\n",
    "acclist = np.array(acclist)[0]\n",
    "list(zip(loslist, acclist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8386170380000001"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(acclist)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(np.array(acclist)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.array([(0.37357231974601746, 0.83750004, 0.8360489 ), (0.3687582314014435, 0.83573961, 0.83808553), (0.3652315139770508, 0.83789265, 0.82993889), (0.36622631549835205, 0.83680344, 0.83401221), (0.38029944896698, 0.83207953, 0.83706719)])\n",
    "np.min(a[:, 1]), np.mean(a[:, 1]), np.max(a[:, 1]), np.min(a[:, 0]), np.mean(a[:, 0]), np.max(a[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(los, accs[:, :2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(label1 == 0).sum(), np.array(ans_mtx < 0.5).sum(), label1.shape, ans_mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(C = 0.3, multi_class=\"ovr\", solver=\"liblinear\", max_iter=1000)\n",
    "log_model.fit(train, label)\n",
    "print(log_model.score(train, label))\n",
    "y_pred = log_model.predict(test)\n",
    "y_prob = log_model.predict_proba(test)[:, 1]\n",
    "print(accuracy_score(label1, y_pred))\n",
    "print(roc_auc_score(label1, y_prob))\n",
    "print(log_loss(label1, y_prob))\n",
    "print(precision_score(label1, y_pred))\n",
    "print(recall_score(label1, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
